# Neural Networks Explained - Following Andrej Karpathy's Lectures

This repository contains Jupyter notebooks that closely follow and delve into Andrej Karpathy's neural networks lectures. While the lectures themselves offer a deep understanding of the subject, these notebooks aim to provide additional clarity, making complex concepts more digestible.

## ğŸš€ Motivation

As I worked through Andrej Karpathy's neural networks lectures, I found myself seeking a deeper understanding of the foundational concepts. These notebooks serve as both a personal resource and a guide for others who are on a similar path. By meticulously breaking down and expanding on Andrej Karpathy's lectures, I hope to solidify my own understanding and assist others in doing the same.

## ğŸ“˜ Contents

- **Micrograd** - A step-by-step breakdown of a tiny autograd engine, explaining the nuances of automatic differentiation.
- **[Other Topics]** -

## ğŸ–‹ï¸ Features

- Detailed explanations of neural network concepts for enhanced clarity.
- Visualizations and diagrams to aid understanding.
- Slow-motion, manual breakdowns of processes like backpropagation to solidify foundational knowledge.
- Additional insights and perspectives on topics covered in the lectures.

## ğŸ“– References

- [Andrej Karpathy's Neural Networks Lectures](https://github.com/karpathy/nn-zero-to-hero.git)
