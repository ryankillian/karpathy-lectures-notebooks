{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "xqfEjzAnWDUP",
        "u7akS-071XWS",
        "HgTq-qL9b9Rf",
        "2OjS-sytcGPX",
        "Wtu_Xt2OnwDA",
        "OkAVEYwHg97l",
        "WeaYGBfbrGS6",
        "z7WarqFPujpv",
        "r0vwWT4byn6E",
        "Dfinx2_NEgOm",
        "fwUgGTsOsbHA",
        "AlarE1sbv9t6",
        "gDypdt_x18zx",
        "d1aJkR3h-eZG",
        "vkKF_0I9Gnfd",
        "6Qn0YmUlLC2D",
        "TmfXwCUPW45G",
        "MOEqZkimXzAS",
        "ypat99obcrc5"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction"
      ],
      "metadata": {
        "id": "xqfEjzAnWDUP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Backpropagation: A Deep Dive\n",
        "\n",
        "In this notebook, we follow Andrej Karpathy's Neural Networks: Hero to Zero Lecture 5 on \"Building makemore Part 4: Becoming a Backprop Ninja\", we examine backpropagation in detail."
      ],
      "metadata": {
        "id": "YAYKVsenZZ5f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What is a Leaky Abstraction?\n",
        "\n",
        "### 1. What is an Abstraction?\n",
        "\n",
        "First, you need to understand the concept of \"abstraction.\" In computing and software design, abstraction refers to hiding complex details and showing only the essential features of an object or a system. Think of it like a car: when you drive, you don't need to know how its engine works in detail; you just need to know how to operate the steering wheel, accelerator, and brakes. The car's design abstracts away the complexities of its internal workings.\n",
        "\n",
        "### 2. Perfect Abstraction\n",
        "\n",
        "In a perfect world, abstractions would hide all the complexities underneath, and you'd never have to worry about them. Using the car example, it would be as if you never had to concern yourself with the engine, transmission, or any other internal part of the car; you'd just drive.\n",
        "\n",
        "### 3. The Reality: Leaky Abstractions\n",
        "\n",
        "However, no abstraction is perfect. At times, some of the complexities that an abstraction is supposed to hide \"leak\" through, forcing you to deal with them. This is the concept of a \"leaky abstraction.\"\n",
        "\n",
        "### 4. Examples:\n",
        "\n",
        "#### a. **Computer Memory Management**:\n",
        "High-level programming languages abstract away the details of memory management. In languages like Python, you don't have to manually allocate and deallocate memory like in C or C++. However, if you're not careful, you might still run into \"memory leaks\" where unused memory isn't freed up, leading to potential system slowdowns or crashes. The abstraction of automatic memory management is \"leaking\" in this case.\n",
        "\n",
        "#### b. **Internet and Networks**:\n",
        "When you visit a website, the complexities of data packets, IP addresses, and network routing are abstracted away from you. You just type a URL and see the webpage. But sometimes, the page fails to load because a \"server IP address could not be found.\" The complexities of DNS (Domain Name System) and IP routing have \"leaked\" through the abstraction of the web browser.\n",
        "\n",
        "#### c. **Driving a Car**:\n",
        "Even with our car example, while you don't need to know how the engine works, sometimes you might have to deal with issues like the car not starting because the battery is dead. The abstraction of \"just driving\" leaks when you have to jump-start the car.\n",
        "\n",
        "### 5. Why Does It Matter?\n",
        "\n",
        "Understanding that abstractions can be leaky is crucial because it reminds developers, engineers, and users that no system is perfect. At times, you'll have to deal with the underlying complexities. It's a call to be prepared for unexpected challenges and to have a foundational understanding of the systems you're working with, even if they're abstracted away most of the time.\n",
        "\n",
        "[The problem with Backpropagation is that it is a leaky abstraction](https://karpathy.medium.com/yes-you-should-understand-backprop-e2f06eab496b)\n"
      ],
      "metadata": {
        "id": "LCs3TnXH0E3t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Summary of transcript"
      ],
      "metadata": {
        "id": "-zpZ74LjU4s9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "### Importance of Understanding Backpropagation\n",
        "\n",
        "The lecturer emphasizes the significance of understanding backpropagation, even in the age of auto-differentiation tools like PyTorch's autograd. Backpropagation is not just a magical tool that makes neural networks work; it requires a deep comprehension to ensure optimal functionality.\n",
        "\n",
        "### Backpropagation as a \"Leaky Abstraction\"\n",
        "\n",
        "The term \"leaky abstraction\" refers to the idea that without understanding its internals, backpropagation might not work optimally or could fail altogether. There are potential pitfalls:\n",
        "- Saturating functions too much can cause gradients to vanish.\n",
        "- Dead neurons in the network.\n",
        "- Issues with exploding or vanishing gradients, especially with recurrent neural networks.\n",
        "- Subtle bugs that arise from misunderstandings about backpropagation.\n",
        "\n",
        "It's important to note that simply stacking differentiable functions and hoping backpropagation will handle everything isn't a guaranteed strategy for success.\n",
        "\n",
        "### Historical Context: Manual Backpropagation\n",
        "\n",
        "Historically, manually writing the backward pass (calculating gradients) was the norm. About a decade ago, it was standard practice to hand-write the backward pass rather than relying on auto-differentiation tools. The lecturer mentions:\n",
        "- The use of MATLAB for deep learning, highlighting how the field's toolset has evolved.\n",
        "- The manual calculation of gradients in earlier research work, emphasizing that understanding gradients and backpropagation was crucial.\n",
        "\n",
        "This hands-on approach ensured that practitioners had a deep, intuitive understanding of how neural networks operated.\n",
        "\n",
        "## Implementing Backward Pass Manually\n",
        "\n",
        "The lecturer provides a walkthrough of implementing the backward pass manually, emphasizing its educational value:\n",
        "- By implementing the backward pass, learners will get a more explicit understanding of the underlying processes, removing any hidden \"magic\".\n",
        "- This understanding aids in debugging neural networks and ensuring that learners know exactly what is happening under the hood.\n",
        "\n",
        "### Exercise Structure\n",
        "\n",
        "The exercises in the lecture are structured to gradually introduce the concepts:\n",
        "1. Full breakdown of the loss and manual backpropagation through each segment.\n",
        "2. Collapsing the loss into a single cross-entropy call and deriving the gradient analytically.\n",
        "3. Analytical gradient derivation for batch normalization.\n",
        "4. Combining all the pieces to train a two-layer MLP without relying on `loss.backward()` from PyTorch.\n",
        "\n",
        "### Pedagogical Approach\n",
        "\n",
        "The lecturer recommends a hands-on approach to learning:\n",
        "- Learners should first try to implement the derivatives or gradients themselves.\n",
        "- Then, they can refer to the lecturer's video to compare and understand the solutions.\n",
        "\n",
        "## Conclusion\n",
        "\n",
        "Understanding the intricacies of backpropagation is crucial for anyone diving deep into neural networks. While modern tools simplify the process, having a foundational grasp ensures better problem-solving skills, debugging capabilities, and a deeper appreciation for the complexities of neural network training.\n",
        "\n",
        "---\n",
        "\n",
        "### Backpropagation in Neural Networks\n",
        "\n",
        "The lecturer is diving deep into the concept of backpropagation in neural networks, specifically focusing on how to compute the gradients of different components of a network with respect to the loss. This is essential for training neural networks using optimization algorithms like gradient descent.\n",
        "\n",
        "### Importance of Matching Shapes\n",
        "\n",
        "When backpropagating, it's crucial to ensure that the shapes (dimensions) of tensors match up correctly, especially when broadcasting is involved. Broadcasting is a technique in PyTorch (and other deep learning frameworks) that allows tensors of different shapes to be combined in operations by implicitly expanding dimensions.\n",
        "\n",
        "### Deriving Gradients for Softmax and Log Probabilities\n",
        "\n",
        "- **Log Probabilities**: The gradient of the log probabilities, `d_log_probs`, is derived with respect to the loss. The shape of `log_probs` and `d_log_probs` will be the same.\n",
        "  \n",
        "- **Softmax Operation**: For numerical stability, it's common to subtract the maximum value from logits before exponentiating them in the softmax. This ensures that exponentiating doesn't result in extremely large values, which can cause numerical overflow.\n",
        "\n",
        "### Element-wise Operations\n",
        "\n",
        "Operations that are element-wise, like the log and exponentiation, have gradients that can be computed element-wise. For example, the gradient of the natural log is \\( $\\frac{1}{x} $\\).\n",
        "\n",
        "### Chain Rule\n",
        "\n",
        "The chain rule is a fundamental concept in calculus used extensively in backpropagation. It allows the derivation of the gradient of composed functions. In the context of neural networks, it's used to compute the gradient of the loss with respect to any given parameter by multiplying the gradients of all operations that connect the loss to that parameter.\n",
        "\n",
        "### Broadcasting and Replication\n",
        "\n",
        "When dealing with tensors of mismatched dimensions, one tensor may need to be broadcasted (replicated) to match the shape of the other. It's essential to handle the backpropagation correctly in these cases. For example, when backpropagating through a multiplication where broadcasting occurred, the gradients might need to be summed across certain dimensions.\n",
        "\n",
        "### Gradient Checking\n",
        "\n",
        "The lecturer uses a method called `CMP` to compare the manually computed gradients with those computed automatically by PyTorch. This is a form of gradient checking, ensuring that the manual backpropagation is implemented correctly.\n",
        "\n",
        "### Importance of Numerical Stability\n",
        "\n",
        "For certain operations, especially those involving exponentials, it's essential to ensure numerical stability. This might involve subtracting the maximum value from a set of numbers before exponentiating them, which won't change the result due to the properties of exponentiation but will prevent potential numerical issues.\n",
        "\n",
        "### Key Takeaways\n",
        "\n",
        "1. **Backpropagation** is the process of computing the gradient of the loss with respect to every parameter in a neural network.\n",
        "2. The **chain rule** is fundamental for backpropagation in neural networks.\n",
        "3. Ensuring the correct tensor **shapes** and handling **broadcasting** is crucial.\n",
        "4. **Numerical stability** is essential, especially for operations that can produce large values, like exponentiation.\n",
        "5. **Gradient checking** by comparing manual gradients to those produced by a framework (like PyTorch) is a good practice to ensure the correctness of the backpropagation implementation.\n",
        "\n",
        "---\n",
        "\n",
        "### Understanding Backpropagation with Matrix Calculus\n",
        "\n",
        "#### 1. Linear Layer Backpropagation\n",
        "- The output of a linear layer, termed `logits`, is computed using matrix multiplication and an added bias.\n",
        "- When examining the shapes of intermediate tensors, the bias vector undergoes broadcasting during addition to match the shape of the matrix multiplication result.\n",
        "- To understand the backward pass, the approach recommended is to break down matrix operations to simpler scalar operations and then generalize them. This demystifies complex matrix derivatives into understandable scalar operations.\n",
        "  \n",
        "#### 2. Breaking Down Matrix Multiplication\n",
        "- In breaking down matrix multiplication, each element of the resultant matrix is computed as a dot product of a row of the first matrix with a column of the second.\n",
        "- To compute the gradient of the resultant matrix with respect to the elements of the original matrices, the chain rule is used. This involves computing local derivatives and using the incoming gradient.\n",
        "- It was shown that the gradient with respect to one matrix is the dot product of the incoming gradient and the transpose of the other matrix.\n",
        "\n",
        "#### 3. Understanding Broadcasting in Gradients\n",
        "- Broadcasting refers to the operation of expanding dimensions of tensors to perform element-wise operations.\n",
        "- When backpropagating, the broadcasting operation needs to be reversed. This often involves summing over the axis that was expanded.\n",
        "- It's essential to ensure tensor shape consistency during backpropagation, especially when working with broadcasting.\n",
        "\n",
        "#### 4. Backpropagation through Activation Functions\n",
        "- For the `tanh` activation function, its derivative with respect to its input can be expressed in terms of its output: \\($1 - \\text{output}^2$\\).\n",
        "- This derivative is crucial for backpropagation as it scales the incoming gradient.\n",
        "  \n",
        "#### 5. Backpropagation through Batch Normalization\n",
        "- Batch normalization involves standardizing the input data and then scaling and shifting it using learnable parameters.\n",
        "- The backpropagation through the scaling and shifting is straightforward, but the backpropagation through the standardization involves more steps.\n",
        "- It was highlighted that the variance computation in the forward pass used Bessel's correction (dividing by \\(N-1\\) instead of \\(N\\)). This affects the backward pass computations.\n",
        "- The power rule of differentiation is used for backpropagating through the inverse square root in the standardization step.\n",
        "\n",
        "#### Key Takeaways:\n",
        "- Understanding the essence of matrix operations and broadcasting is vital for effective backpropagation in neural networks.\n",
        "- By breaking complex operations into simpler scalar ones, the process of backpropagation becomes more intuitive.\n",
        "- Ensuring tensor shape consistency is crucial, and often the shapes alone can guide the backpropagation steps.\n",
        "- Activation functions and normalization layers introduce non-linearities, and understanding their derivatives is essential for backpropagation.\n",
        "\n",
        "---\n",
        "\n",
        "**Bessel's Correction in Batch Normalization**\n",
        "\n",
        "The lecturer introduces a topic called Bessel's correction, which is used in the context of batch normalization in neural networks.\n",
        "\n",
        "- **Variance Estimation**:\n",
        "  - There are two ways to estimate the variance of an array:\n",
        "    1. Biased estimate: \\( $\\frac{1}{n}$ \\)\n",
        "    2. Unbiased estimate: \\($ \\frac{1}{n - 1} $\\)\n",
        "  - The original paper on batch normalization used the biased version for training but switched to the unbiased version for inference. This introduces a discrepancy between training and testing (inference) time.\n",
        "  - Bessel's correction (unbiased estimate) is particularly useful for small sample sizes. In the context of neural networks, mini-batches represent small samples from the larger dataset. Using the biased version \\( $\\frac{1}{n} $\\) often underestimates the variance.\n",
        "\n",
        "**Batch Normalization Implementation Issues**\n",
        "\n",
        "The lecturer highlighted some ambiguities and potential issues in popular implementations:\n",
        "\n",
        "- **Documentation Issues**: The documentation of certain neural network frameworks might be misleading or incorrect regarding the use of biased or unbiased estimators in batch normalization.\n",
        "  \n",
        "- **Train-Test Mismatch**: The discrepancy in using biased estimators during training and unbiased estimators during inference is seen as problematic. Such mismatches can lead to inconsistencies in the model's performance.\n",
        "\n",
        "- **Recommendation**: Consistency is key. The lecturer advises using the unbiased estimator both during training and inference for more consistent results.\n",
        "\n",
        "**Backpropagation Through Various Layers**\n",
        "\n",
        "The lecturer then transitions into the topic of backpropagation, explaining how to compute gradients for various layers and operations:\n",
        "\n",
        "- **Linear Layers**:\n",
        "  - Derivatives for linear layers can be computed by matching shapes and considering matrix multiplication operations.\n",
        "  \n",
        "- **Indexing Operations**:\n",
        "  - The process involves routing gradients backward through the indices used in the forward pass. If an index was used multiple times, the gradients are accumulated at that index.\n",
        "\n",
        "- **Understanding Shapes**:\n",
        "  - When backpropagating, understanding the shapes of tensors is crucial. Operations like broadcasting in the forward pass translate to sums in the backward pass, and vice versa.\n",
        "\n",
        "- **Practical Tips**:\n",
        "  - It's essential to always scrutinize tensor shapes first.\n",
        "  - Replications in the forward pass become sums in the backward pass and vice versa.\n",
        "  - Use simple toy examples in one's mind to understand the flow of gradients.\n",
        "\n",
        "**Conclusion**\n",
        "\n",
        "Understanding the intricacies of operations like batch normalization and mastering the art of backpropagation are critical for anyone delving into neural networks. The lecturer emphasizes the importance of consistency in implementation and a deep understanding of the underlying math to ensure optimal network performance.\n",
        "\n",
        "---\n",
        "\n",
        "The lecturer is explaining the intricacies of backpropagation and the optimization of neural networks, specifically focusing on the backward pass through the cross-entropy loss and batch normalization layers. Here's a summary of the main points:\n",
        "\n",
        "1. **Cross-Entropy Loss Backward Pass**:\n",
        "    - The lecturer emphasizes that there's often a more efficient way to compute the gradients than by breaking the operation down into its smallest pieces.\n",
        "    - Using the mathematical expression for the loss, one can differentiate it, and many terms will cancel out, leading to a simpler expression for the gradient.\n",
        "    - The gradient of the loss with respect to the logits (input to the softmax function) has an intuitive interpretation: It pushes the probabilities of incorrect predictions down and the probabilities of correct predictions up.\n",
        "\n",
        "2. **Batch Normalization Backward Pass**:\n",
        "    - The lecturer explains the batch normalization backward pass, detailing the mathematical formula for deriving the gradients.\n",
        "    - For simplification, the lecturer ignores the gamma and beta parameters of batch normalization.\n",
        "    - The gradients are derived by considering the forward pass's entire operation and differentiating it.\n",
        "    - The lecturer emphasizes the importance of understanding the difference between vectors and scalars in the context of the batch normalization layer.\n",
        "\n",
        "3. **Putting it All Together**:\n",
        "    - The aim is to replace the automatic differentiation provided by the `loss.backward()` function with manually computed gradients.\n",
        "    - By doing this, one gains full visibility and understanding of the backward pass.\n",
        "    - The gradients computed manually are verified against those computed by PyTorch to ensure correctness.\n",
        "    \n",
        "This lecture provides a deep dive into understanding backpropagation through specific layers, aiming to give students a clear understanding of the mathematical underpinnings and the computational steps involved. The exercises provide hands-on practice, reinforcing the theoretical concepts.\n",
        "\n"
      ],
      "metadata": {
        "id": "rBgpH0OlU7s6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Most important sections of our model to understand\n",
        "\n",
        "To develop a solid intuition about backpropagation in neural networks, it's important to understand both the individual components of a network and how gradients flow through those components. From the given lines, here are the most critical sections to grasp, along with a brief reasoning:\n",
        "\n",
        "1. **Linear Layers**:\n",
        "   - $ hprebn = \\text{embcat} @ W1 + b1 $\n",
        "   - $ \\text{logits} = h @ W2 + b2 $\n",
        "   \n",
        "   **Why**: Linear layers (or fully connected layers) are foundational to neural networks. They apply affine transformations to the input, and understanding how gradients flow through weights and biases is fundamental.\n",
        "\n",
        "2. **BatchNorm Layer**:\n",
        "   - $ \\text{bnmeani}, \\text{bndiff}, \\text{bndiff2}, \\text{bnvar}, \\text{bnvar_inv}, \\text{bnraw}, \\text{hpreact} $\n",
        "   \n",
        "   **Why**: Batch normalization is a technique that helps in stabilizing and accelerating the training of deep networks. It does so by normalizing the activations of each input batch. Grasping the gradient flow here is crucial since BN introduces several intermediate steps and parameters that get optimized during training.\n",
        "\n",
        "3. **Activation Function**:\n",
        "   - $ h = \\text{torch.tanh}(hpreact) $\n",
        "   \n",
        "   **Why**: Activation functions introduce non-linearities, which enable the network to learn more complex representations. Understanding the derivative of activation functions is essential since they are applied element-wise and can significantly influence the gradient during backpropagation.\n",
        "\n",
        "4. **Loss Calculation**:\n",
        "   - $ \\text{logit_maxes}, \\text{norm_logits}, \\text{counts}, \\text{probs}, \\text{logprobs}, \\text{loss} $\n",
        "   \n",
        "   **Why**: The loss function quantifies how well the network's predictions match the actual targets. It's the starting point for backpropagation. Understanding how the loss is computed and how its gradient is determined with respect to the network's outputs is key to grasping backpropagation.\n",
        "\n",
        "5. **Embedding Layer**:\n",
        "   - $ \\text{emb} = C[Xb] $\n",
        "   \n",
        "   **Why**: Embeddings transform discrete data (like words or characters) into continuous vectors. The gradient flow here is slightly different from other layers due to the indexing operation.\n",
        "\n",
        "While the other lines, like reshaping operations, are also important for a complete understanding, they are more straightforward when it comes to backpropagation. The mentioned sections are the ones where deeper intuition about gradient flow can be especially beneficial."
      ],
      "metadata": {
        "id": "NblmrPeRKQEB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset processing\n"
      ],
      "metadata": {
        "id": "u7akS-071XWS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt # for making figures\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "KtzG6NSV1c4k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/karpathy/makemore/master/names.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XD6AOD3J111x",
        "outputId": "9351736f-a3f5-4078-8d00-30c73cf0b849"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-08-25 08:30:31--  https://raw.githubusercontent.com/karpathy/makemore/master/names.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 228145 (223K) [text/plain]\n",
            "Saving to: ‘names.txt’\n",
            "\n",
            "names.txt           100%[===================>] 222.80K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2023-08-25 08:30:31 (6.83 MB/s) - ‘names.txt’ saved [228145/228145]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# read in all the words\n",
        "words = open('names.txt', 'r').read().splitlines()\n",
        "print(len(words))\n",
        "print(max(len(w) for w in words))\n",
        "print(words[:8])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "odNw02wd1fuc",
        "outputId": "909dd69a-dc3e-4a31-d10a-d9ed9be1cf76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32033\n",
            "15\n",
            "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# build the vocabulary of characters and mappings to/from integers\n",
        "chars = sorted(list(set(''.join(words))))\n",
        "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
        "stoi['.'] = 0\n",
        "itos = {i:s for s,i in stoi.items()}\n",
        "vocab_size = len(itos)\n",
        "print(itos)\n",
        "print(vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ahC8NWTV1iB4",
        "outputId": "67990eee-1443-47b0-e830-0b13187a5136"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: '.'}\n",
            "27\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# build the dataset\n",
        "block_size = 3 # context length: how many characters do we take to predict the next one?\n",
        "\n",
        "def build_dataset(words):\n",
        "  X, Y = [], []\n",
        "\n",
        "  for w in words:\n",
        "    context = [0] * block_size\n",
        "    for ch in w + '.':\n",
        "      ix = stoi[ch]\n",
        "      X.append(context)\n",
        "      Y.append(ix)\n",
        "      context = context[1:] + [ix] # crop and append\n",
        "\n",
        "  X = torch.tensor(X)\n",
        "  Y = torch.tensor(Y)\n",
        "  print(X.shape, Y.shape)\n",
        "  return X, Y\n",
        "\n",
        "import random\n",
        "random.seed(42)\n",
        "random.shuffle(words)\n",
        "n1 = int(0.8*len(words))\n",
        "n2 = int(0.9*len(words))\n",
        "\n",
        "Xtr,  Ytr  = build_dataset(words[:n1])     # 80%\n",
        "Xdev, Ydev = build_dataset(words[n1:n2])   # 10%\n",
        "Xte,  Yte  = build_dataset(words[n2:])     # 10%"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gla74CVa1kdr",
        "outputId": "7d8f6321-cc10-4165-b00b-956345fce08a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([182625, 3]) torch.Size([182625])\n",
            "torch.Size([22655, 3]) torch.Size([22655])\n",
            "torch.Size([22866, 3]) torch.Size([22866])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initial code"
      ],
      "metadata": {
        "id": "RRFO-n0g2Nna"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Code in terms of tensor sizes and layers:\n",
        "\n",
        "1. **Embedding Layer**:\n",
        "   ```python\n",
        "   emb = C[Xb] # embed the characters into vectors\n",
        "   ```\n",
        "   Here, `Xb` represents the indices of the batch characters. If `Xb` has a shape of `(batch_size, sequence_length)`, then after this step, `emb` would have a shape of `(batch_size, sequence_length, n_embd)` where `n_embd` is the size of each embedding vector.\n",
        "\n",
        "2. **Reshaping the Embeddings**:\n",
        "   ```python\n",
        "   embcat = emb.view(emb.shape[0], -1) # concatenate the vectors\n",
        "   ```\n",
        "   This reshapes the tensor to concatenate all the embeddings in the sequence for each batch. The resulting shape of `embcat` is `(batch_size, sequence_length * n_embd)`.\n",
        "\n",
        "3. **Linear Layer 1**:\n",
        "   ```python\n",
        "   hprebn = embcat @ W1 + b1 # hidden layer pre-activation\n",
        "   ```\n",
        "   The matrix multiplication `@` denotes the linear transformation. If `W1` has a shape of `(sequence_length * n_embd, n_hidden)`, `hprebn` will have a shape of `(batch_size, n_hidden)`.\n",
        "\n",
        "4. **Batch Normalization Layer**:\n",
        "   ```python\n",
        "   bnmeani = 1/n*hprebn.sum(0, keepdim=True)\n",
        "   ...\n",
        "   hpreact = bngain * bnraw + bnbias\n",
        "   ```\n",
        "   This block is implementing batch normalization. It first computes the mean and variance across the batch dimension (0th dimension). The resulting shape of tensors like `bnmeani`, `bnvar`, etc., is `(1, n_hidden)`. The output `hpreact` also has the shape `(batch_size, n_hidden)`.\n",
        "\n",
        "5. **Non-linearity (Tanh Activation)**:\n",
        "   ```python\n",
        "   h = torch.tanh(hpreact) # hidden layer\n",
        "   ```\n",
        "   This applies the Tanh activation to each element of the tensor. The shape remains unchanged: `(batch_size, n_hidden)`.\n",
        "\n",
        "6. **Linear Layer 2**:\n",
        "   ```python\n",
        "   logits = h @ W2 + b2 # output layer\n",
        "   ```\n",
        "   This is another linear transformation. If `W2` has a shape of `(n_hidden, vocab_size)`, then `logits` will have a shape of `(batch_size, vocab_size)`.\n",
        "\n",
        "7. **Cross Entropy Loss Calculation**:\n",
        "   ```python\n",
        "   ...\n",
        "   loss = -logprobs[range(n), Yb].mean()\n",
        "   ```\n",
        "   This block computes the cross-entropy loss. It first computes the probabilities using the logits, then calculates the logarithm of those probabilities, and finally computes the negative log likelihood for the true labels in `Yb`. The final `loss` is a scalar value.\n",
        "\n",
        "Throughout this code, the neural network consists of two linear layers with a batch normalization and Tanh activation in between. The input to this network is character indices, and it outputs logits for each character in the vocabulary. The loss represents how well the network's predictions align with the true labels."
      ],
      "metadata": {
        "id": "_uC7ME-YOYb0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# utility function we will use later when comparing manual gradients to PyTorch gradients\n",
        "def cmp(s, dt, t):\n",
        "  ex = torch.all(dt == t.grad).item()\n",
        "  app = torch.allclose(dt, t.grad)\n",
        "  maxdiff = (dt - t.grad).abs().max().item()\n",
        "  print(f'{s:15s} | exact: {str(ex):5s} | approximate: {str(app):5s} | maxdiff: {maxdiff}')"
      ],
      "metadata": {
        "id": "R4wCtoeU2QSP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# the initialization\n",
        "\n",
        "n_embd = 10 # the dimensionality of the character embedding vectors\n",
        "n_hidden = 64 # the number of neurons in the hidden layer of the MLP\n",
        "\n",
        "g = torch.Generator().manual_seed(2147483647) # for reproducibility\n",
        "C  = torch.randn((vocab_size, n_embd),            generator=g)\n",
        "# Layer 1\n",
        "W1 = torch.randn((n_embd * block_size, n_hidden), generator=g) * (5/3)/((n_embd * block_size)**0.5)\n",
        "b1 = torch.randn(n_hidden,                        generator=g) * 0.1 # using b1 just for fun, it's useless because of BN\n",
        "# Layer 2\n",
        "W2 = torch.randn((n_hidden, vocab_size),          generator=g) * 0.1\n",
        "b2 = torch.randn(vocab_size,                      generator=g) * 0.1\n",
        "# BatchNorm parameters\n",
        "bngain = torch.randn((1, n_hidden))*0.1 + 1.0\n",
        "bnbias = torch.randn((1, n_hidden))*0.1\n",
        "\n",
        "# Note: I am initializating many of these parameters in non-standard ways\n",
        "# because sometimes initializating with e.g. all zeros could mask an incorrect\n",
        "# implementation of the backward pass.\n",
        "\n",
        "parameters = [C, W1, b1, W2, b2, bngain, bnbias]\n",
        "print(sum(p.nelement() for p in parameters)) # number of parameters in total\n",
        "for p in parameters:\n",
        "  p.requires_grad = True"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A_Q8W1kQ2Smz",
        "outputId": "045aaf35-da6e-4cef-8311-a55eae187413"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4137\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "n = batch_size # a shorter variable also, for convenience\n",
        "# construct a minibatch\n",
        "ix = torch.randint(0, Xtr.shape[0], (batch_size,), generator=g)\n",
        "Xb, Yb = Xtr[ix], Ytr[ix] # batch X,Y"
      ],
      "metadata": {
        "id": "Iz7NPv9N2Vpp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# forward pass, \"chunkated\" into smaller steps that are possible to backward one at a time\n",
        "\n",
        "emb = C[Xb] # embed the characters into vectors\n",
        "# shape (batch_size, sequence_length, n_embd)\n",
        "embcat = emb.view(emb.shape[0], -1) # concatenate the vectors\n",
        "# shape (batch_size, sequence_length * n_embd)\n",
        "\n",
        "# Linear layer 1\n",
        "hprebn = embcat @ W1 + b1 # hidden layer pre-activation\n",
        "# shape (batch_size, n_hidden)\n",
        "\n",
        "# BatchNorm layer\n",
        "# all shape (1, n_hidden)\n",
        "bnmeani = 1/n*hprebn.sum(0, keepdim=True)\n",
        "bndiff = hprebn - bnmeani\n",
        "bndiff2 = bndiff**2\n",
        "bnvar = 1/(n-1)*(bndiff2).sum(0, keepdim=True) # note: Bessel's correction (dividing by n-1, not n)\n",
        "bnvar_inv = (bnvar + 1e-5)**-0.5\n",
        "bnraw = bndiff * bnvar_inv\n",
        "hpreact = bngain * bnraw + bnbias\n",
        "# shape (batch_size, n_hidden)\n",
        "\n",
        "# Non-linearity\n",
        "h = torch.tanh(hpreact) # hidden layer\n",
        "# shape (batch_size, n_hidden)\n",
        "\n",
        "# Linear layer 2\n",
        "logits = h @ W2 + b2 # output layer\n",
        "# shape (batch_size, vocab_size) until loss\n",
        "\n",
        "# cross entropy loss (same as F.cross_entropy(logits, Yb))\n",
        "logit_maxes = logits.max(1, keepdim=True).values\n",
        "norm_logits = logits - logit_maxes # subtract max for numerical stability\n",
        "counts = norm_logits.exp()\n",
        "counts_sum = counts.sum(1, keepdims=True)\n",
        "counts_sum_inv = counts_sum**-1 # if I use (1.0 / counts_sum) instead then I can't get backprop to be bit exact...\n",
        "probs = counts * counts_sum_inv\n",
        "logprobs = probs.log()\n",
        "loss = -logprobs[range(n), Yb].mean()\n",
        "\n",
        "# PyTorch backward pass\n",
        "for p in parameters:\n",
        "  p.grad = None\n",
        "for t in [logprobs, probs, counts, counts_sum, counts_sum_inv, # afaik there is no cleaner way\n",
        "          norm_logits, logit_maxes, logits, h, hpreact, bnraw,\n",
        "         bnvar_inv, bnvar, bndiff2, bndiff, hprebn, bnmeani,\n",
        "         embcat, emb]:\n",
        "  t.retain_grad()\n",
        "loss.backward()\n",
        "loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ty7Rnaoe2Yjl",
        "outputId": "4bf73e3d-ab91-488c-a373-d21a943ca682"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(3.3311, grad_fn=<NegBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise 1 - Full manual backpropagation"
      ],
      "metadata": {
        "id": "dwG3g1_i282E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# `loss = -logprobs[range(n), Yb].mean()`"
      ],
      "metadata": {
        "id": "HgTq-qL9b9Rf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# dlogprobs'\n",
        "# the derivative of the loss with respect to all the elements of logprobs\n",
        "logprobs.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yFLP6GFfRJ2Y",
        "outputId": "7baf2aae-b46b-4adf-b570-295e624cf484"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 27])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# how does logprobs influence the loss?"
      ],
      "metadata": {
        "id": "OfZNTzySTA-d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Yb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "riWMbEGdTKug",
        "outputId": "3f79d4c2-f2e4-4b96-f265-8b926775ee21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 8, 14, 15, 22,  0, 19,  9, 14,  5,  1, 20,  3,  8, 14, 12,  0, 11,  0,\n",
              "        26,  9, 25,  0,  1,  1,  7, 18,  9,  3,  5,  9,  0, 18])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we go thru logprobs and pluck out each value for the label\n",
        "# in the 1st row, we pluck out the 8th column, in the 2nd row the 14th\n",
        "\n",
        "# note: most of the numbers in logprobs don't feed into the loss\n",
        "\n",
        "logprobs[range(n), Yb]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tgKesBniTYHB",
        "outputId": "a8f4945e-18fe-4b03-c697-0f3a30f3c1c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-3.9610, -3.0589, -3.6174, -3.2058, -4.0509, -3.4809, -3.1225, -4.0152,\n",
              "        -3.1346, -4.3416, -3.1203, -1.6839, -2.9063, -2.9989, -3.0348, -3.1512,\n",
              "        -3.9487, -3.0216, -3.5779, -3.3511, -2.7952, -2.9755, -4.3747, -4.0977,\n",
              "        -3.4259, -2.9108, -2.9984, -3.8807, -2.7792, -3.3784, -3.2305, -3.2076],\n",
              "       grad_fn=<IndexBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logprobs[range(n), Yb].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U8cLAyvhT42k",
        "outputId": "fe52d0a3-00ca-4641-d46e-738482c91eba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# loss = 1(a + b + c) / 3\n",
        "# loss = -1/3a + -1/b3 + -1/3c\n",
        "# dloss/da = -1/3\n",
        "# dloss/da = -1/n\n",
        "# dloss/dlogprobs =\n",
        "\n",
        "dlogprobs = torch.zeros_like(logprobs)\n",
        "dlogprobs[range(n), Yb] = -1.0/n\n",
        "\n",
        "cmp('logprobs', dlogprobs, logprobs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tnn-9bktUGVZ",
        "outputId": "922e1cbd-15a0-4eeb-ac2b-f9155574bb2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "logprobs        | exact: True  | approximate: True  | maxdiff: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## `dlogprobs`\n",
        "\n",
        "To understand the process of finding the gradient \\( $\\frac{\\partial \\text{loss}}{\\partial \\text{logprobs}} $\\), often referred to as `dlogprobs`.\n",
        "\n",
        "### Cross Entropy Loss\n",
        "\n",
        "The code is computing the cross-entropy loss, which is defined for a classification problem as:\n",
        "\n",
        "$$\n",
        "\\text{loss} = - \\frac{1}{N} \\sum_{i=1}^{N} \\log(p_{y_i})\n",
        "$$\n",
        "\n",
        "Where:\n",
        "- \\( N \\) is the batch size.\n",
        "- \\( $p_{y_i} $\\) is the predicted probability of the true label \\( $y_i$ \\) for the \\( i \\)-th data point.\n",
        "\n",
        "In terms of the code:\n",
        "1. `logits`: Raw scores (before softmax) for each class.\n",
        "2. `norm_logits`: These are the logits normalized by subtracting the max value for numerical stability.\n",
        "3. `counts`: This is equivalent to the exponential of the normalized logits, i.e., \\( $e^{\\text{norm\\_logits}}$ \\).\n",
        "4. `counts_sum`: Sum of `counts` across classes, which acts as the denominator in the softmax function.\n",
        "5. `probs`: Normalized probabilities using the softmax function.\n",
        "6. `logprobs`: Log of these probabilities.\n",
        "7. `loss`: The negative log likelihood of the true labels averaged over the batch.\n",
        "\n",
        "### Finding `dlogprobs`\n",
        "\n",
        "Given the definition of the loss, we can say for each data point in the batch:\n",
        "\n",
        "$$\n",
        "\\frac{\\partial \\text{loss}}{\\partial \\log(p_{y_i})} = - \\frac{1}{N}\n",
        "$$\n",
        "\n",
        "For all the other log probabilities \\( $\\log(p_j)$ \\) where \\( $j \\neq y_i$ \\):\n",
        "\n",
        "$$\n",
        "\\frac{\\partial \\text{loss}}{\\partial \\log(p_j)} = 0\n",
        "$$\n",
        "\n",
        "This is because the loss is only affected by the log probability of the true class.\n",
        "\n",
        "So, in terms of code, to compute `dlogprobs` for the entire batch:\n",
        "\n",
        "1. Initialize a tensor of zeros with the same shape as `logprobs`.\n",
        "2. For each data point in the batch, set the value at the index of the true label to \\( $-\\frac{1}{N} $\\).\n",
        "\n",
        "This gives you \\( $\\frac{\\partial \\text{loss}}{\\partial \\text{logprobs}} $\\) for the entire batch, which is your `dlogprobs`.\n",
        "\n",
        "Certainly! Let's simplify that explanation.\n",
        "\n",
        "### Understanding `dlogprobs`\n",
        "\n",
        "Think of `dlogprobs` as measuring how much the loss changes when we make tiny changes to our predicted log probabilities.\n",
        "\n",
        "For each data point:\n",
        "- If the log probability (`logprobs`) belongs to the true class, a tiny change in it will change our loss by \\($-\\frac{1}{N}$\\). \\($N$\\) is the number of data points in our batch.\n",
        "- For log probabilities of all other classes (not the true class), a tiny change in them won't affect our loss at all. So, the change is 0.\n",
        "\n",
        "When we try to represent this in code:\n",
        "1. Start with an array (or tensor) filled with zeros that has the same size as `logprobs`.\n",
        "2. For every data point, find the true class's position and put \\($-\\frac{1}{N}$\\) there.\n",
        "\n",
        "The resulting array is what we call `dlogprobs`. It tells us the sensitivity of our loss to changes in `logprobs`."
      ],
      "metadata": {
        "id": "D6l_aOMjXbhy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# `logprobs = probs.log()`"
      ],
      "metadata": {
        "id": "2OjS-sytcGPX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[d/dx log(x) = 1/x](https://www.wolframalpha.com/input?i=d%2Fdx+log%28x%29)"
      ],
      "metadata": {
        "id": "JA9PH1FHcq0q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# d/dx log(x) = 1/x\n",
        "# chain rule\n",
        "dprobs = (1/probs) * dlogprobs\n",
        "cmp('probs', dprobs, probs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JqIOx9kBcH_S",
        "outputId": "63699396-4045-4384-e998-6bc03ba27ca2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "probs           | exact: True  | approximate: True  | maxdiff: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Finding `dprobs`\n",
        "\n",
        "The relationship between `probs` and `logprobs` is given by the logarithm function. Specifically, $ \\text{logprobs} = \\log(\\text{probs}) $.\n",
        "\n",
        "So, how do changes in `probs` affect `logprobs`? The derivative of the natural logarithm function gives us the answer:\n",
        "\n",
        "$$\n",
        "\\frac{\\partial \\log(p)}{\\partial p} = \\frac{1}{p}\n",
        "$$\n",
        "\n",
        "Using this relationship, we can find how `logprobs` changes with respect to `probs`.\n",
        "\n",
        "### Breaking it Down:\n",
        "\n",
        "1. **Start with the Chain Rule:** We already know how our loss changes with respect to `logprobs` (this is `dlogprobs`). To find how the loss changes with respect to `probs` (which is `dprobs`), we need to use the chain rule:\n",
        "\n",
        "$$\n",
        "\\frac{\\partial \\text{loss}}{\\partial \\text{probs}} = \\frac{\\partial \\text{loss}}{\\partial \\text{logprobs}} \\times \\frac{\\partial \\text{logprobs}}{\\partial \\text{probs}}\n",
        "$$\n",
        "\n",
        "Here, the second part is $\\frac{1}{\\text{probs}}$ as per the logarithm derivative.\n",
        "\n",
        "2. **Compute `dprobs`:** Multiply `dlogprobs` by the inverse of `probs` element-wise. This gives you `dprobs`.\n",
        "\n",
        "In simpler terms:\n",
        "\n",
        "- We already know how tiny changes in `logprobs` affect our loss (from `dlogprobs`).\n",
        "- For each probability in `probs`, we find out how a tiny change in it would change its corresponding `logprobs` (which is just the inverse of that probability).\n",
        "- To find out how a tiny change in `probs` affects the loss, we multiply these two values together.\n",
        "\n",
        "The resulting value gives us `dprobs`, which tells us the sensitivity of our loss to changes in `probs`."
      ],
      "metadata": {
        "id": "PNJFRkzIdeFr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Understanding the Behavior of `dprobs`:\n",
        "\n",
        "1. **Behavior at High Confidence:**\n",
        "    - When the network is confident about its prediction, the predicted probability (`probs`) for the correct class is close to 1.\n",
        "    - In the gradient computation, this translates to dividing by a value close to 1, because \\(\\frac{\\partial \\log(p)}{\\partial p} = \\frac{1}{p} \\).\n",
        "    - d log(p)/dp = 1/p\n",
        "    - Thus, the gradient `dlogprobs` is roughly passed through as-is, without significant amplification or attenuation. This means that when the network is confident and correct, the adjustments made during the backpropagation process are moderate.\n",
        "\n",
        "2. **Behavior at Low Confidence:**\n",
        "    - When the network is not confident or is mistaken in its prediction, the predicted probability for the correct class is low, much less than 1.\n",
        "    - This results in a larger value when computing the gradient, as you're essentially dividing by a small number.\n",
        "    - The effect of this is to amplify the gradient for examples where the network's prediction is far from the correct answer. This means the network gets a stronger \"signal\" or \"nudge\" to adjust its weights for such examples.\n",
        "\n",
        "3. **Intuitive Interpretation:**\n",
        "    - The gradient amplification for low-confidence predictions can be thought of as the network's mechanism to pay more attention to its mistakes. It's a way for the network to focus its learning efforts on examples it's currently getting wrong, thus driving improvement in subsequent iterations.\n",
        "    - In other words, the network is \"punishing\" itself more for being wrong on certain examples, thereby learning to correct its mistakes more aggressively.\n",
        "\n",
        "4. **Importance in Training Dynamics:**\n",
        "    - This behavior is crucial for the adaptive nature of neural networks. By dynamically adjusting the gradient based on the network's confidence, we ensure that the network doesn't become complacent with its predictions. Instead, it continually strives to correct its errors, leading to better generalization and performance.\n",
        "\n",
        "In essence, this gradient adjustment mechanism is a form of adaptive learning, ensuring that the network focuses on its weaknesses and continuously seeks to improve."
      ],
      "metadata": {
        "id": "VY7N28lSf8Y9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Understanding `dprobs` in Simple Terms:\n",
        "\n",
        "1. **When the Network is Confident:**\n",
        "    - Imagine a student who answers a test question confidently and gets it right. The teacher just nods and moves on, without much fanfare.\n",
        "    - Similarly, when our network makes a prediction with high confidence and is correct, it doesn't change much. It thinks, \"I got this!\"\n",
        "\n",
        "2. **When the Network Lacks Confidence:**\n",
        "    - Now, imagine the same student hesitantly answers a question and gets it wrong. The teacher might spend extra time explaining the correct answer to ensure the student understands.\n",
        "    - In our network's case, when it's unsure or wrong about a prediction, it takes a closer look and tries harder to get it right the next time.\n",
        "\n",
        "3. **Why this Matters:**\n",
        "    - Think of it like practicing a sport. If you're good at shooting goals but bad at defense, you'd want to spend more time practicing defense to get better overall.\n",
        "    - Our network does the same thing. By focusing more on what it gets wrong, it tries to become better overall.\n",
        "\n",
        "4. **Big Picture:**\n",
        "    - This is like a self-adjusting study plan. If you're learning a new skill and keep making the same mistake, you'd focus on that area until you improve. The network does the same, adjusting its focus based on where it needs the most improvement.\n",
        "\n",
        "In short, our network is like a smart student. It celebrates its successes but spends more time on its mistakes to keep getting better."
      ],
      "metadata": {
        "id": "9LExGO7Hg2zW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## More on `dlogprobs` and `dprobs`\n",
        "\n",
        "## Backpropagation: The Heartbeat of Training\n",
        "\n",
        "1. **Forward Pass**: When we feed data into a neural network, it makes predictions. This flow of data from the input to the output is known as the forward pass. At the end of this pass, we compute the loss, which measures how far off our predictions are from the actual targets.\n",
        "\n",
        "2. **Backward Pass (Backpropagation)**: After computing the loss, we want to adjust our network to reduce that loss in future predictions. To do this, we need to understand which parts of our network (specifically, the weights) contributed the most to the error. Backpropagation helps us figure this out by computing gradients, which essentially tell us how to tweak our weights to minimize the loss.\n",
        "\n",
        "3. **Understanding Gradients**: Think of the loss as a hilly terrain and our goal is to find the lowest point. The gradients are like a compass, pointing in the direction of the steepest descent.\n",
        "\n",
        "### In the Context of `dlogprobs` and `dprobs`:\n",
        "\n",
        "- **The Role of `dlogprobs`**: When computing gradients, we start from the final loss and work our way backwards through each layer of the network. The first gradient we compute is `dlogprobs`, which tells us how much the loss would change with a small change in the log probabilities (logits).\n",
        "\n",
        "    - When the network is confident and correct (`probs` close to 1 for the correct class), the gradient doesn't change much. It \"just gets passed through\" means that it moves to the previous layers without much alteration. It's like telling the earlier layers, \"You did well, keep it up!\"\n",
        "    \n",
        "    - When the network isn't confident or is wrong, the gradient gets amplified. This is the network's way of signaling to the previous layers, \"We need to adjust here!\"\n",
        "\n",
        "- **Passed Through to Where?**: When we say \"passed through\", we mean it moves backward to the previous layers of the network. It's a domino effect. The gradient at one layer influences the gradient of the layer before it, which then influences the layer before that, and so on, until we reach the input layer.\n",
        "\n",
        "### In Summary:\n",
        "\n",
        "Backpropagation is like a feedback loop. The network makes predictions, sees where it went wrong, then adjusts itself to do better next time. The gradients, like `dlogprobs` and `dprobs`, are the messengers carrying information about where and how to adjust. When the network is confident and right, the message is mild. But when it's wrong or unsure, the message is loud and clear, urging the network to pay attention and learn."
      ],
      "metadata": {
        "id": "zYwZikz8kH3t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## From `dlogprobs` to `dprobs`\n",
        "\n",
        "The transition from `dlogprobs` to `dprobs` and then to the rest of the network is particularly crucial. Here's why:\n",
        "\n",
        "1. **End of the Chain**: The computation of `dlogprobs` and `dprobs` is essentially the starting point of backpropagation. The loss is computed using the log probabilities, so the gradient with respect to these values is the first step in the chain rule of backpropagation. Getting this right is foundational to the rest of the backprop process.\n",
        "\n",
        "2. **Magnitude and Direction of Gradients**: As we've discussed, the transition from `dlogprobs`  to `dprobs`  can amplify or dampen gradients. This modulation is crucial. It determines the \"urgency\" of the feedback. If the network is making significant mistakes, the gradient's magnitude will be larger, signaling a stronger need for adjustments in the earlier layers. Conversely, when the network is doing well, the gradient's magnitude will be smaller, signaling that the previous layers are generally on the right track.\n",
        "\n",
        "3. **Propagation to Earlier Layers**: The gradients computed in this phase determine the gradients for the rest of the network. If there's an error or inconsistency at this stage, it will propagate and potentially lead to suboptimal training for the entire network.\n",
        "\n",
        "4. **Vanishing and Exploding Gradients**: This early stage of backpropagation is also where we might start to encounter problems like vanishing or exploding gradients, especially in deeper networks. By monitoring and handling gradients correctly at this stage, we can prevent these issues, ensuring smoother and more effective training.\n",
        "\n",
        "In summary, the transition from `dlogprobs` to `dprobs` and its propagation to the rest of the network is a pivotal point in the backpropagation process. It sets the tone for the feedback that the rest of the network receives. Hence, understanding and handling this stage correctly is paramount to effective training."
      ],
      "metadata": {
        "id": "dJFlVVaJlumO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# `probs = counts * counts_sum_inv`\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Wtu_Xt2OnwDA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# counts = norm_logits.exp()\n",
        "# counts_sum = counts.sum(1, keepdims=True)\n",
        "# counts_sum_inv = counts_sum**-1\n",
        "# probs = counts * counts_sum_inv\n",
        "# logprobs = probs.log()\n",
        "# loss = -logprobs[range(n), Yb].mean()\n",
        "\n",
        "dcounts_sum_inv = (counts * dprobs).sum(1, keepdims=True)\n",
        "\n",
        "cmp('counts_sum_inv', dcounts_sum_inv, counts_sum_inv)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bs8WYIVmfc5v",
        "outputId": "7157dd1e-a5a3-4efa-c4f9-f54ea8cc64a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "counts_sum_inv  | exact: True  | approximate: True  | maxdiff: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## `dcounts_sum_inv`\n",
        "\n",
        "### What is `counts_sum_inv`?\n",
        "`counts_sum_inv` is the inverse of the sum of the counts (which were computed as the exponentiation of the normalized logits). In the given context, it's essentially a way to normalize the counts so that they sum up to one, making them probabilities.\n",
        "\n",
        "### Finding `dcounts_sum_inv`:\n",
        "When backpropagating through the network, we need to compute the gradient of the loss with respect to `counts_sum_inv`. Given that we have `dprobs`, the gradient of the loss with respect to `probs`, finding `dcounts_sum_inv` requires understanding how changing `counts_sum_inv` would affect the loss.\n",
        "\n",
        "### Step-by-step Explanation:\n",
        "\n",
        "1. **Recall the Relationship**:\n",
        " `probs` = `counts` $\\times$ `counts_sum_inv`\n",
        "This equation shows how `probs` is influenced by `counts_sum_inv`.\n",
        "\n",
        "2. **Effect on Probs**:\n",
        "Increasing `counts_sum_inv` by a tiny bit would increase all the values in `probs` proportionally, assuming `counts` remains constant.\n",
        "\n",
        "3. **Gradient Computation**:\n",
        "The gradient `counts_sum_inv` is the sum of all the changes in the loss resulting from these proportional increases in `probs`. In mathematical terms:\n",
        "$$ d\\text{counts_sum_inv} = \\sum_{i} d\\text{probs}_i \\times \\text{counts}_i$$\n",
        "\n",
        "4. **Intuitive Understanding**:\n",
        "Imagine you're distributing a fixed amount of water (representing the sum of counts) among several containers (representing each probability). `counts_sum_inv` determines how much water each container gets. If you slightly change the value of `counts_sum_inv`, it will affect the water level in all containers. The gradient $ d\\text{counts_sum_inv} $ captures the collective effect of these changes on the final desired outcome (the loss).\n",
        "\n",
        "In summary, `dcounts_sum_inv` represents the change in the loss due to a tiny change in `counts_sum_inv`. It accumulates the effects of such changes on each probability and, ultimately, on the loss."
      ],
      "metadata": {
        "id": "-EPhzqhtrEbb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chain rule\n",
        "\n",
        "We want to find:\n",
        "\n",
        "$$\n",
        "\\frac{\\partial \\text{loss}}{\\partial \\text{counts_sum_inv}}\n",
        "$$\n",
        "\n",
        "From the model, we have the relationship:\n",
        "\n",
        "$$\n",
        "\\text{probs} = \\text{counts} \\times \\text{counts_sum_inv}\n",
        "$$\n",
        "\n",
        "Using this relationship, the gradient $ d\\text{probs} $ with respect to $ \\text{counts_sum_inv} $ is:\n",
        "\n",
        "$$\n",
        "\\frac{\\partial \\text{probs}_i}{\\partial \\text{counts_sum_inv}} = \\text{counts}_i\n",
        "$$\n",
        "\n",
        "Now, combining this with our previous calculation for $ d\\text{probs} $ (which is the gradient of the loss with respect to the probabilities), we can use the chain rule:\n",
        "\n",
        "$$\n",
        "\\frac{\\partial \\text{loss}}{\\partial \\text{counts_sum_inv}} = \\sum_j \\frac{\\partial \\text{loss}}{\\partial \\text{probs}_j} \\times \\frac{\\partial \\text{probs}_j}{\\partial \\text{counts_sum_inv}}\n",
        "$$\n",
        "\n",
        "Substituting in the values we have:\n",
        "\n",
        "$$\n",
        "d\\text{counts_sum_inv} = \\sum_j d\\text{probs}_j \\times \\text{counts}_j\n",
        "$$\n",
        "\n",
        "Here:\n",
        "- $ d\\text{probs}_j $ is the gradient of the loss with respect to the j-th probability (from our previous calculation of $ d\\text{probs} $).\n",
        "- $ \\text{counts}_j $ is just the j-th element of the counts tensor.\n",
        "\n",
        "The sum is taken over all elements in the batch, and this gives us $ d\\text{counts_sum_inv} $, the gradient of the loss with respect to $ \\text{counts_sum_inv} $."
      ],
      "metadata": {
        "id": "cJYqfJ-ppH9r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tensor operations needed to compute `dcounts_sum_inv`\n",
        "\n",
        "### Relevant Definitions:\n",
        "\n",
        "- **counts**: This tensor holds the exponentiated normalized logits. Its shape is `[batch_size, num_classes]`.\n",
        "- **probs**: This tensor represents the normalized probabilities. Its shape is also `[batch_size, num_classes]`.\n",
        "- **dprobs**: The gradient of the loss with respect to `probs`. It has the same shape as `probs`, i.e., `[batch_size, num_classes]`.\n",
        "\n",
        "### Calculating $ d\\text{counts_sum_inv} $:\n",
        "\n",
        "Given the relationship\n",
        "\n",
        "$$ \\text{probs} = \\text{counts} \\times \\text{counts_sum_inv} $$\n",
        "\n",
        "The gradient $d\\text{counts_sum_inv} $ for a single instance in the batch is:\n",
        "\n",
        "$$ d\\text{counts_sum_inv}_i = \\sum_{j} d\\text{probs}_{ij} \\times \\text{counts}_{ij} $$\n",
        "\n",
        "This equation states that for each instance `i` in the batch, we want to sum over all classes `j`.\n",
        "\n",
        "### In Tensor Terms:\n",
        "\n",
        "1. **Element-wise Multiplication**: Multiply `dprobs` with `counts` element-wise. This operation doesn't change the shape of the tensors. Both tensors have the shape `[batch_size, num_classes]`, so this operation is straightforward with no need for broadcasting.\n",
        "   - Result: Tensor of shape `[batch_size, num_classes]`.\n",
        "\n",
        "$$ \\text{temp_gradient} = d\\text{probs} \\times \\text{counts} $$\n",
        "\n",
        "2. **Summing Over Classes**: Now, we want to sum the products across the classes for each instance in the batch. This reduces the tensor dimension by summing over the `num_classes` dimension.\n",
        "   - Result: Tensor of shape `[batch_size]`.\n",
        "\n",
        "$$ d\\text{counts_sum_inv} = \\text{sum}(\\text{temp_gradient}, \\text{dim}=1) $$\n",
        "\n",
        "### Broadcasting:\n",
        "In the given context, broadcasting isn't required for the described operations. Both `dprobs` and `counts` have the same shape, so their element-wise multiplication is straightforward. However, in general, PyTorch will automatically use broadcasting when performing operations between tensors of different shapes, as long as those shapes are broadcast-compatible.\n",
        "\n",
        "### In Summary:\n",
        "\n",
        "To compute $ d\\text{counts_sum_inv} $, you'll perform an element-wise multiplication between `dprobs` and `counts`, followed by summing over the `num_classes` dimension. The resulting tensor $ d\\text{counts_sum_inv} $ will have the shape `[batch_size]`."
      ],
      "metadata": {
        "id": "8jXdI83HrPDY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# `counts_sum_inv = counts_sum**-1`\n",
        "\n",
        " [d/dx x**-1 = 1/x**2](https://www.wolframalpha.com/input?i=d%2Fdx+x**-1)\n"
      ],
      "metadata": {
        "id": "OkAVEYwHg97l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# counts = norm_logits.exp()\n",
        "# counts_sum = counts.sum(1, keepdims=True)\n",
        "# counts_sum_inv = counts_sum**-1\n",
        "# probs = counts * counts_sum_inv\n",
        "# logprobs = probs.log()\n",
        "# loss = -logprobs[range(n), Yb].mean()\n",
        "\n",
        "dcounts_sum = (-counts_sum**-2)* dcounts_sum_inv\n",
        "cmp('counts_sum', dcounts_sum, counts_sum)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TXij0fM8jSeb",
        "outputId": "4b82ea56-9ff7-40ab-8c8e-4be55061a099"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "counts_sum      | exact: True  | approximate: True  | maxdiff: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## `dcounts` from `counts_sum`\n",
        "\n",
        "Recall the relationship:\n",
        "\n",
        "$$\n",
        "\\text{probs}_i = \\frac{\\text{counts}_i}{\\text{counts_sum}}\n",
        "$$\n",
        "\n",
        "From this, you can see that each individual count contributes to every probability in $ \\text{probs} $ via the denominator $ \\text{counts_sum} $. This introduces an inverse relationship between each count and every probability.\n",
        "\n",
        "Let's differentiate with respect to $ \\text{counts}_i $:\n",
        "\n",
        "$$\n",
        "\\frac{\\partial \\text{probs}_j}{\\partial \\text{counts}_i} = -\\frac{\\text{probs}_j}{\\text{counts_sum}}\n",
        "$$\n",
        "\n",
        "Notice that the derivative involves a negative sign due to the inverse relationship.\n",
        "\n",
        "Using the chain rule, the gradient of the loss with respect to $ \\text{counts}_i $ for this part is:\n",
        "\n",
        "$$\n",
        "\\frac{\\partial \\text{loss}}{\\partial \\text{counts}_i} = \\sum_j \\frac{\\partial \\text{loss}}{\\partial \\text{probs}_j} \\times \\frac{\\partial \\text{probs}_j}{\\partial \\text{counts}_i}\n",
        "$$\n",
        "\n",
        "Substituting the values we have:\n",
        "\n",
        "$$\n",
        "d\\text{counts}_i (from \\ counts\\_sum) = \\sum_j -d\\text{probs}_j \\times \\frac{\\text{probs}_j}{\\text{counts_sum}}\n",
        "$$\n",
        "\n",
        "In tensor notation:\n",
        "\n",
        "$$\n",
        "d\\text{counts} (from \\ counts\\_sum) = -\\text{probs} \\times d\\text{counts_sum}\n",
        "$$\n",
        "\n",
        "Where:\n",
        "- $ d\\text{probs} $ is of shape [batch_size, vocab_size]\n",
        "- $ \\text{probs} $ is of shape [batch_size, vocab_size]\n",
        "- $ d\\text{counts_sum} $ is of shape [batch_size, 1]\n",
        "\n",
        "Again, broadcasting is at play due to the multiplication of tensors of shape [batch_size, vocab_size] and [batch_size, 1].\n",
        "\n",
        "To summarize, the $ d\\text{counts} $ gradient comes from two sources:\n",
        "1. The direct relationship of counts to the computed probabilities.\n",
        "2. The inverse relationship where each count affects all probabilities through the denominator.\n",
        "\n",
        "Both these gradients are combined to get the overall gradient for counts."
      ],
      "metadata": {
        "id": "ygWuH0djvLqC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## `dcounts_sum`\n",
        "\n",
        "### Background:\n",
        "The term `counts_sum` represents the summation of the exponentiated values of normalized logits for each instance in the batch. In other words, for each data point in our batch, we sum up the exponentiated values across all possible classes. This summation plays a crucial role in converting the logits into probabilities.\n",
        "\n",
        "### Derivation of $d\\text{counts_sum}$:\n",
        "\n",
        "Given the relationship:\n",
        "\n",
        "$$ \\text{probs} = \\text{counts} \\times \\text{counts_sum\\=_inv} $$\n",
        "\n",
        "From our earlier computation, we found:\n",
        "\n",
        "$$ d\\text{counts_sum_inv}_i = \\sum_j d\\text{probs}_{ij} \\times \\text{counts}_{ij} $$\n",
        "\n",
        "Now, the inverse of `counts_sum` is used to compute `probs`. Hence, the gradient of the loss with respect to `counts_sum` can be computed as:\n",
        "\n",
        "$$ d\\text{counts_sum} = - \\text{counts_sum_inv}^2 \\times d\\text{counts_sum_inv} $$\n",
        "\n",
        "This equation captures the intuition that if the total counts (sum) increases, the inverse decreases, hence the negative sign.\n",
        "\n",
        "### In Tensor Terms:\n",
        "\n",
        "1. **Square the Inverse**: Compute the square of the inverse of `counts_sum`. This will give you a tensor of shape `[batch_size]`.\n",
        "\n",
        "$$ \\text{inverse_square} = \\text{counts_sum_inv}^2 $$\n",
        "\n",
        "2. **Element-wise Multiplication**: Multiply the `inverse_square` tensor with the previously computed `dcounts_sum_inv` tensor, element-wise. Remember to include a negative sign. Since both tensors have the shape `[batch_size]`, this operation is straightforward with no need for broadcasting.\n",
        "\n",
        "$$ d\\text{counts_sum} = - \\text{inverse_square} \\times d\\text{counts_sum_inv} $$\n",
        "\n",
        "### Broadcasting:\n",
        "In this context, there's no need for broadcasting since the operations involve tensors with compatible shapes.\n",
        "\n",
        "### Summary:\n",
        "\n",
        "To compute $ d\\text{counts_sum}$, you'll square the inverse of `counts_sum` and then multiply this with the previously computed gradient `dcounts_sum_inv`, ensuring to use a negative sign. The resulting tensor \\(d\\text{counts\\_sum}\\) will have the shape `[batch_size]`."
      ],
      "metadata": {
        "id": "qrUMn8T5hufA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chain rule\n",
        "\n",
        "The chain rule states:\n",
        "\n",
        "$$\n",
        "\\frac{\\partial \\text{loss}}{\\partial \\text{counts_sum}} = \\frac{\\partial \\text{loss}}{\\partial \\text{counts_sum_inv}} \\times \\frac{\\partial \\text{counts_sum_inv}}{\\partial \\text{counts_sum}}\n",
        "$$\n",
        "\n",
        "From the previous discussion:\n",
        "\n",
        "$$\n",
        "\\frac{\\partial \\text{counts_sum_inv}}{\\partial \\text{counts_sum}} = -\\frac{1}{\\text{counts_sum}^2}\n",
        "$$\n",
        "\n",
        "Substituting that in:\n",
        "\n",
        "$$\n",
        "\\frac{\\partial \\text{loss}}{\\partial \\text{counts\\_sum}} = \\frac{\\partial \\text{loss}}{\\partial \\text{counts\\_sum\\_inv}} \\times \\left(-\\frac{1}{\\text{counts\\_sum}^2}\\right)\n",
        "$$\n",
        "\n",
        "Now, using the variable names:\n",
        "\n",
        "$$\n",
        "d\\text{counts_sum} = -\\frac{1}{\\text{counts_sum}^2} \\times d\\text{counts_sum_inv}\n",
        "$$\n"
      ],
      "metadata": {
        "id": "5ZiYB6URnrNZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The chain rule so far.\n",
        "\n",
        "### 1. From \\( $\\text{loss} $\\) to \\( $\\text{logprobs} $\\):\n",
        "\n",
        "Given the loss function:\n",
        "\n",
        "$$ \\text{loss} = -\\frac{1}{N} \\sum_i \\text{logprobs}_{i, y_i} $$\n",
        "\n",
        "The gradient of the loss with respect to $\\text{logprobs}$ is:\n",
        "\n",
        "$$ \\frac{\\partial \\text{loss}}{\\partial \\text{logprobs}_{i, y_i}} = -\\frac{1}{N} $$\n",
        "$$ \\frac{\\partial \\text{loss}}{\\partial \\text{logprobs}_{i, j}} = 0 \\quad \\text{for} \\quad j \\neq y_i $$\n",
        "\n",
        "### 2. From $\\text{logprobs} $ to $ \\text{probs} $:\n",
        "\n",
        "Using the relationship:\n",
        "\n",
        "$ \\text{logprobs} = \\log(\\text{probs}) $\n",
        "\n",
        "The gradient is:\n",
        "\n",
        "$ \\frac{\\partial \\text{logprobs}}{\\partial \\text{probs}} = \\frac{1}{\\text{probs}} $\n",
        "\n",
        "### 3. From $ \\text{probs} $ to $ \\text{counts_sum_inv} $:\n",
        "\n",
        "Given the relationship:\n",
        "\n",
        "$$ \\text{probs} = \\text{counts} \\times \\text{counts_sum_inv} $$\n",
        "\n",
        "The gradient is:\n",
        "\n",
        "$$ \\frac{\\partial \\text{probs}}{\\partial \\text{counts_sum_inv}} = \\text{counts} $$\n",
        "\n",
        "### 4. From $ \\text{counts_sum_inv} $ to $ \\text{counts_sum} $:\n",
        "\n",
        "Since:\n",
        "\n",
        "$$ \\text{counts_sum_inv} = \\frac{1}{\\text{counts_sum}} $$\n",
        "\n",
        "The gradient is:\n",
        "\n",
        "$$ \\frac{\\partial \\text{counts_sum_inv}}{\\partial \\text{counts_sum}} = -\\frac{1}{\\text{counts_sum}^2} $$\n",
        "\n",
        "Now, using the chain rule, you combine these gradients to get the gradient of the loss with respect to any of these intermediate variables. For example, to get the gradient of the loss with respect to $\\text{counts_sum} $, you'd multiply the gradients through each step:\n",
        "\n",
        "$$ \\frac{\\partial \\text{loss}}{\\partial \\text{counts_sum}} = \\frac{\\partial \\text{loss}}{\\partial \\text{logprobs}} \\times \\frac{\\partial \\text{logprobs}}{\\partial \\text{probs}} \\times \\frac{\\partial \\text{probs}}{\\partial \\text{counts_sum_inv}} \\times \\frac{\\partial \\text{counts_sum_inv}}{\\partial \\text{counts_sum}} $$\n",
        "\n",
        "This chained multiplication allows you to propagate the gradient from the output (loss) back through the network to the input, which is the essence of backpropagation."
      ],
      "metadata": {
        "id": "ai1XXcjOlAbb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# `counts_sum = counts.sum(1, keepdims=True)`"
      ],
      "metadata": {
        "id": "WeaYGBfbrGS6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# counts = norm_logits.exp()\n",
        "# counts_sum = counts.sum(1, keepdims=True)\n",
        "# counts_sum_inv = counts_sum**-1\n",
        "# probs = counts * counts_sum_inv\n",
        "# logprobs = probs.log()\n",
        "# loss = -logprobs[range(n), Yb].mean()\n",
        "\n",
        "dcounts = counts_sum_inv * dprobs\n",
        "dcounts += torch.ones_like(counts) * dcounts_sum\n",
        "\n",
        "cmp('counts', dcounts, counts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WbSK86-jrLcv",
        "outputId": "ec563be0-af8c-4617-fceb-dd3cd34aa1ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "counts          | exact: True  | approximate: True  | maxdiff: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## `dcounts`\n",
        "\n",
        "Let's break down the calculation of the gradient $ d\\text{counts} $ with respect to the loss.\n",
        "\n",
        "To find $ d\\text{counts} $ , we'll trace back through the operations that lead to the loss, focusing on the role of $ \\text{counts} $.\n",
        "\n",
        "The sequence of relationships we've been following is:\n",
        "1. $ \\text{counts} $ are used to compute $ \\text{counts_sum} $.\n",
        "2. $ \\text{counts_sum} $ is used to compute $ \\text{counts_sum_inv} $.\n",
        "3. $ \\text{counts_sum_inv} $ multiplies with $ \\text{counts} $ to compute $ \\text{probs} $.\n",
        "4. $ \\text{probs} $ are used to compute $ \\text{logprobs} $.\n",
        "5. $ \\text{logprobs} $ are used to compute the loss.\n",
        "\n",
        "Now, let's find $ d\\text{counts} $.\n",
        "\n",
        "From the relationship:\n",
        "\n",
        "$$\n",
        "\\text{probs}_i = \\text{counts}_i \\times \\text{counts_sum_inv}\n",
        "$$\n",
        "\n",
        "We can differentiate with respect to $ \\text{counts}_i $ to get:\n",
        "\n",
        "$$\n",
        "\\frac{\\partial \\text{probs}_i}{\\partial \\text{counts}_i} = \\text{counts\\_sum\\_inv}\n",
        "$$\n",
        "\n",
        "Using the chain rule, the gradient of the loss with respect to $ \\text{counts}_i $ is:\n",
        "\n",
        "$$\n",
        "\\frac{\\partial \\text{loss}}{\\partial \\text{counts}_i} = \\frac{\\partial \\text{loss}}{\\partial \\text{probs}_i} \\times \\frac{\\partial \\text{probs}_i}{\\partial \\text{counts}_i}\n",
        "$$\n",
        "\n",
        "Substituting the values we have:\n",
        "\n",
        "$$\n",
        "d\\text{counts}_i = d\\text{probs}_i \\times \\text{counts_sum_inv}\n",
        "$$\n",
        "\n",
        "In tensor notation (considering all elements in the batch):\n",
        "\n",
        "$$\n",
        "d\\text{counts} = d\\text{probs} \\times \\text{counts\\_sum\\_inv}\n",
        "$$\n",
        "\n",
        "**Shapes & Broadcasting**:\n",
        "- $ d\\text{probs} $: shape of [batch_size, num_classes]\n",
        "- $ \\text{counts\\_sum\\_inv} $: shape of [batch_size, 1] (since it's computed per example in the batch)\n",
        "\n",
        "In this case, broadcasting is at play. When multiplying, $ \\text{counts_sum_inv} $ is broadcasted to match the shape of $ d\\text{probs} $, effectively scaling each row of $ d\\text{probs} $ by its corresponding value in $\\text{counts_sum_inv} $."
      ],
      "metadata": {
        "id": "xAITxDrlsF-n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# `counts = norm_logits.exp()`"
      ],
      "metadata": {
        "id": "z7WarqFPujpv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# dnorm_logits = norm_logits.exp() * dcounts\n",
        "dnorm_logits = counts * dcounts\n",
        "\n",
        "cmp('norm_logits', dnorm_logits, norm_logits)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iu9rCOwCundE",
        "outputId": "fe78de35-51ce-4e83-a789-56fc6b763ab4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "norm_logits     | exact: True  | approximate: True  | maxdiff: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## `dnorm_logits`\n",
        "\n",
        "### Background:\n",
        "\n",
        "From the provided code, the normalized logits, $ \\text{norm_logits} $, are computed as:\n",
        "\n",
        "$$\n",
        "\\text{norm_logits} = \\text{logits} - \\text{logit_maxes}\n",
        "$$\n",
        "\n",
        "And then, we have:\n",
        "\n",
        "$$\n",
        "\\text{counts} = \\exp(\\text{norm_logits})\n",
        "$$\n",
        "\n",
        "The relationship between $ \\text{counts} $ and $ \\text{norm_logits} $ is exponential. So, we need to differentiate the exponential function to understand how a change in $ \\text{norm_logits} $ will affect the loss.\n",
        "\n",
        "### Chain Rule Calculation:\n",
        "\n",
        "Using the chain rule:\n",
        "\n",
        "$$\n",
        "\\frac{\\partial \\text{loss}}{\\partial \\text{norm_logits}} = \\frac{\\partial \\text{loss}}{\\partial \\text{counts}} \\times \\frac{\\partial \\text{counts}}{\\partial \\text{norm_logits}}\n",
        "$$\n",
        "\n",
        "Differentiating the exponential function, we get:\n",
        "\n",
        "$$\n",
        "\\frac{\\partial \\text{counts}_i}{\\partial \\text{norm_logits}_i} = \\exp(\\text{norm_logits}_i) = \\text{counts}_i\n",
        "$$\n",
        "\n",
        "Hence:\n",
        "\n",
        "$$\n",
        "\\frac{\\partial \\text{loss}}{\\partial \\text{norm_logits}_i} = \\frac{\\partial \\text{loss}}{\\partial \\text{counts}_i} \\times \\text{counts}_i\n",
        "$$\n",
        "\n",
        "### PyTorch Calculation:\n",
        "\n",
        "Given the relationship, the PyTorch way to calculate $ d\\text{norm_logits} $ would be:\n",
        "\n",
        "$$\n",
        "d\\text{norm_logits} = d\\text{counts} \\times \\text{counts}\n",
        "$$\n",
        "\n",
        "In code:\n",
        "\n",
        "```python\n",
        "dnorm_logits = dcounts * counts\n",
        "```\n",
        "\n",
        "This line of code computes the gradient of the loss with respect to the normalized logits. The multiplication is element-wise, so each component of the gradient \\( d\\text{norm_logits} \\) depends on the corresponding components of \\( d\\text{counts} \\) and \\( \\text{counts} \\)."
      ],
      "metadata": {
        "id": "uYuKea3KxzwD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# `norm_logits = logits - logit_maxes`"
      ],
      "metadata": {
        "id": "r0vwWT4byn6E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dlogit_maxes = (-dnorm_logits).sum(1, keepdims=True)\n",
        "\n",
        "cmp('logit_maxes', dlogit_maxes, logit_maxes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jlWQQflnywlM",
        "outputId": "5d83e7d6-128d-4d42-eb38-8346160aceeb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "logit_maxes     | exact: True  | approximate: True  | maxdiff: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# note very small values. dlogit_maxes does't have an impact on probs or loss.\n",
        "dlogit_maxes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kf3G35PSF4bp",
        "outputId": "6c5e92c9-d698-45e2-9bea-d525322ad761"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 2.3283e-10],\n",
              "        [ 4.6566e-09],\n",
              "        [-1.8626e-09],\n",
              "        [ 9.3132e-10],\n",
              "        [ 2.3283e-09],\n",
              "        [ 0.0000e+00],\n",
              "        [ 3.2596e-09],\n",
              "        [ 4.1910e-09],\n",
              "        [-6.0536e-09],\n",
              "        [ 9.3132e-10],\n",
              "        [ 1.8626e-09],\n",
              "        [-5.1223e-09],\n",
              "        [-1.8626e-09],\n",
              "        [-3.7253e-09],\n",
              "        [ 2.3283e-09],\n",
              "        [-1.3970e-09],\n",
              "        [ 4.1910e-09],\n",
              "        [ 4.1910e-09],\n",
              "        [ 1.8626e-09],\n",
              "        [-1.8626e-09],\n",
              "        [-4.6566e-10],\n",
              "        [-5.5879e-09],\n",
              "        [ 0.0000e+00],\n",
              "        [-2.0955e-09],\n",
              "        [ 1.8626e-09],\n",
              "        [-2.3283e-10],\n",
              "        [-2.3283e-10],\n",
              "        [ 3.9581e-09],\n",
              "        [-4.1910e-09],\n",
              "        [ 3.7253e-09],\n",
              "        [-7.4506e-09],\n",
              "        [-1.8626e-09]], grad_fn=<SumBackward1>)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## `dlogit_maxes`\n",
        "\n",
        "### Background:\n",
        "\n",
        "The computation for normalized logits is:\n",
        "$$\n",
        "\\text{norm_logits} = \\text{logits} - \\text{logit_maxes}\n",
        "$$\n",
        "\n",
        "For each instance in the batch, $ \\text{logit_maxes} $ is subtracted from every logit to provide numerical stability during the softmax computation.\n",
        "\n",
        "### Chain Rule Calculation:\n",
        "\n",
        "Using the chain rule for differentiation, the gradient of the loss with respect to $ \\text{logit_maxes} $ is:\n",
        "\n",
        "$$\n",
        "\\frac{\\partial \\text{loss}}{\\partial \\text{logit_maxes}} = \\frac{\\partial \\text{loss}}{\\partial \\text{norm_logits}} \\times \\frac{\\partial \\text{norm_logits}}{\\partial \\text{logit_maxes}}\n",
        "$$\n",
        "\n",
        "We know:\n",
        "$$\n",
        "\\frac{\\partial \\text{norm_logits}_i}{\\partial \\text{logit_maxes}_i} = -1\n",
        "$$\n",
        "\n",
        "This is because  $ \\text{logit_maxes} $ is subtracted from every logit for a particular instance in the batch, making the rate of change -1.\n",
        "\n",
        "When we sum up these contributions, we get the total gradient for $ \\text{logit_maxes} $ for a particular instance. Since $ \\text{logit_maxes} $ has been subtracted from every logit for the instance, the net gradient contribution from all logits is the sum of the individual gradient contributions.\n",
        "\n",
        "### PyTorch Calculation:\n",
        "\n",
        "Using the above relationship, the PyTorch way to compute $ d\\text{logit_maxes} $ is:\n",
        "$$\n",
        "d\\text{logit_maxes} = (-d\\text{norm_logits}).\\text{sum(1, keepdims=True)}\n",
        "$$\n",
        "\n",
        "This means for each instance in the batch, the gradient for $ \\text{logit_maxes} $ is the negative sum of the gradients of all logits for that instance.\n",
        "\n",
        "This gradient represents how much the loss will change for a unit change in $ \\text{logit_maxes} $, considering the contributions from all logits for that instance. The negative sign indicates that as $ \\text{logit_maxes} $ increases, the normalized logits decrease, and vice versa.\n",
        "\n",
        "### Revised Theory:\n",
        "\n",
        "The gradient $ d\\text{logit_maxes} $ indicates how a change in the maximum logit value for each instance affects the overall loss. The gradient is the negative sum of the gradients of all logits for that instance, capturing the combined effect of all logits on the loss. This combined gradient will guide the optimization process to adjust the logits in a way that reduces the loss."
      ],
      "metadata": {
        "id": "iQMlXs2t64lW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## `dlogits` branch 1\n",
        "\n",
        "### Background:\n",
        "\n",
        "The equation we're focusing on is:\n",
        "$$\n",
        "\\text{norm_logits} = \\text{logits} - \\text{logit_maxes}\n",
        "$$\n",
        "\n",
        "This equation simply represents the subtraction of the maximum logit value (for each instance in the batch) from all the logits. The purpose is to provide numerical stability during subsequent calculations, such as the softmax.\n",
        "\n",
        "### Chain Rule Calculation:\n",
        "\n",
        "Using the chain rule for differentiation, the gradient of the loss with respect to `logits` is:\n",
        "\n",
        "$$\n",
        "\\frac{\\partial \\text{loss}}{\\partial \\text{logits}} = \\frac{\\partial \\text{loss}}{\\partial \\text{norm_logits}} \\times \\frac{\\partial \\text{norm_logits}}{\\partial \\text{logits}}\n",
        "$$\n",
        "\n",
        "Now, looking at the equation, for each logit:\n",
        "$$\n",
        "\\frac{\\partial \\text{norm_logits}_i}{\\partial \\text{logits}_i} = 1\n",
        "$$\n",
        "\n",
        "This is because each logit directly contributes to the corresponding normalized logit with a rate of change of 1. In simpler terms, if you increase a logit by 1, the corresponding normalized logit also increases by 1 (and vice versa).\n",
        "\n",
        "### PyTorch Calculation:\n",
        "\n",
        "Given the above relationship, the PyTorch way to compute the gradient $ d\\text{logits} $ is:\n",
        "\n",
        "$$\n",
        "d\\text{logits} = d\\text{norm_logits}\n",
        "$$\n",
        "\n",
        "This gradient represents the direct contribution of each logit to the loss. For each logit in the batch, the gradient tells us how much the loss will change for a unit change in that particular logit.\n",
        "\n",
        "### Summary:\n",
        "\n",
        "The gradient $ d\\text{logits} $ gives us a sense of how each individual logit value impacts the final loss. A positive gradient for a logit indicates that increasing its value will increase the loss (and vice versa). This gradient will guide the optimization algorithm on how to adjust the logits to minimize the loss."
      ],
      "metadata": {
        "id": "enrYungStC6v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# emb = C[Xb] # embed the characters into vectors\n",
        "# embcat = emb.view(emb.shape[0], -1) # concatenate the vectors\n",
        "# hprebn = embcat @ W1 + b1 # hidden layer pre-activation\n",
        "# bnmeani = 1/n*hprebn.sum(0, keepdim=True)\n",
        "# bndiff = hprebn - bnmeani\n",
        "# bndiff2 = bndiff**2\n",
        "# bnvar = 1/(n-1)*(bndiff2).sum(0, keepdim=True)\n",
        "# bnvar_inv = (bnvar + 1e-5)**-0.5\n",
        "# bnraw = bndiff * bnvar_inv\n",
        "# hpreact = bngain * bnraw + bnbias\n",
        "# h = torch.tanh(hpreact) # hidden layer\n",
        "# logits = h @ W2 + b2 # output layer\n",
        "# logit_maxes = logits.max(1, keepdim=True).values\n",
        "# norm_logits = logits - logit_maxes\n",
        "# counts = norm_logits.exp()\n",
        "# counts_sum = counts.sum(1, keepdims=True)\n",
        "# counts_sum_inv = counts_sum**-1\n",
        "# probs = counts * counts_sum_inv\n",
        "# logprobs = probs.log()\n",
        "# loss = -logprobs[range(n), Yb].mean()\n",
        "\n",
        "\n",
        "\n",
        "dlogit_maxes = (-dnorm_logits).sum(1, keepdims=True)\n",
        "dnorm_logits = dcounts * counts\n",
        "dcounts = counts_sum_inv * dprobs\n",
        "dcounts += torch.ones_like(counts) * dcounts_sum\n",
        "dcounts_sum = (-counts_sum**-2)* dcounts_sum_inv\n",
        "dcounts_sum_inv = (counts * dprobs).sum(1, keepdims=True)\n",
        "dlogprobs = torch.zeros_like(logprobs)\n",
        "dlogprobs[range(n), Yb] = -1.0/n\n",
        "dprobs = (1/probs) * dlogprobs"
      ],
      "metadata": {
        "id": "NNB_J61K_xIu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dlogits = dnorm_logits.clone()\n",
        "dlogits += F.one_hot(logits.max(1).indices,num_classes=logits.shape[1]) * dlogit_maxes\n",
        "\n",
        "cmp('logits', dlogits, logits)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qs-uRTAK_5Cc",
        "outputId": "03f1a518-007a-4408-caed-50d9b2107c73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "logits          | exact: True  | approximate: True  | maxdiff: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(F.one_hot(logits.max(1).indices,num_classes=logits.shape[1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "vgsZtgD_Hu01",
        "outputId": "6a81cf52-f8d8-41a0-b20f-a1ce5ba85bdb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7c025fa50310>"
            ]
          },
          "metadata": {},
          "execution_count": 37
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# `logit_maxes = logits.max(1, keepdim=True).values`"
      ],
      "metadata": {
        "id": "Dfinx2_NEgOm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## `dlogits` branch 2\n",
        "\n",
        "### Background:\n",
        "\n",
        "The line of code:\n",
        "$$\n",
        "\\text{logit_maxes} = \\text{logits}.max(1, \\text{keepdim=True}).values\n",
        "$$\n",
        "\n",
        "is used to find the maximum logit value for each instance in the batch. Essentially, for each instance (or row) of logits, it extracts the largest value. This is primarily done to ensure numerical stability in subsequent operations, especially when computing the softmax function.\n",
        "\n",
        "### Intuition:\n",
        "\n",
        "Now, remember that `logit_maxes` is just the maximum value from `logits`. When we backpropagate through this operation, only the maximum logit for each instance contributes to the gradient; all other logits have zero contribution because they didn't affect the output of the `max` function.\n",
        "\n",
        "### Chain Rule Calculation:\n",
        "\n",
        "Using the chain rule for differentiation, the gradient of the loss with respect to `logits` from the max operation is:\n",
        "\n",
        "$$\n",
        "\\frac{\\partial \\text{loss}}{\\partial \\text{logits}} = \\frac{\\partial \\text{loss}}{\\partial \\text{logit_maxes}} \\times \\frac{\\partial \\text{logit_maxes}}{\\partial \\text{logits}}\n",
        "$$\n",
        "\n",
        "Now, $ \\frac{\\partial \\text{logit_maxes}}{\\partial \\text{logits}} $ is a bit special:\n",
        "\n",
        "- It's 1 for the logit that was the maximum (because that logit directly influenced `logit_maxes`).\n",
        "- It's 0 for all other logits (because they had no influence on `logit_maxes`).\n",
        "\n",
        "### PyTorch Calculation:\n",
        "\n",
        "The PyTorch way to compute the gradient $ d\\text{logits} $ based on the operation is:\n",
        "\n",
        "$$\n",
        "d\\text{logits}[i] =\n",
        "\\begin{cases}\n",
        "d\\text{logit_maxes}[i] & \\text{if } \\text{logits}[i] = \\text{logit_maxes} \\\\\n",
        "0 & \\text{otherwise}\n",
        "\\end{cases}\n",
        "$$\n",
        "\n",
        "### Summary:\n",
        "\n",
        "For the `max` operation, only the maximum value in the `logits` tensor has a gradient that affects the loss, and the gradient for all other values is 0. This is because the other values didn't contribute to the maximum and, therefore, had no direct influence on the loss."
      ],
      "metadata": {
        "id": "Bog5kTxgH9YL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# `logits = h @ W2 + b2`"
      ],
      "metadata": {
        "id": "fwUgGTsOsbHA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "logits.shape, h.shape, W2.shape, b2.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AE9iJ1L8LNWv",
        "outputId": "4e95bd93-8bcb-45e6-8f46-d35c5b6abe46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([32, 27]),\n",
              " torch.Size([32, 64]),\n",
              " torch.Size([64, 27]),\n",
              " torch.Size([27]))"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dh = dlogits @ W2.T\n",
        "dW2 = h.T @ dlogits\n",
        "db2 = dlogits.sum(0)\n",
        "\n",
        "cmp('h', dh, h)\n",
        "cmp('W2', dW2, W2)\n",
        "cmp('b2', db2, b2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v4oQOL4oshcS",
        "outputId": "d6ebdf24-d58b-4ec4-8f42-c87fd460a447"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "h               | exact: True  | approximate: True  | maxdiff: 0.0\n",
            "W2              | exact: True  | approximate: True  | maxdiff: 0.0\n",
            "b2              | exact: True  | approximate: True  | maxdiff: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## `dh, dW2 and dB2`\n",
        "\n",
        "### Forward Propagation:\n",
        "\n",
        "$ \\text{logits} = h \\times W2 + b2 $\n",
        "\n",
        "Where:\n",
        "- \\( h \\) is the output from the previous layer.\n",
        "- \\( W2 \\) are the weights of this layer.\n",
        "- \\( b2 \\) are the biases of this layer.\n",
        "\n",
        "This is just a linear transformation (matrix multiplication followed by a bias addition).\n",
        "\n",
        "### Backward Propagation:\n",
        "\n",
        "#### 1. Gradient with respect to \\( h \\):\n",
        "\n",
        "$$ \\frac{\\partial \\text{loss}}{\\partial h} = \\frac{\\partial \\text{loss}}{\\partial \\text{logits}} \\times W2^T $$\n",
        "\n",
        "This comes from the chain rule. If you think of the matrix multiplication, when we backpropagate through it, the gradient gets distributed across the rows of the weight matrix. In terms of matrix operations, this is achieved by multiplying the gradient with respect to the output $ \\text{logits} $ with the transpose of the weights $ W2^T $.\n",
        "\n",
        "**Python code:**\n",
        "\n",
        "```python\n",
        "dh = dlogits @ W2.T\n",
        "```\n",
        "\n",
        "#### 2. Gradient with respect to \\( W2 \\):\n",
        "\n",
        "$$ \\frac{\\partial \\text{loss}}{\\partial W2} = h^T \\times \\frac{\\partial \\text{loss}}{\\partial \\text{logits}} $$\n",
        "\n",
        "Here, we're considering how much the change in each weight will affect the loss. For this, we need to look at the activations coming into the weight and the gradient of the loss with respect to the output. In matrix terms, this is achieved by multiplying the transpose of the incoming activations $ h^T $ with the gradient with respect to the output.\n",
        "\n",
        "**Python code:**\n",
        "\n",
        "```python\n",
        "dW2 = h.T @ dlogits\n",
        "```\n",
        "\n",
        "#### 3. Gradient with respect to \\( b2 \\):\n",
        "\n",
        "$$ \\frac{\\partial \\text{loss}}{\\partial b2} = \\sum \\frac{\\partial \\text{loss}}{\\partial \\text{logits}} $$\n",
        "\n",
        "The bias gets added to each output, so its gradient is simply the sum of the gradients of the output it affects.\n",
        "\n",
        "**Python code:**\n",
        "\n",
        "```python\n",
        "db2 = dlogits.sum(0)\n",
        "```\n",
        "\n",
        "**In summary:**\n",
        "\n",
        "- The gradient with respect to the hidden state \\( h \\) is computed by distributing the gradients of the output across the weights.\n",
        "- The gradient with respect to the weights \\( W2 \\) is found by seeing how the activations and the output gradients interact.\n",
        "- The gradient for the biases \\( b2 \\) is the sum of the gradients of the outputs they affect."
      ],
      "metadata": {
        "id": "zcVeK9TKt5P0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# `h = torch.tanh(hpreact)`"
      ],
      "metadata": {
        "id": "AlarE1sbv9t6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# a = tanh(z)\n",
        "# da/dz = 1 - a**2\n",
        "\n",
        "# h = torch.tanh(hpreact)\n",
        "# dloss/dhpreact = dloss/dh * dh/dhpreact\n",
        "# dhpreact = (1- dh**2) * dh\n",
        "\n",
        "dhpreact = (1.0 - h**2) * dh\n",
        "# dhpreact = dh * (1 - torch.tanh(hpreact)**2)\n",
        "cmp('hpreact', dhpreact, hpreact)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UaSZwCykwCvZ",
        "outputId": "8fe12e56-9867-49fd-ae28-22b373f22808"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hpreact         | exact: False | approximate: True  | maxdiff: 4.656612873077393e-10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`dhpreact`\n",
        "\n",
        "### Forward Propagation:\n",
        "\n",
        "The operation in the forward pass is:\n",
        "\n",
        "$$ h = \\tanh(h_{\\text{preact}}) $$\n",
        "\n",
        "Here, $ h_{\\text{preact}} $ is the pre-activation output from the previous layer, and we apply the hyperbolic tangent $ \\tanh $ function to get the activations, $ h $.\n",
        "\n",
        "### Backward Propagation:\n",
        "\n",
        "To understand the backward pass for the $ \\tanh $ function, we must first understand the derivative of $ \\tanh $:\n",
        "\n",
        "$$ \\frac{d}{dx} \\tanh(x) = 1 - \\tanh^2(x) $$\n",
        "\n",
        "This derivative gives us the rate of change of $ \\tanh $ at any point \\( x \\). When backpropagating, we'll use this derivative to find out how much the loss would change if we tweaked the value of $ h_{\\text{preact}} $ just a little bit.\n",
        "\n",
        "Now, for the chain rule:\n",
        "\n",
        "$$ \\frac{\\partial \\text{loss}}{\\partial h_{\\text{preact}}} = \\frac{\\partial \\text{loss}}{\\partial h} \\times \\frac{\\partial h}{\\partial h_{\\text{preact}}} $$\n",
        "\n",
        "Where:\n",
        "- $ \\frac{\\partial \\text{loss}}{\\partial h} $ is the gradient of the loss with respect to \\( h \\) (which we would have from subsequent layers during backpropagation).\n",
        "- $ \\frac{\\partial h}{\\partial h_{\\text{preact}}} $ is the gradient of \\( h \\) with respect to $ h_{\\text{preact}} $, which is $ 1 - \\tanh^2(h_{\\text{preact}}) $ based on the derivative of the $ \\tanh $ function.\n",
        "\n",
        "Combining these, we get:\n",
        "\n",
        "$$ \\frac{\\partial \\text{loss}}{\\partial h_{\\text{preact}}} = \\frac{\\partial \\text{loss}}{\\partial h} \\times (1 - \\tanh^2(h_{\\text{preact}})) $$\n",
        "\n",
        "**Python code:**\n",
        "\n",
        "```python\n",
        "dhpreact = dh * (1 - torch.tanh(hpreact)**2)\n",
        "```\n",
        "\n",
        "**In summary:**\n",
        "\n",
        "The gradient with respect to $ h_{\\text{preact}} $ is calculated by multiplying the gradient of the loss with respect to \\( h \\) by the derivative of the $ \\tanh $ function at $ h_{\\text{preact}} $. This gives us a measure of how changes in $ h_{\\text{preact}} $ would affect the overall loss."
      ],
      "metadata": {
        "id": "Ds1gaurcyPlr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# `hpreact = bngain * bnraw + bnbias`"
      ],
      "metadata": {
        "id": "gDypdt_x18zx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hpreact.shape, bngain.shape, bnraw.shape, bnbias.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3o14-7Ft3L9Y",
        "outputId": "2326b72a-df3b-440e-e41c-6ed321deb9b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([32, 64]),\n",
              " torch.Size([1, 64]),\n",
              " torch.Size([32, 64]),\n",
              " torch.Size([1, 64]))"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# hpreact = bngain * bnraw + bnbias\n",
        "\n",
        "# dloss/dbngain = dbngain/dhpreact * dloss/dhpreact\n",
        "# need sum because of shapes and make sure broadcasting is backpropagated\n",
        "dbngain = (bnraw * dhpreact).sum(0, keepdims=True)\n",
        "\n",
        "cmp('bngain', dbngain, bngain)\n",
        "# cmp('bnbias', dbnbias, bnbias)\n",
        "# cmp('bnraw', dbnraw, bnraw)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ESmsrN4E2DPr",
        "outputId": "0b18fe28-691d-4c70-d4e8-978861dcd4f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bngain          | exact: False | approximate: True  | maxdiff: 2.7939677238464355e-09\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dloss/bnraw = bnraw/dhpreact * dloss/dhpreact\n",
        "# don't need sum because of shapes\n",
        "dbnraw = bngain * dhpreact\n",
        "\n",
        "cmp('bnraw', dbnraw, bnraw)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pegRRCPp4P_K",
        "outputId": "fc372d35-97dd-4c82-c693-8479cab2addb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bnraw           | exact: False | approximate: True  | maxdiff: 4.656612873077393e-10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dloss/bnbias = bnbias/dhpreact * dloss/dhpreact\n",
        "# don't need sum because of shapes\n",
        "dbnbias = dhpreact.sum(0, keepdims=True)\n",
        "\n",
        "cmp('dbnbias', dbnbias, bnbias)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_P8IOx2j4sPH",
        "outputId": "4a00f5ca-592f-4ffe-fe81-f9ba40cbc989"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dbnbias         | exact: False | approximate: True  | maxdiff: 5.587935447692871e-09\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## `dbngain, dbnbias, dbnraw`\n",
        "\n",
        "$$ h_{\\text{preact}} = \\text{bngain} \\times \\text{bnraw} + \\text{bnbias} $$\n",
        "\n",
        "### Understanding the Equation:\n",
        "\n",
        "1. $ h_{\\text{preact}} $ is the output we get after applying batch normalization and before passing it through the activation function.\n",
        "2. $ \\text{bngain} $ and $ \\text{bnbias} $ are learnable parameters in batch normalization. They are used to scale and shift the normalized output, respectively.\n",
        "3. $ \\text{bnraw} $ is the normalized output, which is the result of subtracting the mean and dividing by the standard deviation.\n",
        "\n",
        "### Backward Propagation:\n",
        "\n",
        "We want to determine how the loss changes with respect to $ \\text{bngain} $, $ \\text{bnraw} $, and $ \\text{bnbias} $.\n",
        "\n",
        "#### 1. Gradient with respect to $ \\text{bngain} $:\n",
        "\n",
        "Using the chain rule, the gradient with respect to $ \\text{bngain} $ can be calculated as:\n",
        "\n",
        "$$ \\frac{\\partial \\text{loss}}{\\partial \\text{bngain}} = \\frac{\\partial \\text{loss}}{\\partial h_{\\text{preact}}} \\times \\frac{\\partial h_{\\text{preact}}}{\\partial \\text{bngain}} $$\n",
        "\n",
        "Given that:\n",
        "\n",
        "$$ \\frac{\\partial h_{\\text{preact}}}{\\partial \\text{bngain}} = \\text{bnraw} $$\n",
        "\n",
        "Combining them, we get:\n",
        "\n",
        "$$ \\frac{\\partial \\text{loss}}{\\partial \\text{bngain}} = \\frac{\\partial \\text{loss}}{\\partial h_{\\text{preact}}} \\times \\text{bnraw} $$\n",
        "\n",
        "#### 2. Gradient with respect to $ \\text{bnraw} $:\n",
        "\n",
        "Similarly, for $ \\text{bnraw} $:\n",
        "\n",
        "$$ \\frac{\\partial \\text{loss}}{\\partial \\text{bnraw}} = \\frac{\\partial \\text{loss}}{\\partial h_{\\text{preact}}} \\times \\frac{\\partial h_{\\text{preact}}}{\\partial \\text{bnraw}} $$\n",
        "\n",
        "Given that:\n",
        "\n",
        "$$ \\frac{\\partial h_{\\text{preact}}}{\\partial \\text{bnraw}} = \\text{bngain} $$\n",
        "\n",
        "Combining them, we get:\n",
        "\n",
        "$$ \\frac{\\partial \\text{loss}}{\\partial \\text{bnraw}} = \\frac{\\partial \\text{loss}}{\\partial h_{\\text{preact}}} \\times \\text{bngain} $$\n",
        "\n",
        "#### 3. Gradient with respect to $ \\text{bnbias} $:\n",
        "\n",
        "The term $ \\text{bnbias} $ is added directly to $ h_{\\text{preact}} $, so:\n",
        "\n",
        "$$ \\frac{\\partial \\text{loss}}{\\partial \\text{bnbias}} = \\frac{\\partial \\text{loss}}{\\partial h_{\\text{preact}}} $$\n",
        "\n",
        "**Python code:**\n",
        "\n",
        "```python\n",
        "dbngain = (dhpreact * bnraw).sum(dim=0)\n",
        "dbnraw = dhpreact * bngain\n",
        "dbnbias = dhpreact.sum(dim=0)\n",
        "```\n",
        "\n",
        "**In Summary**:\n",
        "\n",
        "- The gradient with respect to $ \\text{bngain} $ tells us how much the loss would change if we adjust the scaling after normalization.\n",
        "- The gradient with respect to $ \\text{bnraw} $ indicates how the loss would change with changes to the normalized output.\n",
        "- The gradient with respect to $ \\text{bnbias} $ reveals the impact of the bias term in the batch normalization on the loss."
      ],
      "metadata": {
        "id": "vDZ3lEOf4_LL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The shapes of the tensors\n",
        "\n",
        "The difference in behavior stems from the shapes of the tensors and the operations being performed. Let's dive into this by examining the shapes you've provided:\n",
        "\n",
        "- `hpreact`: $ 32 \\times 64 $ (batch size of 32, and 64 features or neurons)\n",
        "- `bngain` and `bnbias`: $1 \\times 64$ (broadcastable to $32 \\times 64$)\n",
        "- `bnraw`: $32 \\times 64$\n",
        "\n",
        "Given the equation:\n",
        "\n",
        "$$ \\text{hpreact} = \\text{bngain} \\times \\text{bnraw} + \\text{bnbias} $$\n",
        "\n",
        "1. **For `bngain` and `bnbias`:**\n",
        "    When `bngain` (or `bnbias`) is multiplied (or added) to `bnraw`, broadcasting is used due to their shape being $1 \\times 64$. This means the same values of `bngain` are multiplied with each of the 32 examples in the batch for every feature. When you're calculating the gradient with respect to `bngain` (or `bnbias`), you're aggregating the effect across all examples in the batch for each feature. That's why you sum over the batch dimension, resulting in a tensor of shape $1 \\times 64$, which matches the shape of `bngain` (or `bnbias`).\n",
        "\n",
        "2. **For `bnraw`:**\n",
        "    The gradient `dbnraw` has the same shape as `bnraw`, i.e., $32 \\times 64$. Since `bnraw` is an intermediate result for each example in the batch and isn't shared across examples (unlike `bngain` and `bnbias`), there's no aggregation (sum) required over the batch dimension. Each example's `bnraw` value has its own gradient, and there's no need to sum them.\n",
        "\n",
        "In essence, the sums for `bngain` and `bnbias` are due to the broadcasting during the forward pass. The same values of `bngain` and `bnbias` affect every example in the batch. Hence, during backpropagation, the gradients from each example in the batch need to be summed to get the total gradient for `bngain` and `bnbias`. On the other hand, `bnraw` is calculated individually for each example, so its gradients are also individual and don't need to be summed."
      ],
      "metadata": {
        "id": "lkfwlID59NHG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Theoretical vs Practical Gradient Computation\n",
        "\n",
        "The summation over the batch dimension in the PyTorch implementation addresses a subtle but crucial aspect of mini-batch gradient descent.\n",
        "\n",
        "### Theoretical vs Practical Gradient Computation:\n",
        "\n",
        "In the theoretical derivation, we look at the gradient computation for a single data point. When we compute the gradient for a mini-batch, it's essentially the average of the gradients for each individual data point in the mini-batch. The backward pass computes the gradients for each data point, and then we usually sum these gradients across the batch to get the total gradient for the mini-batch.\n",
        "\n",
        "### Why the Summation?\n",
        "\n",
        "When you perform mini-batch gradient descent, you're averaging the loss across the batch. Thus, the gradient for each parameter is an average gradient over the batch. The sum operation is essentially summing up the gradients for each data point in the batch for each parameter.\n",
        "\n",
        "In the specific context of batch normalization:\n",
        "\n",
        "1. **dbngain**: The gradient with respect to `bngain` is affected by every example in the batch. For each example, we have a gradient value. To get the overall gradient for `bngain` for the entire batch, we sum across all these individual gradients. This gives us a single gradient value for `bngain` which will be used for the update.\n",
        "\n",
        "2. **dbnbias**: Similarly, the gradient with respect to `bnbias` is affected by every example in the batch. Summing across all examples gives us the total gradient for `bnbias`.\n",
        "\n",
        "### Important Note:\n",
        "\n",
        "It's worth noting that, after summing, many deep learning frameworks, including PyTorch, will often divide by the batch size if you're computing the mean loss over the batch. This effectively averages the summed gradients, which scales them appropriately for the update. Whether you sum (as in the code provided) or average depends on how the forward pass (loss computation) is structured and how you plan to apply the gradient updates.\n",
        "\n",
        "In the provided code, the summation effectively calculates the total gradient for the batch. If you were to subsequently average your gradients, you'd divide by the batch size during the update step."
      ],
      "metadata": {
        "id": "EGiv_b687peM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# `bnraw = bndiff * bnvar_inv`"
      ],
      "metadata": {
        "id": "d1aJkR3h-eZG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bnraw.shape, bndiff.shape, bnvar_inv.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hgwKN5lpB7CY",
        "outputId": "9c2151bb-1a0e-4ff7-fe68-ee0a43ae6ab9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([32, 64]), torch.Size([32, 64]), torch.Size([1, 64]))"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# bnraw = bndiff * bnvar_inv\n",
        "\n",
        "# dloss/bndiff = dbnvar_inv/bdndiff * dbndiff/dbraw\n",
        "\n",
        "dbndiff = bnvar_inv * dbnraw\n"
      ],
      "metadata": {
        "id": "Btd_CzTA-ucD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# bnraw = bndiff * bnvar_inv\n",
        "\n",
        "# dloss/dbnvar_inv = dbnraw/dbnvar_inv * dloss/dbnraw\n",
        "\n",
        "dbnvar_inv = (bndiff * dbnraw).sum(0, keepdims=True)\n",
        "cmp('bnvar_inv', dbnvar_inv, bnvar_inv)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RqY9zQ18DAWx",
        "outputId": "b474ee39-191b-478f-aa81-6d9e3bb35a3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bnvar_inv       | exact: False | approximate: True  | maxdiff: 7.450580596923828e-09\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## `dbnvar_inv, bdndiff`\n",
        "\n",
        "Let's break down the backpropagation through the equation:\n",
        "\n",
        "$$ \\text{bnraw} = \\text{bndiff} \\times \\text{bnvar_inv} $$\n",
        "\n",
        "Given that we already have $ \\frac{\\partial \\text{loss}}{\\partial \\text{bnraw}} $ (denoted as `dbnraw` for simplicity), we need to find $ \\frac{\\partial \\text{loss}}{\\partial \\text{bndiff}} $ and $ \\frac{\\partial \\text{loss}}{\\partial \\text{bnvar_inv}} $.\n",
        "\n",
        "### 1. Gradient with respect to `bndiff`:\n",
        "\n",
        "Using the chain rule:\n",
        "\n",
        "$$ \\frac{\\partial \\text{loss}}{\\partial \\text{bndiff}} = \\frac{\\partial \\text{loss}}{\\partial \\text{bnraw}} \\times \\frac{\\partial \\text{bnraw}}{\\partial \\text{bndiff}} $$\n",
        "\n",
        "Given that $ \\text{bnraw} $ is a product of $ \\text{bndiff} $ and $ \\text{bnvar\\_inv} $, the gradient is simply:\n",
        "\n",
        "$$ \\frac{\\partial \\text{bnraw}}{\\partial \\text{bndiff}} = \\text{bnvar_inv} $$\n",
        "\n",
        "Therefore, in PyTorch:\n",
        "\n",
        "```python\n",
        "dbndiff = dbnraw * bnvar_inv\n",
        "```\n",
        "\n",
        "### 2. Gradient with respect to `bnvar_inv`:\n",
        "\n",
        "Using the chain rule:\n",
        "\n",
        "$$ \\frac{\\partial \\text{loss}}{\\partial \\text{bnvar_inv}} = \\frac{\\partial \\text{loss}}{\\partial \\text{bnraw}} \\times \\frac{\\partial \\text{bnraw}}{\\partial \\text{bnvar_inv}} $$\n",
        "\n",
        "Given that $ \\text{bnraw} $ is a product of $ \\text{bndiff} $ and $ \\text{bnvar_inv} $, the gradient is:\n",
        "\n",
        "$$ \\frac{\\partial \\text{bnraw}}{\\partial \\text{bnvar_inv}} = \\text{bndiff} $$\n",
        "\n",
        "Therefore, in PyTorch:\n",
        "\n",
        "```python\n",
        "dbnvar_inv = (dbnraw * bndiff).sum(dim=0, keepdim=True)\n",
        "```\n",
        "\n",
        "The `sum` operation is used here because during the forward pass, `bnvar_inv` (of shape $1 \\times \\text{features}$) gets broadcasted to match the shape of `bndiff` (of shape $ \\text{batch_size} \\times \\text{features} $), and thus, during the backward pass, we aggregate the gradients across the batch dimension to match the original shape of `bnvar_inv`.\n",
        "\n",
        "In summary, `dbndiff` and `dbnvar_inv` represent the gradients of the loss with respect to `bndiff` and `bnvar_inv` respectively, and they are calculated using the chain rule based on the operations performed during the forward pass."
      ],
      "metadata": {
        "id": "QhSab2LeEo1D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# `bnvar_inv = (bnvar + 1e-5)**-0.5`"
      ],
      "metadata": {
        "id": "vkKF_0I9Gnfd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# bnvar_inv = (bnvar + 1e-5)**-0.5\n",
        "\n",
        "# power rule then chain rule\n",
        "\n",
        "# dbnvar = (local derivative of bnvar) * dbnvar_inv\n",
        "\n",
        "dbnvar = (-0.5*(bnvar + 1e-5)**-1.5) * dbnvar_inv\n",
        "\n",
        "cmp('bnvar', dbnvar, bnvar)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_vkWf1HCGrkR",
        "outputId": "958ced7c-2a09-43b8-9043-e4ec97ced056"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bnvar           | exact: False | approximate: True  | maxdiff: 1.862645149230957e-09\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## `dbnvar`\n",
        "\n",
        "Let's delve into the backpropagation for the equation:\n",
        "\n",
        "$$ \\text{bnvar_inv} = (\\text{bnvar} + 1 \\times 10^{-5})^{-0.5} $$\n",
        "\n",
        "Given that we already have $ \\frac{\\partial \\text{loss}}{\\partial \\text{bnvar_inv}} $ (denoted as `dbnvar_inv` for clarity), we want to compute $ \\frac{\\partial \\text{loss}}{\\partial \\text{bnvar}} $, or `dbnvar`.\n",
        "\n",
        "### Deriving the gradient with respect to `bnvar`:\n",
        "\n",
        "Using the chain rule:\n",
        "\n",
        "$$ \\frac{\\partial \\text{loss}}{\\partial \\text{bnvar}} = \\frac{\\partial \\text{loss}}{\\partial \\text{bnvar_inv}} \\times \\frac{\\partial \\text{bnvar_inv}}{\\partial \\text{bnvar}} $$\n",
        "\n",
        "The partial derivative $ \\frac{\\partial \\text{bnvar_inv}}{\\partial \\text{bnvar}} $ is derived from the given function. Taking the derivative of $ \\text{bnvar_inv} $ with respect to $ \\text{bnvar} $ using **The Power Rule**  gives:\n",
        "\n",
        "$$ \\frac{\\partial \\text{bnvar_inv}}{\\partial \\text{bnvar}} = -0.5 (\\text{bnvar} + 1 \\times 10^{-5})^{-1.5} $$\n",
        "\n",
        "Now, combining this with our known `dbnvar_inv`, we get:\n",
        "\n",
        "$$ \\frac{\\partial \\text{loss}}{\\partial \\text{bnvar}} = \\text{dbnvar_inv} \\times (-0.5 (\\text{bnvar} + 1 \\times 10^{-5})^{-1.5}) $$\n",
        "\n",
        "### In PyTorch:\n",
        "\n",
        "```python\n",
        "dbnvar = dbnvar_inv * (-0.5 * (bnvar + 1e-5)**-1.5)\n",
        "```\n",
        "\n",
        "In essence, `dbnvar` represents the gradient of the loss with respect to `bnvar`. This gradient is computed by multiplying the gradient with respect to `bnvar_inv` (which we already have) by the derivative of the function that computes `bnvar_inv` from `bnvar`."
      ],
      "metadata": {
        "id": "Ys8_MJz7Ils8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# `bnvar = 1/(n-1)*(bndiff2).sum(0, keepdim=True)`"
      ],
      "metadata": {
        "id": "6Qn0YmUlLC2D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# bnvar = 1/(n-1)*(bndiff2).sum(0, keepdim=True)"
      ],
      "metadata": {
        "id": "DA2jKRW-LHtL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bnvar.shape, bndiff2.shape, n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oiT9gAY-LPHv",
        "outputId": "33045218-4c7c-4d86-88dc-bf147e610183"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1, 64]), torch.Size([32, 64]), 32)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(bndiff2).sum(0, keepdim=True).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PQLLWaL0Lom6",
        "outputId": "8b59e423-6d22-457d-a4e5-d14a60525101"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 64])"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# alternative implementation\n",
        "\n",
        "# dbndiff2 = (1.0 / (n - 1))*torch.ones_like(bndiff2) * dbnvar"
      ],
      "metadata": {
        "id": "gqI-5bQKaukD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dbndiff2 = dbnvar * (1.0 / (n - 1))\n",
        "cmp('bndiff2', dbndiff2, bndiff2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "27RJ_H--LyRm",
        "outputId": "326ab493-60c0-4cda-c693-9ac623939f21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bndiff2         | exact: False | approximate: True  | maxdiff: 5.820766091346741e-11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## `dbndiff2`\n",
        "\n",
        "Let's break down the backpropagation for the equation:\n",
        "\n",
        "$$ \\text{bnvar} = \\frac{1}{n-1} \\sum_{i} \\text{bndiff2}_i $$\n",
        "\n",
        "Given that we already have $ \\frac{\\partial \\text{loss}}{\\partial \\text{bnvar}} $ (denoted as `dbnvar`), we want to compute $ \\frac{\\partial \\text{loss}}{\\partial \\text{bndiff2}} $, or `dbndiff2`.\n",
        "\n",
        "### Deriving the gradient with respect to `bndiff2`:\n",
        "\n",
        "Using the chain rule:\n",
        "\n",
        "$$ \\frac{\\partial \\text{loss}}{\\partial \\text{bndiff2}_i} = \\frac{\\partial \\text{loss}}{\\partial \\text{bnvar}} \\times \\frac{\\partial \\text{bnvar}}{\\partial \\text{bndiff2}_i} $$\n",
        "\n",
        "For each element `i` in the batch, the partial derivative $ \\frac{\\partial \\text{bnvar}}{\\partial \\text{bndiff2}_i} $ is simply $ \\frac{1}{n-1} $. This is because the summation in the equation for `bnvar` essentially adds up each element of `bndiff2`, and the gradient with respect to each element is the coefficient in front of the summation, which is $ \\frac{1}{n-1} $.\n",
        "\n",
        "Using the power rule:\n",
        "\n",
        "$$ \\frac{\\partial \\text{loss}}{\\partial \\text{bndiff2}} = \\text{dbnvar} \\times \\frac{1}{n-1} $$\n",
        "\n",
        "### In PyTorch:\n",
        "\n",
        "Considering the shapes involved:\n",
        "\n",
        "- `dbnvar`: (1, 64)\n",
        "- `bndiff2`: (32, 64)\n",
        "\n",
        "Since `dbnvar` needs to be applied to each instance in the batch, broadcasting will be employed when we perform the multiplication:\n",
        "\n",
        "```python\n",
        "dbndiff2 = dbnvar * (1.0 / (n - 1))\n",
        "```\n",
        "\n",
        "Here, `dbndiff2` is the gradient of the loss with respect to `bndiff2`, and it's computed by multiplying the gradient with respect to `bnvar` (which we already have) by the coefficient $ \\frac{1}{n-1} $. Broadcasting takes care of applying this coefficient to each batch element."
      ],
      "metadata": {
        "id": "JgJFLW_7MLJJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## `Bessel's Correction`\n",
        "\n",
        "When you have a set of data and you want to estimate its variance, you often use the formula:\n",
        "\n",
        "$$ \\text{variance} = \\frac{\\sum_{i=1}^{n} (x_i - \\text{mean})^2}{n} $$\n",
        "\n",
        "However, when using this formula on a sample from a larger population (rather than the entire population itself), it tends to slightly underestimate the actual variance of the whole population. This is particularly noticeable when the sample size is small.\n",
        "\n",
        "Bessel's Correction is a simple adjustment to correct this bias. Instead of dividing by \\( n \\) (the number of data points), we divide by \\( n-1 \\):\n",
        "\n",
        "$$ \\text{corrected variance} = \\frac{\\sum_{i=1}^{n} (x_i - \\text{mean})^2}{n-1} $$\n",
        "\n",
        "**Why \"n-1\" and not \"n\"?**\n",
        "\n",
        "Imagine you're measuring the height of students in a classroom to estimate the average height of all students in the school. If you only measure 2 students, the average of their heights will match one of the student's heights exactly. So, your estimation of the variability (variance) based on these 2 students will be lower than the actual variance in the whole school.\n",
        "\n",
        "By using \\( n-1 \\), we're essentially giving more \"weight\" to the variability we've observed in our sample, making our estimate a bit larger and, on average, more accurate.\n",
        "\n",
        "### Summary:\n",
        "\n",
        "Bessel's Correction is like giving your sample variance a small boost to make it a better estimate of the entire population's variance, especially when working with small samples. It's a statistical tweak to ensure our variance estimate isn't too optimistic (or low)."
      ],
      "metadata": {
        "id": "HA-aQxH0OrzE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# `bnvar = 1/(n-1)*(bndiff2).sum(0, keepdim=True)`"
      ],
      "metadata": {
        "id": "TmfXwCUPW45G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bndiff2.shape, bndiff.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AYtbdYB9XbQa",
        "outputId": "1376a3e2-f30b-4133-9278-f6e71c2cd756"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([32, 64]), torch.Size([32, 64]))"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# bndiff2 = bndiff**2\n",
        "\n",
        "# branc 1\n",
        "dbndiff = bnvar_inv * dbnraw\n",
        "\n",
        "dbndiff += 2.0 * bndiff * dbndiff2\n",
        "\n",
        "cmp('bndiff', dbndiff, bndiff)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m0wQDAWDW-_9",
        "outputId": "8057e29d-ece1-48c6-a799-7ec1e8cda857"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bndiff          | exact: False | approximate: True  | maxdiff: 4.656612873077393e-10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# `bndiff2 = bndiff**2`\n"
      ],
      "metadata": {
        "id": "MOEqZkimXzAS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dbndiff = 2 * bndiff * dbndiff2"
      ],
      "metadata": {
        "id": "2tiMwHbbFvHY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## `dnbdiff`\n",
        "\n",
        "Let's break down the process of backpropagation through the operation $ \\text{bndiff}^2 $.\n",
        "\n",
        "### Forward Pass:\n",
        "You have a tensor, $ \\text{bndiff} $, and you square each element in this tensor to get $ \\text{bndiff}^2 $.\n",
        "\n",
        "### Mathematical Representation:\n",
        "$$ \\text{bndiff2}_i = \\text{bndiff}_i^2 $$\n",
        "\n",
        "Where $ i $ is the index of a specific element in our tensors.\n",
        "\n",
        "### Backward Pass:\n",
        "To find how the loss $ L $ changes with respect to $ \\text{bndiff} $, you'd want to know how a small change in $ \\text{bndiff} $ affects $ L $ through $ \\text{bndiff}^2 $. This is essentially finding the gradient $ \\frac{\\partial L}{\\partial \\text{bndiff}_i} $.\n",
        "\n",
        "Using the chain rule and the power rule of differentiation, we can compute the gradient:\n",
        "\n",
        "$$ \\frac{\\partial L}{\\partial \\text{bndiff}_i} = \\frac{\\partial L}{\\partial \\text{bndiff2}_i} \\times \\frac{\\partial \\text{bndiff2}_i}{\\partial \\text{bndiff}_i} $$\n",
        "\n",
        "Now, focusing on the second term, the derivative of $ \\text{bndiff}_i^2 $ with respect to $ \\text{bndiff}_i $ is:\n",
        "\n",
        "$$ \\frac{\\partial \\text{bndiff2}_i}{\\partial \\text{bndiff}_i} = 2 \\times \\text{bndiff}_i $$\n",
        "\n",
        "### PyTorch Implementation:\n",
        "Given that we already have $ \\frac{\\partial L}{\\partial \\text{bndiff2}} $ (let's call this tensor $ \\text{dbndiff2} $), we can compute $ \\frac{\\partial L}{\\partial \\text{bndiff}} $ (or $ \\text{dbndiff} $) as:\n",
        "\n",
        "```python\n",
        "dbndiff = 2 * bndiff * dbndiff2\n",
        "```\n",
        "\n",
        "### Summary:\n",
        "Squaring operations amplify the effects of the original values. During backpropagation, this operation effectively scales the gradients by $ 2 \\times \\text{bndiff} $, making larger values in $ \\text{bndiff} $ have even larger gradients and, thus, larger updates during optimization."
      ],
      "metadata": {
        "id": "61Yhe4KQF2Xz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# `bndiff = hprebn - bnmeani`"
      ],
      "metadata": {
        "id": "ypat99obcrc5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bndiff.shape, hprebn.shape, bnmeani.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gj0arnLedEon",
        "outputId": "f1b50498-df4a-4be7-f489-e848c7c78ce0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([32, 64]), torch.Size([32, 64]), torch.Size([1, 64]))"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# bndiff = hprebn - bnmeani\n",
        "\n",
        "dbnmeani = -dbndiff.sum(dim=0, keepdim=True)\n",
        "\n",
        "cmp('bnmeani', dbnmeani, bnmeani)\n",
        "\n",
        "# cmp('hprebn', dhprebn, hprebn)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eiTeet17cyl3",
        "outputId": "cea4111f-70e8-47c9-d43e-535a5d68e497"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bnmeani         | exact: False | approximate: True  | maxdiff: 3.725290298461914e-09\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# bndiff = hprebn - bnmeani\n",
        "\n",
        "dhprebn = dbndiff.clone()\n",
        "\n",
        "cmp('hprebn', dhprebn, hprebn)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zeTRmmwNrMfi",
        "outputId": "c9d69275-e74b-4a8f-cdc3-19b02af4c919"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hprebn          | exact: False | approximate: False | maxdiff: 0.0011816248297691345\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## `hprebn` and `bnmeani`\n",
        "\n",
        "Let's look at the subtraction operation and understand its gradient propagation.\n",
        "\n",
        "### Forward Pass:\n",
        "You have two tensors, `hprebn` and `bnmeani`. You subtract `bnmeani` from each row of `hprebn` to get the tensor `bndiff`.\n",
        "\n",
        "### Mathematical Representation:\n",
        "For each element in the tensor:\n",
        "$$ \\text{bndiff}_{ij} = \\text{hprebn}_{ij} - \\text{bnmeani}_{j} $$\n",
        "Where \\( i \\) represents the batch index and \\( j \\) represents the feature index.\n",
        "\n",
        "### Backward Pass:\n",
        "\n",
        "1. **Gradient with respect to hprebn ($ \\text{dhprebn} $):** For each element in `hprebn`, its contribution to the corresponding element in `bndiff` is +1. Hence, the gradient of `bndiff` with respect to `hprebn` is an identity operation. In other words, the gradient simply \"passes through\" without any change.\n",
        "   \n",
        "   Mathematical representation:\n",
        "   $$ \\frac{\\partial \\text{bndiff}_{ij}}{\\partial \\text{hprebn}_{ij}} = 1 $$\n",
        "   \n",
        "   So, the gradient $ \\text{dhprebn} $ is:\n",
        "   $$ \\text{dhprebn}_{ij} = \\text{dbndiff}_{ij} $$\n",
        "\n",
        "2. **Gradient with respect to bnmeani ($ \\text{dbnmeani} $):** Now, for `bnmeani`, each element in `bnmeani` affects all rows of `bndiff` in the corresponding column. The contribution of each element in `bnmeani` to `bndiff` is -1. Since each element in `bnmeani` affects all the rows in `bndiff`, the gradient for each element in `bnmeani` is the sum of gradients for all rows in `bndiff` for the corresponding column.\n",
        "\n",
        "   Mathematical representation:\n",
        "   $$ \\frac{\\partial \\text{bndiff}_{ij}}{\\partial \\text{bnmeani}_{j}} = -1 $$\n",
        "   \n",
        "   Summing over all rows (batch dimension):\n",
        "   $$ \\text{dbnmeani}_{j} = \\sum_{i} (-\\text{dbndiff}_{ij}) $$\n",
        "\n",
        "### PyTorch Implementation:\n",
        "Given that we already have $ \\text{dbndiff} $, we can compute $ \\text{dhprebn} $ and $ \\text{dbnmeani} $ as:\n",
        "\n",
        "```python\n",
        "dhprebn = dbndiff\n",
        "dbnmeani = -dbndiff.sum(dim=0, keepdim=True)\n",
        "```\n",
        "\n",
        "### Summary:\n",
        "The operation `hprebn - bnmeani` is a simple subtraction where the gradient for `hprebn` just \"passes through\" and for `bnmeani`, the gradient is aggregated (summed up) across the batch dimension since `bnmeani` affects all rows of `bndiff`. The broadcasting in the forward operation (subtracting a [1, 64] tensor from a [32, 64] tensor) gets reflected as a sum in the backward pass."
      ],
      "metadata": {
        "id": "RQb3NYb1mjUC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Addition and subtraction operations in\n",
        "\n",
        "Addition and subtraction operations are among the simplest in terms of backpropagation due to their straightforward derivatives. Here's a brief explanation:\n",
        "\n",
        "Similarly for \\( b \\).\n",
        "1. **Addition**:\n",
        "  If you have a function f = a + b , the derivative with respect to both \\( a \\) and \\( b \\) is 1. This means that any change in \\( a \\) or \\( b \\) has a direct 1-to-1 effect on \\( f \\). During backpropagation, the gradient simply \"passes through\" the addition operation without any modification.\n",
        "  \n",
        "  Chain rule for addition:\n",
        "  $$\n",
        "  \\frac{\\partial f}{\\partial a} = \\frac{\\partial f}{\\partial f} \\times \\frac{\\partial f}{\\partial a} = 1 \\times 1 = 1\n",
        "  $$\n",
        "  Similarly for \\( b \\).\n",
        "\n",
        "2. **Subtraction**:\n",
        "  If you have a function \\( g = a - b \\), the derivative with respect to \\( a \\) is 1, while with respect to \\( b \\), it's -1. This means that an increase in \\( a \\) increases \\( g \\) directly, while an increase in \\( b \\) decreases \\( g \\). During backpropagation, the gradient again \"passes through\" for \\( a \\) but with a sign change for \\( b \\).\n",
        "  \n",
        "  Chain rule for subtraction:\n",
        "  $$\n",
        "  \\frac{\\partial g}{\\partial a} = \\frac{\\partial g}{\\partial g} \\times \\frac{\\partial g}{\\partial a} = 1 \\times 1 = 1\n",
        "  $$\n",
        "  And:\n",
        "  $$\n",
        "  \\frac{\\partial g}{\\partial b} = \\frac{\\partial g}{\\partial g} \\times \\frac{\\partial g}{\\partial b} = 1 \\times (-1) = -1\n",
        "  $$\n",
        "\n",
        "So, while we technically apply the chain rule for all operations during backpropagation, the nature of addition and subtraction makes their chain rule applications particularly straightforward. The gradients essentially propagate back without modification for addition and with just a sign change for subtraction."
      ],
      "metadata": {
        "id": "OujJgBNao-Yb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# `bnmeani = 1/n*hprebn.sum(0, keepdim=True)`"
      ],
      "metadata": {
        "id": "sD8NHT_nt8tk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bnmeani = 1/n*hprebn.sum(0, keepdim=True)\n",
        "\n",
        "dhprebn += (1/n)* dbnmeani\n",
        "\n",
        "# dhprebn += (1.0/n) * torch.ones_like(hprebn)\n",
        "\n",
        "cmp('hprebn', dhprebn, hprebn)\n",
        "\n",
        "# dloss/dhprebn = dbnmeani/dhprebn * dloss/dbmeani"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rwVLCZIRuLIX",
        "outputId": "1499d8c5-828c-4729-bf5f-9dc8dad1c638"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hprebn          | exact: False | approximate: True  | maxdiff: 6.984919309616089e-10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bnmeani.shape, hprebn.shape, hprebn.sum(0, keepdim=True).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W4oLpEckwE6f",
        "outputId": "871a2d4d-8fc8-4ac2-a711-39478be12012"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1, 64]), torch.Size([32, 64]), torch.Size([1, 64]))"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dhprebn.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mvh5yd1kwVza",
        "outputId": "37060255-fec6-48df-ec4e-935b2d64e027"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 64])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## `dhprebn`\n",
        "\n",
        "The operation in the given line calculates the mean of `hprebn` across the batch (i.e., the first dimension). Specifically, for every feature (or neuron) in the hidden layer, it calculates the average activation across all examples in the batch.\n",
        "\n",
        "Mathematically:\n",
        "$$ \\text{bnmeani}_j = \\frac{1}{n} \\sum_{i=1}^{n} \\text{hprebn}_{ij} $$\n",
        "Where:\n",
        "- \\( i \\) is the index that runs over the batch size.\n",
        "- \\( j \\) is the index that runs over the feature dimension (in this case, 64).\n",
        "\n",
        "The above equation computes the mean for a single feature \\( j \\). This operation is repeated for all features.\n",
        "\n",
        "### Backpropagation:\n",
        "\n",
        "We want to compute: $ \\frac{\\partial \\text{bnmeani}_j}{\\partial \\text{hprebn}_{ij}} $.\n",
        "\n",
        "Given that bnmeani is a mean, the derivative of the mean with respect to any one of the terms being averaged is $ \\frac{1}{n} $. This is because if you were to slightly change one of the terms in the sum (i.e., one of the hprebn values), it would change the mean by that amount divided by the number of terms (n).\n",
        "\n",
        "### Intuition:\n",
        "Imagine you and your friends are splitting the bill at a restaurant, and you decide to contribute a bit more to the total amount (a small increase in one of the hprebn values). The average contribution (bnmeani) will only increase by your extra amount divided by the number of friends (including you).\n",
        "\n",
        "### In terms of tensors:\n",
        "Given the shapes `hprebn.shape = torch.Size([32, 64])` and `bnmeani.shape = torch.Size([1, 64])`, the gradient $ \\frac{\\partial \\text{bnmeani}}{\\partial \\text{hprebn}} $ will have the shape of `hprebn`, which is `[32, 64]`.\n",
        "\n",
        "For every feature \\( j \\), all 32 values in the batch dimension of `hprebn` for that feature would have a gradient of $ \\frac{1}{32} $ (because $ n = 32 $).\n",
        "\n",
        "### PyTorch code:\n",
        "```python\n",
        "dhprebn = (1.0/n) * torch.ones_like(hprebn)\n",
        "```\n",
        "\n",
        "This code will create a tensor with the same shape as `hprebn` where every entry is $ \\frac{1}{32} $."
      ],
      "metadata": {
        "id": "kA3WxY75v0iT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# `hprebn = embcat @ W1 + b1`"
      ],
      "metadata": {
        "id": "jCvDK6AjtILh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# hprebn = embcat @ W1 + b1\n",
        "\n",
        "# cmp('embcat', dembcat, embcat)\n",
        "# cmp('W1', dW1, W1)\n",
        "# cmp('b1', db1, b1)"
      ],
      "metadata": {
        "id": "smnCFjxAyHSt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hprebn.shape, embcat.shape, W1.shape, b1.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rTOIgcqKyPph",
        "outputId": "ef97a6c5-8b9d-48a9-971e-e6ecb7c835ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([32, 64]),\n",
              " torch.Size([32, 30]),\n",
              " torch.Size([30, 64]),\n",
              " torch.Size([64]))"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dembcat = dhprebn @ W1.T\n",
        "\n",
        "cmp('embcat', dembcat, embcat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wEpqGGHVyj9q",
        "outputId": "40174805-7581-4f00-ff00-f3fcb84c9563"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "embcat          | exact: False | approximate: True  | maxdiff: 1.862645149230957e-09\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dW1 = embcat.T @ dhprebn\n",
        "cmp('W1', dW1, W1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03NoGbpszTP9",
        "outputId": "42c1145e-2dfe-47da-88c8-23e567a95665"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "W1              | exact: False | approximate: True  | maxdiff: 7.450580596923828e-09\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "db1 = dhprebn.sum(0)\n",
        "cmp('db1', db1, b1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XHlEtaspznWC",
        "outputId": "66258f9d-004a-46e0-da0b-26bb89a068e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "db1             | exact: False | approximate: True  | maxdiff: 3.725290298461914e-09\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## `dembcat`, `dW1` and `db1`\n",
        "\n",
        "Let's break down the backpropagation for the equation:\n",
        "\n",
        "$$ \\text{hprebn} = \\text{embcat} @ \\text{W1} + \\text{b1} $$\n",
        "\n",
        "Here, the \"@\" symbol represents matrix multiplication.\n",
        "\n",
        "### 1. $ \\frac{\\partial \\text{hprebn}}{\\partial \\text{embcat}} $ (Gradient with respect to `embcat`):\n",
        "\n",
        "If you think of `embcat @ W1` as a series of dot products, then for each neuron in `hprebn`, its value is influenced by every element in `embcat` through the weights in `W1`.\n",
        "\n",
        "The gradient of a given neuron in `hprebn` with respect to `embcat` is just the corresponding column in `W1`. This is because a change in a particular element of `embcat` would affect the output neuron linearly according to the weight connecting them.\n",
        "\n",
        "Thus, when you consider the entire matrix `hprebn` (batch_size x hidden_size), its gradient with respect to `embcat` (batch_size x (n_embd * block_size)) will be given by:\n",
        "\n",
        "$$ \\frac{\\partial \\text{hprebn}}{\\partial \\text{embcat}} = \\text{W1}^T $$\n",
        "\n",
        "The transpose is due to the way matrix multiplication works.\n",
        "\n",
        "### PyTorch code:\n",
        "```python\n",
        "dembcat = dhprebn @ W1.T\n",
        "```\n",
        "\n",
        "### 2. $ \\frac{\\partial \\text{hprebn}}{\\partial \\text{W1}} $ (Gradient with respect to `W1`):\n",
        "\n",
        "For each weight in `W1`, its influence on a given neuron in `hprebn` is proportional to the value of the corresponding input neuron in `embcat`.\n",
        "\n",
        "When considering the entire matrix of weights `W1`, the gradient will be the outer product of the gradient of `hprebn` with respect to its input and the input itself (`embcat`).\n",
        "\n",
        "### PyTorch code:\n",
        "```python\n",
        "dW1 = embcat.T @ dhprebn\n",
        "```\n",
        "\n",
        "### 3. $ \\frac{\\partial \\text{hprebn}}{\\partial \\text{b1}} $ (Gradient with respect to `b1`):\n",
        "\n",
        "Each bias in `b1` just gets added to the corresponding neuron in `hprebn`. So, the gradient of `hprebn` with respect to `b1` is a vector of ones for each example in the batch, summed across the batch dimension.\n",
        "\n",
        "### PyTorch code:\n",
        "```python\n",
        "db1 = dhprebn.sum(dim=0)\n",
        "```\n",
        "\n",
        "In summary:\n",
        "- `dembcat` shows how much `hprebn` changes with a change in `embcat`.\n",
        "- `dW1` shows how much `hprebn` changes with a change in `W1`.\n",
        "- `db1` shows how much `hprebn` changes with a change in `b1`."
      ],
      "metadata": {
        "id": "mYgzju3J0WnF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# `embcat = emb.view(emb.shape[0], -1)`"
      ],
      "metadata": {
        "id": "DLl-S2b57ZgC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embcat.shape, emb.shape, emb.view(emb.shape[0], -1).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1rydr4hQ70Hj",
        "outputId": "5daba817-d07c-498b-8804-7e7e93593112"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([32, 30]), torch.Size([32, 3, 10]), torch.Size([32, 30]))"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# embcat = emb.view(emb.shape[0], -1)\n",
        "\n",
        "demb = dembcat.view(emb.shape)\n",
        "cmp('emb', demb, emb)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aLCS42TP7r11",
        "outputId": "d0590b6b-b7d8-4465-b715-e04c30668892"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "emb             | exact: False | approximate: True  | maxdiff: 1.862645149230957e-09\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## `demb`\n",
        "\n",
        "Let's understand the operation:\n",
        "\n",
        "$$ \\text{embcat} = \\text{emb}.view(\\text{emb}.shape[0], -1) $$\n",
        "\n",
        "This line takes the 3D tensor `emb` with shape (batch_size, sequence_length, embedding_size) and reshapes it into a 2D matrix `embcat` with shape (batch_size, sequence_length * embedding_size).\n",
        "\n",
        "The backpropagation process here is straightforward: since the `view()` operation doesn't change the values in the tensor, but only rearranges them, the gradient simply flows back to the positions they were originally in.\n",
        "\n",
        "### $ \\frac{\\partial \\text{embcat}}{\\partial \\text{emb}} $ (Gradient with respect to `emb`):\n",
        "\n",
        "The gradient with respect to `emb` is just the gradient of `embcat` reshaped back to the original shape of `emb`.\n",
        "\n",
        "In more intuitive terms:\n",
        "- If a particular value in `embcat` influences the loss by some amount, the same value (which came from `emb`) in `emb` influences the loss by the same amount.\n",
        "- The reshaping operation is just about rearranging these values, so the gradients merely \"follow\" these values back to their original positions.\n",
        "\n",
        "### PyTorch code:\n",
        "```python\n",
        "demb = dembcat.view(emb.shape)\n",
        "```\n",
        "\n",
        "In summary:\n",
        "- The gradient `demb` shows how much the loss changes with a change in `emb`, and it's simply the gradient of `embcat` reshaped back to the shape of `emb`."
      ],
      "metadata": {
        "id": "OV8PoiMN9egg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# `emb = C[Xb]`"
      ],
      "metadata": {
        "id": "5Fh9YcsX-hD8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "emb.shape, C.shape, Xb.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9FfHND_1-2uC",
        "outputId": "d4230eed-633e-4040-a5ef-14abac2ed4a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([32, 3, 10]), torch.Size([27, 10]), torch.Size([32, 3]))"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Xb[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kVWGzf_LBNXr",
        "outputId": "7481abda-8c88-4128-fbe3-81a5aedb9d43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1,  1,  4],\n",
              "        [18, 14,  1],\n",
              "        [11,  5,  9],\n",
              "        [ 0,  0,  1],\n",
              "        [12, 15, 14]])"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# emb = C[Xb]\n",
        "\n",
        "# dC = torch.zeros_like(C)\n",
        "# dC.index_add_(0, Xb.view(-1), demb.view(-1, C.shape[1]))\n",
        "\n",
        "dC = torch.zeros_like(C)\n",
        "for k in range(Xb.shape[0]):\n",
        "  for j in range(Xb.shape[1]):\n",
        "    ix = Xb[k,j]\n",
        "    dC[ix] += demb[k,j]\n",
        "\n",
        "\n",
        "cmp('C', dC, C)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "suYPs1wW-7iV",
        "outputId": "2622e298-3b81-48f1-c52d-019564516a55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "C               | exact: False | approximate: True  | maxdiff: 5.587935447692871e-09\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`dC`\n",
        "\n",
        "The operation in focus is:\n",
        "\n",
        "$$ \\text{emb} = C[Xb] $$\n",
        "\n",
        "This line essentially means that we're indexing into the embedding matrix \\( C \\) using the indices in \\( Xb \\). For each row in \\( Xb \\), we're pulling out a corresponding row from \\( C \\) to construct $ \\text{emb} $.\n",
        "\n",
        "### Understanding the Gradient Flow:\n",
        "\n",
        "1. The gradient with respect to the embeddings matrix \\( C \\), denoted as \\( dC \\), tells us how much the loss would change for a tiny change in the values of \\( C \\).\n",
        "2. The gradient $ d\\text{emb} $ tells us how much the loss changes for a tiny change in the values of $ \\text{emb} $.\n",
        "\n",
        "Now, since each row of $ \\text{emb} $ is just a row from \\( C \\), the gradient for that particular row in \\( C \\) would be the gradient for the corresponding row in $ \\text{emb} $. If multiple rows in $ \\text{emb} $ correspond to the same row in \\( C \\) (due to repeated indices in \\( Xb \\)), the gradients for those rows in $ \\text{emb} $ would accumulate for that row in \\( C \\).\n",
        "\n",
        "In simpler terms:\n",
        "- If a particular embedding from \\( C \\) was used multiple times to construct $ \\text{emb} $, then the gradient for that embedding in \\( C \\) would be the sum of the gradients for all those times it was used.\n",
        "\n",
        "### PyTorch code:\n",
        "```python\n",
        "dC = torch.zeros_like(C)\n",
        "dC.index_add_(0, Xb.view(-1), demb.view(-1, C.shape[1]))\n",
        "```\n",
        "\n",
        "- The `index_add_` function accumulates the gradients from `demb` into the appropriate rows of `dC` based on the indices in `Xb`.\n",
        "\n",
        "In summary:\n",
        "- The gradient \\( dC \\) represents how much the loss changes with respect to changes in the embeddings matrix \\( C \\). For each embedding in \\( C \\) that was used to construct $ \\text{emb} $, its gradient is either the gradient of the corresponding row in $ \\text{emb} $ or the sum of multiple such gradients if that embedding was used multiple times."
      ],
      "metadata": {
        "id": "EV__c-m1_-my"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Summary of answers to Exercise 1"
      ],
      "metadata": {
        "id": "LeZIZB0ZHqLb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Exercise 1: backprop through the whole thing manually,\n",
        "# backpropagating through exactly all of the variables\n",
        "# as they are defined in the forward pass above, one by one\n",
        "\n",
        "# -----------------\n",
        "# YOUR CODE HERE :)\n",
        "# -----------------\n",
        "\n",
        "cmp('logprobs', dlogprobs, logprobs)\n",
        "cmp('probs', dprobs, probs)\n",
        "cmp('counts_sum_inv', dcounts_sum_inv, counts_sum_inv)\n",
        "cmp('counts_sum', dcounts_sum, counts_sum)\n",
        "cmp('counts', dcounts, counts)\n",
        "cmp('norm_logits', dnorm_logits, norm_logits)\n",
        "cmp('logit_maxes', dlogit_maxes, logit_maxes)\n",
        "cmp('logits', dlogits, logits)\n",
        "cmp('h', dh, h)\n",
        "cmp('W2', dW2, W2)\n",
        "cmp('b2', db2, b2)\n",
        "cmp('hpreact', dhpreact, hpreact)\n",
        "cmp('bngain', dbngain, bngain)\n",
        "cmp('bnbias', dbnbias, bnbias)\n",
        "cmp('bnraw', dbnraw, bnraw)\n",
        "cmp('bnvar_inv', dbnvar_inv, bnvar_inv)\n",
        "cmp('bnvar', dbnvar, bnvar)\n",
        "cmp('bndiff2', dbndiff2, bndiff2)\n",
        "cmp('bndiff', dbndiff, bndiff)\n",
        "# cmp('bnmeani', dbnmeani, bnmeani)\n",
        "cmp('hprebn', dhprebn, hprebn)\n",
        "cmp('embcat', dembcat, embcat)\n",
        "cmp('W1', dW1, W1)\n",
        "cmp('b1', db1, b1)\n",
        "cmp('emb', demb, emb)\n",
        "cmp('C', dC, C)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FQpavx7b2-7y",
        "outputId": "4e459114-8775-4328-8abe-5ae6e48e61e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "logprobs        | exact: True  | approximate: True  | maxdiff: 0.0\n",
            "probs           | exact: True  | approximate: True  | maxdiff: 0.0\n",
            "counts_sum_inv  | exact: True  | approximate: True  | maxdiff: 0.0\n",
            "counts_sum      | exact: True  | approximate: True  | maxdiff: 0.0\n",
            "counts          | exact: True  | approximate: True  | maxdiff: 0.0\n",
            "norm_logits     | exact: True  | approximate: True  | maxdiff: 0.0\n",
            "logit_maxes     | exact: True  | approximate: True  | maxdiff: 0.0\n",
            "logits          | exact: True  | approximate: True  | maxdiff: 0.0\n",
            "h               | exact: True  | approximate: True  | maxdiff: 0.0\n",
            "W2              | exact: True  | approximate: True  | maxdiff: 0.0\n",
            "b2              | exact: True  | approximate: True  | maxdiff: 0.0\n",
            "hpreact         | exact: False | approximate: True  | maxdiff: 4.656612873077393e-10\n",
            "bngain          | exact: False | approximate: True  | maxdiff: 1.862645149230957e-09\n",
            "bnbias          | exact: False | approximate: True  | maxdiff: 3.725290298461914e-09\n",
            "bnraw           | exact: False | approximate: True  | maxdiff: 9.313225746154785e-10\n",
            "bnvar_inv       | exact: False | approximate: True  | maxdiff: 3.725290298461914e-09\n",
            "bnvar           | exact: False | approximate: True  | maxdiff: 6.984919309616089e-10\n",
            "bndiff2         | exact: False | approximate: True  | maxdiff: 2.9103830456733704e-11\n",
            "bndiff          | exact: False | approximate: False | maxdiff: 0.0312500037252903\n",
            "hprebn          | exact: False | approximate: False | maxdiff: 0.032431624829769135\n",
            "embcat          | exact: False | approximate: False | maxdiff: 0.16928476095199585\n",
            "W1              | exact: False | approximate: False | maxdiff: 1.2596672773361206\n",
            "b1              | exact: False | approximate: False | maxdiff: 1.0378119945526123\n",
            "emb             | exact: False | approximate: True  | maxdiff: 1.862645149230957e-09\n",
            "C               | exact: False | approximate: True  | maxdiff: 5.587935447692871e-09\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# emb = C[Xb] # embed the characters into vectors\n",
        "# embcat = emb.view(emb.shape[0], -1) # concatenate the vectors\n",
        "# hprebn = embcat @ W1 + b1 # hidden layer pre-activation\n",
        "# bnmeani = 1/n*hprebn.sum(0, keepdim=True)\n",
        "# bndiff = hprebn - bnmeani\n",
        "# bndiff2 = bndiff**2\n",
        "# bnvar = 1/(n-1)*(bndiff2).sum(0, keepdim=True)\n",
        "# bnvar_inv = (bnvar + 1e-5)**-0.5\n",
        "# bnraw = bndiff * bnvar_inv\n",
        "# hpreact = bngain * bnraw + bnbias\n",
        "# h = torch.tanh(hpreact) # hidden layer\n",
        "# logits = h @ W2 + b2 # output layer\n",
        "# logit_maxes = logits.max(1, keepdim=True).values\n",
        "# norm_logits = logits - logit_maxes\n",
        "# counts = norm_logits.exp()\n",
        "# counts_sum = counts.sum(1, keepdims=True)\n",
        "# counts_sum_inv = counts_sum**-1\n",
        "# probs = counts * counts_sum_inv\n",
        "# logprobs = probs.log()\n",
        "# loss = -logprobs[range(n), Yb].mean()\n",
        "\n",
        "dlogprobs = torch.zeros_like(logprobs)\n",
        "dlogprobs[range(n), Yb] = -1.0/n\n",
        "dprobs = (1/probs) * dlogprobs\n",
        "dcounts_sum_inv = (counts * dprobs).sum(1, keepdims=True)\n",
        "dcounts_sum = (-counts_sum**-2)* dcounts_sum_inv\n",
        "dcounts = counts_sum_inv * dprobs\n",
        "dcounts += torch.ones_like(counts) * dcounts_sum\n",
        "dnorm_logits = dcounts * counts\n",
        "dlogit_maxes = (-dnorm_logits).sum(1, keepdims=True)\n",
        "dlogits = dnorm_logits.clone()\n",
        "dlogits += F.one_hot(logits.max(1).indices,num_classes=logits.shape[1]) * dlogit_maxes\n",
        "dh = dlogits @ W2.T\n",
        "dW2 = h.T @ dlogits\n",
        "db2 = dlogits.sum(0)\n",
        "dhpreact = (1.0 - h**2) * dh\n",
        "dbngain = (bnraw * dhpreact).sum(0, keepdims=True)\n",
        "dbnraw = bngain * dhpreact\n",
        "dbnbias = dhpreact.sum(0, keepdims=True)\n",
        "dbndiff = bnvar_inv * dbnraw\n",
        "dbnvar_inv = (bndiff * dbnraw).sum(0, keepdims=True)\n",
        "dbnvar = (-0.5*(bnvar + 1e-5)**-1.5) * dbnvar_inv\n",
        "dbndiff2 = dbnvar * (1.0 / (n - 1))\n",
        "dbndiff += 2.0 * bndiff * dbndiff2\n",
        "dhprebn = dbndiff\n",
        "dbnmeani = -dbndiff.sum(dim=0, keepdim=True)\n",
        "dhprebn += (1.0/n) * torch.ones_like(hprebn)\n",
        "dembcat = dhprebn @ W1.T\n",
        "dW1 = embcat.T @ dhprebn\n",
        "db1 = dhprebn.sum(0)\n",
        "cmp('emb', demb, emb)\n",
        "dC = torch.zeros_like(C)\n",
        "for k in range(Xb.shape[0]):\n",
        "  for j in range(Xb.shape[1]):\n",
        "    ix = Xb[k,j]\n",
        "    dC[ix] += demb[k,j]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nIjsgHCv-pPd",
        "outputId": "4e3ae56b-112c-4b12-d3ca-d89dfea67cea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "emb             | exact: False | approximate: True  | maxdiff: 1.862645149230957e-09\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dlogprobs = torch.zeros_like(logprobs)\n",
        "dlogprobs[range(n), Yb] = -1.0/n\n",
        "dprobs = (1.0 / probs) * dlogprobs\n",
        "dcounts_sum_inv = (counts * dprobs).sum(1, keepdim=True)\n",
        "dcounts = counts_sum_inv * dprobs\n",
        "dcounts_sum = (-counts_sum**-2) * dcounts_sum_inv\n",
        "dcounts += torch.ones_like(counts) * dcounts_sum\n",
        "dnorm_logits = counts * dcounts\n",
        "dlogits = dnorm_logits.clone()\n",
        "dlogit_maxes = (-dnorm_logits).sum(1, keepdim=True)\n",
        "dlogits += F.one_hot(logits.max(1).indices, num_classes=logits.shape[1]) * dlogit_maxes\n",
        "dh = dlogits @ W2.T\n",
        "dW2 = h.T @ dlogits\n",
        "db2 = dlogits.sum(0)\n",
        "dhpreact = (1.0 - h**2) * dh\n",
        "dbngain = (bnraw * dhpreact).sum(0, keepdim=True)\n",
        "dbnraw = bngain * dhpreact\n",
        "dbnbias = dhpreact.sum(0, keepdim=True)\n",
        "dbndiff = bnvar_inv * dbnraw\n",
        "dbnvar_inv = (bndiff * dbnraw).sum(0, keepdim=True)\n",
        "dbnvar = (-0.5*(bnvar + 1e-5)**-1.5) * dbnvar_inv\n",
        "dbndiff2 = (1.0/(n-1))*torch.ones_like(bndiff2) * dbnvar\n",
        "dbndiff += (2*bndiff) * dbndiff2\n",
        "dhprebn = dbndiff.clone()\n",
        "dbnmeani = (-dbndiff).sum(0)\n",
        "dhprebn += 1.0/n * (torch.ones_like(hprebn) * dbnmeani)\n",
        "dembcat = dhprebn @ W1.T\n",
        "dW1 = embcat.T @ dhprebn\n",
        "db1 = dhprebn.sum(0)\n",
        "demb = dembcat.view(emb.shape)\n",
        "dC = torch.zeros_like(C)\n",
        "for k in range(Xb.shape[0]):\n",
        "  for j in range(Xb.shape[1]):\n",
        "    ix = Xb[k,j]\n",
        "    dC[ix] += demb[k,j]\n",
        "\n",
        "cmp('logprobs', dlogprobs, logprobs)\n",
        "cmp('probs', dprobs, probs)\n",
        "cmp('counts_sum_inv', dcounts_sum_inv, counts_sum_inv)\n",
        "cmp('counts_sum', dcounts_sum, counts_sum)\n",
        "cmp('counts', dcounts, counts)\n",
        "cmp('norm_logits', dnorm_logits, norm_logits)\n",
        "cmp('logit_maxes', dlogit_maxes, logit_maxes)\n",
        "cmp('logits', dlogits, logits)\n",
        "cmp('h', dh, h)\n",
        "cmp('W2', dW2, W2)\n",
        "cmp('b2', db2, b2)\n",
        "cmp('hpreact', dhpreact, hpreact)\n",
        "cmp('bngain', dbngain, bngain)\n",
        "cmp('bnbias', dbnbias, bnbias)\n",
        "cmp('bnraw', dbnraw, bnraw)\n",
        "cmp('bnvar_inv', dbnvar_inv, bnvar_inv)\n",
        "cmp('bnvar', dbnvar, bnvar)\n",
        "cmp('bndiff2', dbndiff2, bndiff2)\n",
        "cmp('bndiff', dbndiff, bndiff)\n",
        "# cmp('bnmeani', dbnmeani, bnmeani)\n",
        "cmp('hprebn', dhprebn, hprebn)\n",
        "cmp('embcat', dembcat, embcat)\n",
        "cmp('W1', dW1, W1)\n",
        "cmp('b1', db1, b1)\n",
        "cmp('emb', demb, emb)\n",
        "cmp('C', dC, C)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8z46dA_tHUr0",
        "outputId": "750fa8a2-68f0-49db-f16c-00ad0452022c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "logprobs        | exact: True  | approximate: True  | maxdiff: 0.0\n",
            "probs           | exact: True  | approximate: True  | maxdiff: 0.0\n",
            "counts_sum_inv  | exact: True  | approximate: True  | maxdiff: 0.0\n",
            "counts_sum      | exact: True  | approximate: True  | maxdiff: 0.0\n",
            "counts          | exact: True  | approximate: True  | maxdiff: 0.0\n",
            "norm_logits     | exact: True  | approximate: True  | maxdiff: 0.0\n",
            "logit_maxes     | exact: True  | approximate: True  | maxdiff: 0.0\n",
            "logits          | exact: True  | approximate: True  | maxdiff: 0.0\n",
            "h               | exact: True  | approximate: True  | maxdiff: 0.0\n",
            "W2              | exact: True  | approximate: True  | maxdiff: 0.0\n",
            "b2              | exact: True  | approximate: True  | maxdiff: 0.0\n",
            "hpreact         | exact: False | approximate: True  | maxdiff: 4.656612873077393e-10\n",
            "bngain          | exact: False | approximate: True  | maxdiff: 2.3283064365386963e-09\n",
            "bnbias          | exact: False | approximate: True  | maxdiff: 3.725290298461914e-09\n",
            "bnraw           | exact: False | approximate: True  | maxdiff: 6.984919309616089e-10\n",
            "bnvar_inv       | exact: False | approximate: True  | maxdiff: 3.725290298461914e-09\n",
            "bnvar           | exact: False | approximate: True  | maxdiff: 4.656612873077393e-10\n",
            "bndiff2         | exact: False | approximate: True  | maxdiff: 1.4551915228366852e-11\n",
            "bndiff          | exact: False | approximate: True  | maxdiff: 4.656612873077393e-10\n",
            "hprebn          | exact: False | approximate: True  | maxdiff: 4.656612873077393e-10\n",
            "embcat          | exact: False | approximate: True  | maxdiff: 1.3969838619232178e-09\n",
            "W1              | exact: False | approximate: True  | maxdiff: 8.381903171539307e-09\n",
            "b1              | exact: False | approximate: True  | maxdiff: 3.725290298461914e-09\n",
            "emb             | exact: False | approximate: True  | maxdiff: 1.3969838619232178e-09\n",
            "C               | exact: False | approximate: True  | maxdiff: 9.313225746154785e-09\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise 2"
      ],
      "metadata": {
        "id": "ngJrm0t2H0iL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Exercise 2: backprop through cross_entropy but all in one go\n",
        "# to complete this challenge look at the mathematical expression of the loss,\n",
        "# take the derivative, simplify the expression, and just write it out\n",
        "\n",
        "# forward pass\n",
        "\n",
        "# before:\n",
        "# logit_maxes = logits.max(1, keepdim=True).values\n",
        "# norm_logits = logits - logit_maxes # subtract max for numerical stability\n",
        "# counts = norm_logits.exp()\n",
        "# counts_sum = counts.sum(1, keepdims=True)\n",
        "# counts_sum_inv = counts_sum**-1 # if I use (1.0 / counts_sum) instead then I can't get backprop to be bit exact...\n",
        "# probs = counts * counts_sum_inv\n",
        "# logprobs = probs.log()\n",
        "# loss = -logprobs[range(n), Yb].mean()\n",
        "\n",
        "# now:\n",
        "loss_fast = F.cross_entropy(logits, Yb)\n",
        "print(loss_fast.item(), 'diff:', (loss_fast - loss).item())\n",
        "\n",
        "\n",
        "# dlogits = probs\n",
        "# dlogits[range(n), Yb] -= 1\n",
        "# dlogits /= n\n",
        "\n",
        "dlogits = F.softmax(logits,1)\n",
        "dlogits[range(n), Yb] -= 1\n",
        "dlogits /= n\n",
        "\n",
        "cmp('logits', dlogits, logits)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1nQXjizjLLVb",
        "outputId": "23524c83-c8e6-4ec3-8352-ae193b48264c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.3310658931732178 diff: -2.384185791015625e-07\n",
            "logits          | exact: False | approximate: True  | maxdiff: 5.3551048040390015e-09\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## `loss_fast = F.cross_entropy(logits, Yb)`\n",
        "\n",
        "Let's break it down into simpler steps.\n",
        "\n",
        "## Understanding Cross-Entropy Loss:\n",
        "\n",
        "Cross-entropy loss for classification is defined as:\n",
        "\n",
        "$$\n",
        "L = - \\frac{1}{N} \\sum_{i=1}^{N} y_i \\log(p_i)\n",
        "$$\n",
        "\n",
        "Where:\n",
        "- \\( N \\) is the number of data points (or batch size).\n",
        "- \\($ y_i $\\) is the true label for data point \\( i \\). It's 1 for the correct class and 0 for all others.\n",
        "- \\($ p_i $\\) is the predicted probability for data point \\( i \\) belonging to the correct class.\n",
        "\n",
        "For multi-class classification, this equation becomes a sum over all classes, but the principle remains the same. Only one term in the sum is non-zero for each data point, corresponding to the correct class.\n",
        "\n",
        "## Finding the Derivative:\n",
        "\n",
        "The task is to compute the gradient of the loss with respect to the logits, which will be used in the backpropagation. This gradient is commonly denoted as $ \\frac{\\partial L}{\\partial \\text{logits}} $.\n",
        "\n",
        "### Step-by-Step Derivation:\n",
        "\n",
        "1. **Softmax Activation**:\n",
        "   Before we get the probabilities \\( $ p_i $ \\), the logits go through a softmax function:\n",
        "\n",
        "$$\n",
        "p_i = \\frac{e^{\\text{logits}_i}}{\\sum_{j} e^{\\text{logits}_j}}\n",
        "$$\n",
        "\n",
        "2. **Compute Gradient**:\n",
        "   Taking the derivative of the cross-entropy loss with respect to the logits, we get:\n",
        "\n",
        "$$\n",
        "\\frac{\\partial L}{\\partial \\text{logits}_i} = p_i - y_i\n",
        "$$\n",
        "\n",
        "This is a simplified result after applying the chain rule and sum rule in differentiation.\n",
        "\n",
        "3. **Intuition**:\n",
        "   If our model's prediction \\($ p_i $\\) is perfect, then \\($ p_i = y_i $\\) (either 1 for the correct class or 0 for the others). So, the gradient becomes zero, meaning no update is needed for that data point.\n",
        "   If the prediction is wrong, the gradient will push the logits in the direction to correct the mistake.\n",
        "\n",
        "### Implementing in PyTorch:\n",
        "\n",
        "Given that you've computed the loss using `F.cross_entropy(logits, Yb)`, the gradient with respect to the logits can be computed by simply performing a backward operation on the loss. However, if you want to compute it manually:\n",
        "\n",
        "```python\n",
        "dlogits = probs\n",
        "dlogits[range(n), Yb] -= 1\n",
        "dlogits /= n\n",
        "```\n",
        "\n",
        "In this code:\n",
        "- We start with the predicted probabilities (`probs`).\n",
        "- We subtract 1 from the probabilities of the correct classes.\n",
        "- Finally, we divide by `n` to get the average gradient.\n",
        "\n",
        "This provides an efficient way to compute the gradient of the cross-entropy loss with respect to the logits."
      ],
      "metadata": {
        "id": "hHFjObIix0wv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "F.softmax(logits, 1)[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gg-LAp9t1Pta",
        "outputId": "51bc7542-74d4-448b-a43b-844e71d9798c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.0717, 0.0896, 0.0171, 0.0525, 0.0176, 0.0876, 0.0234, 0.0385, 0.0188,\n",
              "        0.0304, 0.0386, 0.0315, 0.0361, 0.0289, 0.0335, 0.0129, 0.0086, 0.0186,\n",
              "        0.0158, 0.0555, 0.0470, 0.0230, 0.0246, 0.0706, 0.0569, 0.0287, 0.0220],\n",
              "       grad_fn=<SelectBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dlogits[0] * n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "59OuPfYe1VXR",
        "outputId": "b3bb7473-e82e-4200-d455-b4243d49447b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.0717,  0.0896,  0.0171,  0.0525,  0.0176,  0.0876,  0.0234,  0.0385,\n",
              "        -0.9812,  0.0304,  0.0386,  0.0315,  0.0361,  0.0289,  0.0335,  0.0129,\n",
              "         0.0086,  0.0186,  0.0158,  0.0555,  0.0470,  0.0230,  0.0246,  0.0706,\n",
              "         0.0569,  0.0287,  0.0220], grad_fn=<MulBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dlogits[1] * n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P4Rh61E9KL-y",
        "outputId": "e084a0fb-266f-4d15-d291-e868982d014b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.0508,  0.0569,  0.0974,  0.0557,  0.0357,  0.0319,  0.0183,  0.0487,\n",
              "         0.0198,  0.0246,  0.0543,  0.0405,  0.0477,  0.0292, -0.9569,  0.0381,\n",
              "         0.0272,  0.0157,  0.0209,  0.0363,  0.0178,  0.0218,  0.0141,  0.0690,\n",
              "         0.0220,  0.0366,  0.0261], grad_fn=<MulBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dlogits[2] * n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O05470EEKcHM",
        "outputId": "a657a273-7933-4341-b9a4-cdfcfd06cc02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.0202,  0.0249,  0.0144,  0.0144,  0.0217,  0.0452,  0.0565,  0.0674,\n",
              "         0.0615,  0.0298,  0.0230,  0.0312,  0.0404,  0.0487,  0.0218, -0.9745,\n",
              "         0.0135,  0.0333,  0.0293,  0.1104,  0.0641,  0.0367,  0.0368,  0.0424,\n",
              "         0.0360,  0.0220,  0.0289], grad_fn=<MulBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dlogits[0].sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M_9ydDED1dyd",
        "outputId": "2edd4505-d1b0-4e6a-8a63-96f9dbd06dbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(-6.9849e-10, grad_fn=<SumBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8,8))\n",
        "plt.imshow(dlogits.detach(), cmap='gray')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 694
        },
        "id": "6qBR_JmR1iI5",
        "outputId": "5fa1d232-e49a-4661-ca83-907d76c818db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7914e70e6230>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x800 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Understanding Cross-Entropy Loss and Backpropagation:\n",
        "\n",
        "#### 1. **Visualizing the Logits:**\n",
        "Imagine you're trying to classify an image of a cat, dog, or bird. The logits are the raw scores your neural network produces for each class before turning them into probabilities. For instance, if logits are `[2, 5, 1]`, it suggests that the network is quite confident that the image is a dog compared to a cat or bird.\n",
        "\n",
        "#### 2. **The Role of Probabilities:**\n",
        "The softmax function transforms these logits into probabilities. Continuing with our example, `[2, 5, 1]` might be converted to `[0.05, 0.9, 0.05]`, indicating a 90% probability that it's a dog.\n",
        "\n",
        "#### 3. **Intuition Behind Loss Gradient:**\n",
        "Now, suppose the true label was \"cat\". The gradient provides feedback, essentially saying, \"You misjudged the 'cat' prediction. Here's how you should adjust your logits to get closer to the correct answer next time.\"\n",
        "\n",
        "For our example, the gradients would be:\n",
        "- For \"cat\" (correct class): `-0.95`, indicating the model should increase this logit.\n",
        "- For \"dog\" (incorrect class): `+0.9`, suggesting the model should decrease this logit.\n",
        "- For \"bird\" (incorrect class): `+0.05`, again indicating a decrease for this logit.\n",
        "\n",
        "#### 4. **Summing the Forces:**\n",
        "If you sum the elements of this gradient tensor, they'll total zero. This ensures that the \"increase\" force on the correct class is offset by the \"decrease\" forces on the incorrect classes.\n",
        "\n",
        "#### 5. **Intuitive Explanation of Gradients:**\n",
        "Think of gradients as forces in a tug-of-war. For incorrect predictions, there's a substantial pull towards correction. The magnitude of this pull depends on the prediction's confidence. For instance, if the network was highly confident but incorrect (like being 90% sure it's a dog when it's a cat), there's a strong corrective force.\n",
        "\n",
        "#### 6. **Training as a Tug-of-War System:**\n",
        "Visualize the neural network as a vast system of pulleys. Each gradient represents a force acting on these pulleys. As the network trains, these forces tweak the weights and biases to improve predictions. The intensity of the force (gradient) determines the size of the adjustment.\n",
        "\n",
        "#### 7. **Cross-Entropy's Beauty:**\n",
        "The brilliance of cross-entropy loss lies in its generation of these forces. It's not just about the prediction being right or wrong but also about how confident the model was. This dynamic nudging ensures neural networks train efficiently and robustly.\n",
        "\n",
        "### Simplified Example:\n",
        "\n",
        "Imagine teaching a child to differentiate between circles and squares. Each time the child identifies a shape, you provide feedback:\n",
        "\n",
        "- If they confidently declare \"circle!\" for a square, you might firmly correct them: \"No, that's unmistakably a square!\"\n",
        "- If they hesitantly guess \"circle?\" for a square, your correction might be milder: \"That's okay, but it's indeed a square.\"\n",
        "\n",
        "The feedback's intensity mirrors the gradient. The child's confidence aligns with the softmax probabilities, and your feedback refines their understanding, similar to how gradients adjust a neural network's parameters.\n",
        "\n",
        "This push and pull between accuracy and error, steered by gradient forces, encapsulates training a neural network with cross-entropy loss."
      ],
      "metadata": {
        "id": "FwHZe5YqOAwb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gradients in the context of the cross-entropy loss and softmax activation\n",
        "\n",
        "**Step 1:** Consider the softmax function and the cross-entropy loss:\n",
        "Given logits \\($[z_1, z_2, z_3]$\\), the softmax function computes:\n",
        "\n",
        "$$\n",
        "p_i = \\frac{e^{z_i}}{\\sum_{j=1}^{3} e^{z_j}}\n",
        "$$\n",
        "\n",
        "The cross-entropy loss \\( L \\) between the predicted probabilities \\( p \\) and the true labels \\( y \\) (one-hot encoded) is:\n",
        "\n",
        "$$\n",
        "L = -\\sum_{i=1}^{3} y_i \\log(p_i)\n",
        "$$\n",
        "\n",
        "**Step 2:** Notice how the loss is computed:\n",
        "Only the log probability of the correct class affects the loss. For our example, if \"dog\" is the correct class, then \\($ y_2 = 1 $\\) and \\($ y_1 = y_3 = 0 $\\). So, our loss becomes:\n",
        "\n",
        "$$\n",
        "L = -\\log(p_2)\n",
        "$$\n",
        "\n",
        "**Step 3:** Compute the gradient of the loss with respect to the logits:\n",
        "For the correct class (let's say index 2 for \"dog\"):\n",
        "\n",
        "$$\n",
        "\\frac{\\partial L}{\\partial z_2} = \\frac{\\partial (-\\log(p_2))}{\\partial z_2}\n",
        "$$\n",
        "\n",
        "For the incorrect classes:\n",
        "\n",
        "$$\n",
        "\\frac{\\partial L}{\\partial z_1} = \\frac{\\partial (-\\log(p_2))}{\\partial z_1}\n",
        "$$\n",
        "$$\n",
        "\\frac{\\partial L}{\\partial z_3} = \\frac{\\partial (-\\log(p_2))}{\\partial z_3}\n",
        "$$\n",
        "\n",
        "**Step 4:** Simplify the gradients:\n",
        "Using the properties of the softmax function and some calculus, you'd find:\n",
        "\n",
        "- The gradient for the correct class is \\($ p_2 - 1$ \\) (which is always negative since \\($ p_2 $\\) is between 0 and 1).\n",
        "- The gradient for the incorrect classes is just their softmax probability. So for class 1 (cat), it's \\($ p_1$ \\) (which is always positive) and for class 3 (bird), it's \\($ p_3 $\\) (also always positive).\n",
        "\n",
        "**Intuition:**\n",
        "For the correct class (\"dog\" in our case): The model wants to increase its confidence. To do so, the logit for the correct class should increase, which is reflected by a negative gradient.\n",
        "\n",
        "For incorrect classes (\"cat\" and \"bird\"): The model wants to reduce its confidence in these. To decrease the probability of these classes, their logits should decrease. However, during backpropagation, the gradient (which indicates the rate of change of loss concerning the logits) is positive. This might seem counterintuitive, but remember that optimizers like gradient descent subtract the gradient from the parameters. So, a positive gradient will result in a decrease in the logit value during the update step.\n",
        "\n",
        "Hence, confidently wrong logits get a large positive gradient (pushing them down more), not-confidently-wrong logits get a small positive gradient (pushing them down slightly), and the correct logits get a negative gradient (pushing them up)."
      ],
      "metadata": {
        "id": "tXzPA9bB__Bt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise 3"
      ],
      "metadata": {
        "id": "-CseLYOtO03F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Exercise 3: backprop through batchnorm but all in one go\n",
        "# to complete this challenge look at the mathematical expression of the output of batchnorm,\n",
        "# take the derivative w.r.t. its input, simplify the expression, and just write it out\n",
        "# BatchNorm paper: https://arxiv.org/abs/1502.03167\n",
        "\n",
        "# forward pass\n",
        "\n",
        "# before:\n",
        "# bnmeani = 1/n*hprebn.sum(0, keepdim=True)\n",
        "# bndiff = hprebn - bnmeani\n",
        "# bndiff2 = bndiff**2\n",
        "# bnvar = 1/(n-1)*(bndiff2).sum(0, keepdim=True) # note: Bessel's correction (dividing by n-1, not n)\n",
        "# bnvar_inv = (bnvar + 1e-5)**-0.5\n",
        "# bnraw = bndiff * bnvar_inv\n",
        "# hpreact = bngain * bnraw + bnbias\n",
        "\n",
        "# now:\n",
        "hpreact_fast = bngain * (hprebn - hprebn.mean(0, keepdim=True)) / torch.sqrt(hprebn.var(0, keepdim=True, unbiased=True) + 1e-5) + bnbias\n",
        "print('max diff:', (hpreact_fast - hpreact).abs().max())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WT28iCk1SLSZ",
        "outputId": "5f1830fb-36ff-4dca-800b-e43a212772d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max diff: tensor(4.7684e-07, grad_fn=<MaxBackward1>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# backward pass\n",
        "\n",
        "# before we had:\n",
        "# dbnraw = bngain * dhpreact\n",
        "# dbndiff = bnvar_inv * dbnraw\n",
        "# dbnvar_inv = (bndiff * dbnraw).sum(0, keepdim=True)\n",
        "# dbnvar = (-0.5*(bnvar + 1e-5)**-1.5) * dbnvar_inv\n",
        "# dbndiff2 = (1.0/(n-1))*torch.ones_like(bndiff2) * dbnvar\n",
        "# dbndiff += (2*bndiff) * dbndiff2\n",
        "# dhprebn = dbndiff.clone()\n",
        "# dbnmeani = (-dbndiff).sum(0)\n",
        "# dhprebn += 1.0/n * (torch.ones_like(hprebn) * dbnmeani)\n",
        "\n",
        "# calculate dhprebn given dhpreact (i.e. backprop through the batchnorm)\n",
        "# (you'll also need to use some of the variables from the forward pass up above)\n",
        "\n",
        "# -----------------\n",
        "# YOUR CODE HERE :)\n",
        "\n",
        "# dhprebn = (bngain / (n * torch.sqrt(bnvar + 1e-5))) * (n * dhpreact - dhpreact.sum(0) - (hprebn - bnmeani) * (dhpreact * (hprebn - bnmeani)).sum(0) / (bnvar + 1e-5))\n",
        "\n",
        "dhprebn = bngain*bnvar_inv/n * (n*dhpreact - dhpreact.sum(0) - n/(n-1)*bnraw*(dhpreact*bnraw).sum(0))\n",
        "# -----------------\n",
        "\n",
        "cmp('hprebn', dhprebn, hprebn) # I can only get approximate to be true, my maxdiff is 9e-10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fmGLapUTO3AH",
        "outputId": "240dea0e-5036-44bc-ca94-330e036b5750"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hprebn          | exact: False | approximate: True  | maxdiff: 9.313225746154785e-10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The backward pass of Batch Normalization\n",
        "\n",
        "### 1. Understanding the Forward Pass:\n",
        "\n",
        "The forward pass for Batch Normalization can be distilled into a few main steps:\n",
        "- Compute the mean of the batch (`bnmeani`).\n",
        "- Calculate the difference between each element and the mean (`bndiff`).\n",
        "- Calculate the variance of the batch (`bnvar`).\n",
        "- Normalize the batch using the variance and mean (`bnraw`).\n",
        "- Scale and shift using `bngain` and `bnbias`.\n",
        "\n",
        "The updated forward pass (`hpreact_fast`) performs all these operations in one line.\n",
        "\n",
        "### 2. The Backward Pass:\n",
        "\n",
        "The backward pass computes the gradient of the loss with respect to the inputs of the Batch Normalization layer. The objective is to compute `dhprebn` given `dhpreact`.\n",
        "\n",
        "Given the previous backward pass steps, we can see that the gradient is computed in a sequential manner, going backward from the last operation in the forward pass up to the first.\n",
        "\n",
        "### 3. Simplifying the Backward Pass:\n",
        "\n",
        "The challenge here is to simplify the backward pass and compute `dhprebn` directly from `dhpreact` in a single line.\n",
        "\n",
        "Using the given forward pass and the chain rule of calculus, the gradient of the loss with respect to the input of the Batch Normalization layer can be computed as:\n",
        "\n",
        "$$\n",
        "dhprebn = \\frac{bngain}{n \\times \\sqrt{bnvar + 1e-5}} \\times (n \\times dhpreact - dhpreact.sum(0) - (hprebn - bnmeani) \\times (dhpreact * (hprebn - bnmeani)).sum(0) / (bnvar + 1e-5))\n",
        "$$\n",
        "\n",
        "This equation is derived from the chain rule of calculus and the gradients from the forward pass.\n",
        "\n",
        "### 4. Implementing the Simplified Backward Pass:\n",
        "\n",
        "Let's plug in the formula to compute `dhprebn`.\n",
        "\n",
        "``` python\n",
        "dhprebn = (bngain / (n * torch.sqrt(bnvar + 1e-5))) * (n * dhpreact - dhpreact.sum(0) - (hprebn - bnmeani) * (dhpreact * (hprebn - bnmeani)).sum(0) / (bnvar + 1e-5))\n",
        "```\n",
        "\n",
        "Run the `cmp` function to verify the computed `dhprebn`:\n",
        "\n",
        "``` python\n",
        "cmp('hprebn', dhprebn, hprebn)\n",
        "```\n",
        "\n",
        "This should return a small difference, indicating that our simplified backward pass is closely matching the expected values.\n",
        "\n",
        "In summary, we've taken the multiple steps from the backward pass of Batch Normalization and condensed them into a single expression, making it more efficient and concise."
      ],
      "metadata": {
        "id": "le8rNCf5SvpP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The intuition behind A. Karpathy's solution.\n",
        "\n",
        "### Batch Normalization Backward Pass\n",
        "\n",
        "When backpropagating through the Batch Normalization layer, we're essentially figuring out how much each input (before normalization) contributed to the loss. This helps us understand how much to tweak each input to minimize the loss.\n",
        "\n",
        "#### Step 1: Derivation of the Gradient\n",
        "\n",
        "Using the chain rule of calculus, the derivative of the loss with respect to the normalized input \\( $\\text{bnraw} $\\) is:\n",
        "\n",
        "$$ \\frac{\\partial \\text{loss}}{\\partial \\text{bnraw}} = \\text{bngain} \\times \\frac{\\partial \\text{loss}}{\\partial \\text{hpreact}} $$\n",
        "\n",
        "Here, \\( $\\text{bngain} $\\) represents the scaling factor applied to the normalized input, and \\( $\\frac{\\partial \\text{loss}}{\\partial \\text{hpreact}} $\\) is the gradient passed down to the Batch Normalization layer.\n",
        "\n",
        "#### Step 2: Backpropagation Through Normalization\n",
        "\n",
        "Next, we need to figure out how much each input (before normalization) contributed to \\( $\\text{bnraw} $\\). To do this, we backpropagate through the normalization step, which involves both the mean \\($ \\text{bnmeani}$ \\) and the inverse variance \\($ \\text{bnvar_inv} $\\).\n",
        "\n",
        "This is where the provided solution comes into play:\n",
        "\n",
        "\n",
        "```python\n",
        "dhprebn = bngain*bnvar_inv/n * (n*dhpreact - dhpreact.sum(0) - n/(n-1)*bnraw*(dhpreact*bnraw).sum(0))\n",
        "```\n",
        "\n",
        "$$ \\text{dhprebn} = \\text{bngain} \\times \\text{bnvar_inv} / n \\times (n \\times \\text{dhpreact} - \\text{dhpreact}.sum(0) - \\frac{n}{n-1} \\times \\text{bnraw} \\times (\\text{dhpreact} \\times \\text{bnraw}).sum(0)) $$\n",
        "\n",
        "This formula might seem complex, but it's essentially capturing three main ideas:\n",
        "\n",
        "1. **Scaling by Variance:** The \\( $\\text{bngain} \\times \\text{bnvar_inv} $\\) term captures how a change in the normalized input \\( $\\text{bnraw}$ \\) affects the final output. If the variance is high, a small change in the input will have a smaller effect on the output, and vice versa.\n",
        "\n",
        "2. **Adjustment for Mean:** The \\( $\\text{dhpreact}.sum(0) $\\) term adjusts for the mean of the batch. If the gradient is high and positive, it means that increasing the input will decrease the loss. If the gradient is negative, it means increasing the input will increase the loss.\n",
        "\n",
        "3. **Correction for Batch Variance:** The \\($ \\frac{n}{n-1} \\times \\text{bnraw} \\times (\\text{dhpreact} \\times \\text{bnraw}).sum(0) $\\) term corrects for the variance of the batch. It ensures that the gradient is adjusted based on how much each input deviated from the mean.\n",
        "\n",
        "### Intuition\n",
        "\n",
        "The gradient \\( $\\text{dhprebn} $\\) tells the model how to adjust each input to the Batch Normalization layer to minimize the loss. If \\( $\\text{dhprebn}$ \\) is positive, it means increasing that input will decrease the loss, and vice versa.\n",
        "\n",
        "The provided formula captures the essence of backpropagation through Batch Normalization. It combines the effects of scaling by variance, adjusting for mean, and correcting for batch variance to compute the final gradient for each input.\n",
        "\n",
        "In essence, the lecturer's solution is a concise representation of the chain rule applied to the Batch Normalization layer, capturing the complex interplay of mean, variance, and scaling in one formula."
      ],
      "metadata": {
        "id": "rtTJtG3wYgsR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise 4"
      ],
      "metadata": {
        "id": "k75_D3Ibgtud"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train for 100 iterations and compare backpropagation grads with Pytorch"
      ],
      "metadata": {
        "id": "gzbcfrSJkI1t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Exercise 4: putting it all together!\n",
        "# Train the MLP neural net with your own backward pass\n",
        "\n",
        "# init\n",
        "n_embd = 10 # the dimensionality of the character embedding vectors\n",
        "n_hidden = 200 # the number of neurons in the hidden layer of the MLP\n",
        "\n",
        "g = torch.Generator().manual_seed(2147483647) # for reproducibility\n",
        "C  = torch.randn((vocab_size, n_embd),            generator=g)\n",
        "# Layer 1\n",
        "W1 = torch.randn((n_embd * block_size, n_hidden), generator=g) * (5/3)/((n_embd * block_size)**0.5)\n",
        "b1 = torch.randn(n_hidden,                        generator=g) * 0.1\n",
        "# Layer 2\n",
        "W2 = torch.randn((n_hidden, vocab_size),          generator=g) * 0.1\n",
        "b2 = torch.randn(vocab_size,                      generator=g) * 0.1\n",
        "# BatchNorm parameters\n",
        "bngain = torch.randn((1, n_hidden))*0.1 + 1.0\n",
        "bnbias = torch.randn((1, n_hidden))*0.1\n",
        "\n",
        "parameters = [C, W1, b1, W2, b2, bngain, bnbias]\n",
        "print(sum(p.nelement() for p in parameters)) # number of parameters in total\n",
        "for p in parameters:\n",
        "  p.requires_grad = True\n",
        "\n",
        "# same optimization as last time\n",
        "max_steps = 200000\n",
        "batch_size = 32\n",
        "n = batch_size # convenience\n",
        "lossi = []\n",
        "\n",
        "# use this context manager for efficiency once your backward pass is written (TODO)\n",
        "# with torch.no_grad():\n",
        "\n",
        "  # kick off optimization\n",
        "for i in range(max_steps):\n",
        "\n",
        "  # minibatch construct\n",
        "  ix = torch.randint(0, Xtr.shape[0], (batch_size,), generator=g)\n",
        "  Xb, Yb = Xtr[ix], Ytr[ix] # batch X,Y\n",
        "\n",
        "  # forward pass\n",
        "  emb = C[Xb] # embed the characters into vectors\n",
        "  embcat = emb.view(emb.shape[0], -1) # concatenate the vectors\n",
        "  # Linear layer\n",
        "  hprebn = embcat @ W1 + b1 # hidden layer pre-activation\n",
        "  # BatchNorm layer\n",
        "  # -------------------------------------------------------------\n",
        "  bnmean = hprebn.mean(0, keepdim=True)\n",
        "  bnvar = hprebn.var(0, keepdim=True, unbiased=True)\n",
        "  bnvar_inv = (bnvar + 1e-5)**-0.5\n",
        "  bnraw = (hprebn - bnmean) * bnvar_inv\n",
        "  hpreact = bngain * bnraw + bnbias\n",
        "  # -------------------------------------------------------------\n",
        "  # Non-linearity\n",
        "  h = torch.tanh(hpreact) # hidden layer\n",
        "  logits = h @ W2 + b2 # output layer\n",
        "  loss = F.cross_entropy(logits, Yb) # loss function\n",
        "\n",
        "  # backward pass\n",
        "  for p in parameters:\n",
        "    p.grad = None\n",
        "  loss.backward() # use this for correctness comparisons, delete it later!\n",
        "\n",
        "  # manual backprop! #swole_doge_meme\n",
        "  # -----------------\n",
        "  dlogits = F.softmax(logits, 1)\n",
        "  dlogits[range(n), Yb] -= 1\n",
        "  dlogits /= n\n",
        "  # 2nd layer backprop\n",
        "  dh = dlogits @ W2.T\n",
        "  dW2 = h.T @ dlogits\n",
        "  db2 = dlogits.sum(0)\n",
        "  # tanh\n",
        "  dhpreact = (1.0 - h**2) * dh\n",
        "  # batchnorm backprop\n",
        "  dbngain = (bnraw * dhpreact).sum(0, keepdim=True)\n",
        "  dbnbias = dhpreact.sum(0, keepdim=True)\n",
        "  dhprebn = bngain*bnvar_inv/n * (n*dhpreact - dhpreact.sum(0) - n/(n-1)*bnraw*(dhpreact*bnraw).sum(0))\n",
        "  # 1st layer\n",
        "  dembcat = dhprebn @ W1.T\n",
        "  dW1 = embcat.T @ dhprebn\n",
        "  db1 = dhprebn.sum(0)\n",
        "  # embedding\n",
        "  demb = dembcat.view(emb.shape)\n",
        "  dC = torch.zeros_like(C)\n",
        "  for k in range(Xb.shape[0]):\n",
        "    for j in range(Xb.shape[1]):\n",
        "      ix = Xb[k,j]\n",
        "      dC[ix] += demb[k,j]\n",
        "  grads = [dC, dW1, db1, dW2, db2, dbngain, dbnbias]\n",
        "  # -----------------\n",
        "\n",
        "  # update\n",
        "  lr = 0.1 if i < 100000 else 0.01 # step learning rate decay\n",
        "  for p, grad in zip(parameters, grads):\n",
        "    #p.data += -lr * p.grad # old way of cheems doge (using PyTorch grad from .backward())\n",
        "    p.data += -lr * grad # new way of swole doge TODO: enable\n",
        "\n",
        "  # track stats\n",
        "  if i % 10000 == 0: # print every once in a while\n",
        "    print(f'{i:7d}/{max_steps:7d}: {loss.item():.4f}')\n",
        "  lossi.append(loss.log10().item())\n",
        "\n",
        "  if i >= 100: # TODO: delete early breaking when you're ready to train the full net\n",
        "    break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZQpaMYSvgwUT",
        "outputId": "920063a9-c8aa-4cf4-b5ab-8aca068e7c9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12297\n",
            "      0/ 200000: 3.7810\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check everything ok with 100 iterations\n",
        "for p,g in zip(parameters, grads):\n",
        "  cmp(str(tuple(p.shape)), g, p)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xPtJLXQuhA7k",
        "outputId": "1be5b1a8-12c0-48e1-977c-1be6fea5bf56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(27, 10)        | exact: False | approximate: True  | maxdiff: 1.1175870895385742e-08\n",
            "(30, 200)       | exact: False | approximate: True  | maxdiff: 1.1175870895385742e-08\n",
            "(200,)          | exact: False | approximate: True  | maxdiff: 3.14321368932724e-09\n",
            "(200, 27)       | exact: False | approximate: True  | maxdiff: 1.4901161193847656e-08\n",
            "(27,)           | exact: False | approximate: True  | maxdiff: 7.450580596923828e-09\n",
            "(1, 200)        | exact: False | approximate: True  | maxdiff: 2.3283064365386963e-09\n",
            "(1, 200)        | exact: False | approximate: True  | maxdiff: 7.450580596923828e-09\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Full training without pytorch autograd"
      ],
      "metadata": {
        "id": "GIzYUEVJkjsR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Exercise 4: putting it all together!\n",
        "# Train the MLP neural net with your own backward pass\n",
        "\n",
        "# init\n",
        "n_embd = 10 # the dimensionality of the character embedding vectors\n",
        "n_hidden = 200 # the number of neurons in the hidden layer of the MLP\n",
        "\n",
        "g = torch.Generator().manual_seed(2147483647) # for reproducibility\n",
        "C  = torch.randn((vocab_size, n_embd),            generator=g)\n",
        "# Layer 1\n",
        "W1 = torch.randn((n_embd * block_size, n_hidden), generator=g) * (5/3)/((n_embd * block_size)**0.5)\n",
        "b1 = torch.randn(n_hidden,                        generator=g) * 0.1\n",
        "# Layer 2\n",
        "W2 = torch.randn((n_hidden, vocab_size),          generator=g) * 0.1\n",
        "b2 = torch.randn(vocab_size,                      generator=g) * 0.1\n",
        "# BatchNorm parameters\n",
        "bngain = torch.randn((1, n_hidden))*0.1 + 1.0\n",
        "bnbias = torch.randn((1, n_hidden))*0.1\n",
        "\n",
        "parameters = [C, W1, b1, W2, b2, bngain, bnbias]\n",
        "print(sum(p.nelement() for p in parameters)) # number of parameters in total\n",
        "for p in parameters:\n",
        "  p.requires_grad = True\n",
        "\n",
        "# same optimization as last time\n",
        "max_steps = 200000\n",
        "batch_size = 32\n",
        "n = batch_size # convenience\n",
        "lossi = []\n",
        "\n",
        "# use this context manager for efficiency once your backward pass is written (TODO)\n",
        "with torch.no_grad():\n",
        "\n",
        "  # kick off optimization\n",
        "  for i in range(max_steps):\n",
        "\n",
        "    # minibatch construct\n",
        "    ix = torch.randint(0, Xtr.shape[0], (batch_size,), generator=g)\n",
        "    Xb, Yb = Xtr[ix], Ytr[ix] # batch X,Y\n",
        "\n",
        "    # forward pass\n",
        "    emb = C[Xb] # embed the characters into vectors\n",
        "    embcat = emb.view(emb.shape[0], -1) # concatenate the vectors\n",
        "    # Linear layer\n",
        "    hprebn = embcat @ W1 + b1 # hidden layer pre-activation\n",
        "    # BatchNorm layer\n",
        "    # -------------------------------------------------------------\n",
        "    bnmean = hprebn.mean(0, keepdim=True)\n",
        "    bnvar = hprebn.var(0, keepdim=True, unbiased=True)\n",
        "    bnvar_inv = (bnvar + 1e-5)**-0.5\n",
        "    bnraw = (hprebn - bnmean) * bnvar_inv\n",
        "    hpreact = bngain * bnraw + bnbias\n",
        "    # -------------------------------------------------------------\n",
        "    # Non-linearity\n",
        "    h = torch.tanh(hpreact) # hidden layer\n",
        "    logits = h @ W2 + b2 # output layer\n",
        "    loss = F.cross_entropy(logits, Yb) # loss function\n",
        "\n",
        "    # backward pass\n",
        "    for p in parameters:\n",
        "      p.grad = None\n",
        "    # loss.backward() # use this for correctness comparisons, delete it later!\n",
        "\n",
        "    # manual backprop! #swole_doge_meme\n",
        "    # -----------------\n",
        "    dlogits = F.softmax(logits, 1)\n",
        "    dlogits[range(n), Yb] -= 1\n",
        "    dlogits /= n\n",
        "    # 2nd layer backprop\n",
        "    dh = dlogits @ W2.T\n",
        "    dW2 = h.T @ dlogits\n",
        "    db2 = dlogits.sum(0)\n",
        "    # tanh\n",
        "    dhpreact = (1.0 - h**2) * dh\n",
        "    # batchnorm backprop\n",
        "    dbngain = (bnraw * dhpreact).sum(0, keepdim=True)\n",
        "    dbnbias = dhpreact.sum(0, keepdim=True)\n",
        "    dhprebn = bngain*bnvar_inv/n * (n*dhpreact - dhpreact.sum(0) - n/(n-1)*bnraw*(dhpreact*bnraw).sum(0))\n",
        "    # 1st layer\n",
        "    dembcat = dhprebn @ W1.T\n",
        "    dW1 = embcat.T @ dhprebn\n",
        "    db1 = dhprebn.sum(0)\n",
        "    # embedding\n",
        "    demb = dembcat.view(emb.shape)\n",
        "    dC = torch.zeros_like(C)\n",
        "    for k in range(Xb.shape[0]):\n",
        "      for j in range(Xb.shape[1]):\n",
        "        ix = Xb[k,j]\n",
        "        dC[ix] += demb[k,j]\n",
        "    grads = [dC, dW1, db1, dW2, db2, dbngain, dbnbias]\n",
        "    # -----------------\n",
        "\n",
        "    # update\n",
        "    lr = 0.1 if i < 100000 else 0.01 # step learning rate decay\n",
        "    for p, grad in zip(parameters, grads):\n",
        "      #p.data += -lr * p.grad # old way of cheems doge (using PyTorch grad from .backward())\n",
        "      p.data += -lr * grad # new way of swole doge TODO: enable\n",
        "\n",
        "    # track stats\n",
        "    if i % 10000 == 0: # print every once in a while\n",
        "      print(f'{i:7d}/{max_steps:7d}: {loss.item():.4f}')\n",
        "    lossi.append(loss.log10().item())\n",
        "\n",
        "    # if i >= 100: # TODO: delete early breaking when you're ready to train the full net\n",
        "    #   break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sjjWpeJ2hZwy",
        "outputId": "6fd4b6cb-360b-4fe7-cf8f-8a5500ca15c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12297\n",
            "      0/ 200000: 3.7902\n",
            "  10000/ 200000: 2.2002\n",
            "  20000/ 200000: 2.4057\n",
            "  30000/ 200000: 2.4835\n",
            "  40000/ 200000: 1.9943\n",
            "  50000/ 200000: 2.3577\n",
            "  60000/ 200000: 2.3093\n",
            "  70000/ 200000: 2.0025\n",
            "  80000/ 200000: 2.4324\n",
            "  90000/ 200000: 2.1367\n",
            " 100000/ 200000: 1.9467\n",
            " 110000/ 200000: 2.2802\n",
            " 120000/ 200000: 1.9717\n",
            " 130000/ 200000: 2.3674\n",
            " 140000/ 200000: 2.2753\n",
            " 150000/ 200000: 2.1567\n",
            " 160000/ 200000: 1.9345\n",
            " 170000/ 200000: 1.8242\n",
            " 180000/ 200000: 2.0368\n",
            " 190000/ 200000: 1.9380\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# calibrate the batch norm at the end of training\n",
        "\n",
        "with torch.no_grad():\n",
        "  # pass the training set through\n",
        "  emb = C[Xtr]\n",
        "  embcat = emb.view(emb.shape[0], -1)\n",
        "  hpreact = embcat @ W1 + b1\n",
        "  # measure the mean/std over the entire training set\n",
        "  bnmean = hpreact.mean(0, keepdim=True)\n",
        "  bnvar = hpreact.var(0, keepdim=True, unbiased=True)"
      ],
      "metadata": {
        "id": "VICZ4VlmkcTL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate train and val loss\n",
        "\n",
        "@torch.no_grad() # this decorator disables gradient tracking\n",
        "def split_loss(split):\n",
        "  x,y = {\n",
        "    'train': (Xtr, Ytr),\n",
        "    'val': (Xdev, Ydev),\n",
        "    'test': (Xte, Yte),\n",
        "  }[split]\n",
        "  emb = C[x] # (N, block_size, n_embd)\n",
        "  embcat = emb.view(emb.shape[0], -1) # concat into (N, block_size * n_embd)\n",
        "  hpreact = embcat @ W1 + b1\n",
        "  hpreact = bngain * (hpreact - bnmean) * (bnvar + 1e-5)**-0.5 + bnbias\n",
        "  h = torch.tanh(hpreact) # (N, n_hidden)\n",
        "  logits = h @ W2 + b2 # (N, vocab_size)\n",
        "  loss = F.cross_entropy(logits, y)\n",
        "  print(split, loss.item())\n",
        "\n",
        "split_loss('train')\n",
        "split_loss('val')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8MQvNm5tkerP",
        "outputId": "d17ec031-8ea7-4fcc-9edf-1facba8af825"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train 2.071709632873535\n",
            "val 2.1087567806243896\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sample from the model\n",
        "g = torch.Generator().manual_seed(2147483647 + 10)\n",
        "\n",
        "for _ in range(20):\n",
        "\n",
        "    out = []\n",
        "    context = [0] * block_size # initialize with all ...\n",
        "    while True:\n",
        "      # ------------\n",
        "      # forward pass:\n",
        "      # Embedding\n",
        "      emb = C[torch.tensor([context])] # (1,block_size,d)\n",
        "      embcat = emb.view(emb.shape[0], -1) # concat into (N, block_size * n_embd)\n",
        "      hpreact = embcat @ W1 + b1\n",
        "      hpreact = bngain * (hpreact - bnmean) * (bnvar + 1e-5)**-0.5 + bnbias\n",
        "      h = torch.tanh(hpreact) # (N, n_hidden)\n",
        "      logits = h @ W2 + b2 # (N, vocab_size)\n",
        "      # ------------\n",
        "      # Sample\n",
        "      probs = F.softmax(logits, dim=1)\n",
        "      ix = torch.multinomial(probs, num_samples=1, generator=g).item()\n",
        "      context = context[1:] + [ix]\n",
        "      out.append(ix)\n",
        "      if ix == 0:\n",
        "        break\n",
        "\n",
        "    print(''.join(itos[i] for i in out))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5mWatdVIkhDd",
        "outputId": "9fd31860-68f7-4533-f546-19a40a74d229"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mora.\n",
            "mayah.\n",
            "seen.\n",
            "ndhayla.\n",
            "ren.\n",
            "ruchadrie.\n",
            "cailee.\n",
            "melin.\n",
            "shi.\n",
            "jenleigh.\n",
            "estanaraelyzion.\n",
            "kamin.\n",
            "shubergihimie.\n",
            "tri.\n",
            "joselle.\n",
            "joseus.\n",
            "kuba.\n",
            "geder.\n",
            "yarulyeh.\n",
            "yuma.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Glossary"
      ],
      "metadata": {
        "id": "ZCbXTno0aMPQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## `torch.all()` and `torch.allclose()`\n",
        "\n",
        "### 1. `torch.all()`\n",
        "\n",
        "#### Purpose:\n",
        "This function tests if **all** elements in a tensor are `True` or non-zero.\n",
        "\n",
        "#### Explanation:\n",
        "- If you have a tensor of boolean values (e.g., the result of some comparison operation), `torch.all()` will return `True` only if every element in that tensor is `True`.\n",
        "- For non-boolean tensors, it checks if all elements are non-zero.\n",
        "\n",
        "#### Example:\n",
        "\n",
        "```python\n",
        "import torch\n",
        "\n",
        "# Using boolean tensor\n",
        "a = torch.tensor([True, True, True])\n",
        "b = torch.tensor([True, False, True])\n",
        "print(torch.all(a))  # Output: True\n",
        "print(torch.all(b))  # Output: False\n",
        "\n",
        "# Using integer tensor\n",
        "c = torch.tensor([1, 2, 3])\n",
        "d = torch.tensor([1, 0, 3])\n",
        "print(torch.all(c))  # Output: True\n",
        "print(torch.all(d))  # Output: False\n",
        "```\n",
        "\n",
        "### 2. `torch.allclose()`\n",
        "\n",
        "#### Purpose:\n",
        "This function checks if all elements of two tensors are approximately equal within some tolerance.\n",
        "\n",
        "#### Explanation:\n",
        "- It's used to check if two tensors are \"close enough\" element-wise, given some tolerances (`atol` and `rtol`).\n",
        "- The formula it uses to determine if two elements \\( a \\) and \\( b \\) are close is:\n",
        "  \\[ \\text{abs}(a - b) \\le \\text{atol} + \\text{rtol} \\times \\text{abs}(b) \\]\n",
        "- `atol` (absolute tolerance) and `rtol` (relative tolerance) are parameters you can specify. If not specified, they default to \\( 1 \\times 10^{-8} \\) and \\( 1 \\times 10^{-5} \\), respectively.\n",
        "\n",
        "#### Example:\n",
        "\n",
        "```python\n",
        "import torch\n",
        "\n",
        "a = torch.tensor([1.0, 2.0, 3.0])\n",
        "b = torch.tensor([1.0, 2.01, 3.0])\n",
        "c = torch.tensor([1.0, 2.1, 3.0])\n",
        "\n",
        "# Check if tensors are close with default tolerance\n",
        "print(torch.allclose(a, b))  # Output: True, because differences are within the default tolerances\n",
        "print(torch.allclose(a, c))  # Output: False, because the difference in the second element is too large for default tolerances\n",
        "\n",
        "# Check with custom tolerance\n",
        "print(torch.allclose(a, c, atol=0.2))  # Output: True, because we increased the absolute tolerance\n",
        "```\n",
        "\n",
        "In summary:\n",
        "- `torch.all()` checks if all elements of a tensor are `True` or non-zero.\n",
        "- `torch.allclose()` checks if all elements of two tensors are approximately equal within some tolerance."
      ],
      "metadata": {
        "id": "7YqlUqwPaaWo"
      }
    }
  ]
}