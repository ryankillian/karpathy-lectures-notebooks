{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "collapsed_sections": [
        "YRrj6dm6bMcT",
        "tiBdbxIdFu1w"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction"
      ],
      "metadata": {
        "id": "cNRujV1Gy8US"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "# Multi-Layer Perceptron (MLP) Implementation\n",
        "\n",
        "Based on Andrej Karpathy's \"Building makemore Part 2: MLP\" from the Neural Networks: Hero to Zero series ([Video Link](https://www.youtube.com/watch?v=TCH_1BHY58I)), this colab focuses on constructing an MLP as described in Bengio's paper.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "E_qCclQH1ZaG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Summary of Transcript\n",
        "\n",
        "The lecturer is discussing the implementation of a multi-layer perceptron (MLP) for predicting the next character in a sequence. Here's a breakdown of the content:\n",
        "\n",
        "1. **Introduction**:\n",
        "    - The lecturer introduced the problem of predicting the next character in a sequence using only the previous character as context. They highlighted the limitations of this simple bigram model.\n",
        "    - The exponential increase in possibilities as the context length increases was emphasized.\n",
        "\n",
        "2. **Reference to Bengio et al. 2003 Paper**:\n",
        "    - The discussion shifted to a paper by Bengio et al. from 2003, which proposed using multi-layer perceptrons for predicting the next token in a sequence.\n",
        "    - The paper's model was discussed, which embeds words into a 30-dimensional space. This space would then be fine-tuned during training.\n",
        "    - The lecturer differentiated between the paper's word-level model and the character-level model they are working on.\n",
        "\n",
        "3. **Embedding Concept**:\n",
        "    - The idea of embeddings was elaborated upon. Words or characters are transformed into vectors in a high-dimensional space. Similar words or characters might end up close to each other in this space.\n",
        "\n",
        "4. **Model Architecture**:\n",
        "    - The neural network architecture proposed in the paper was examined:\n",
        "        - Input Layer: Takes the index of incoming words and retrieves embeddings from a lookup table.\n",
        "        - Hidden Layer: Fully connected layer.\n",
        "        - Output Layer: Predicts the next word out of 17,000 possibilities.\n",
        "        - Softmax Layer: Converts logits to probabilities.\n",
        "\n",
        "5. **Implementation using PyTorch**:\n",
        "    - The lecturer started a new Jupyter notebook and began implementing the model using PyTorch.\n",
        "    - The dataset was loaded, and the vocabulary was constructed.\n",
        "    - The lecturer discussed the concept of \"block size\" which represents the context length.\n",
        "    - The dataset was prepared using this block size. The lecturer demonstrated how to reshape the data for different block sizes using examples.\n",
        "    - The embedding lookup table was implemented. The lecturer emphasized the efficiency and flexibility of PyTorch indexing.\n",
        "    - The hidden layer of the network was then implemented. The lecturer explained the concept of tensor views and storage in PyTorch, emphasizing the efficiency of reshaping operations using views.\n",
        "    - The addition of biases was also discussed, with a focus on broadcasting in PyTorch to ensure that the bias addition works correctly across batches of data.\n",
        "\n",
        "The lecture seems to be a mix of theoretical understanding and practical implementation, giving students a comprehensive understanding of the multi-layer perceptron model for language prediction. The lecturer's approach of explaining PyTorch operations in detail is helpful for students to understand the nuances of tensor operations and the efficiency considerations involved.\n",
        "\n",
        "---\n",
        "\n",
        "The lecturer discusses the following topics:\n",
        "\n",
        "1. **Using PyTorch's Functional Cross-Entropy**:\n",
        "   - Instead of manually calculating the cross-entropy loss using softmax and negative log likelihood, one can use PyTorch's built-in function `F.cross_entropy` which is optimized for performance.\n",
        "   - The benefits of using `F.cross_entropy`:\n",
        "     - Avoids creating intermediate tensors, thereby saving memory.\n",
        "     - Provides an efficient backward pass.\n",
        "     - Handles numerical instabilities, especially when dealing with extremely large or small logits.\n",
        "\n",
        "2. **Training on the Full Dataset with Mini-Batches**:\n",
        "   - Instead of training on the entire dataset, which can be computationally expensive, mini-batches are used.\n",
        "   - Training on mini-batches provides an approximate gradient, which is often sufficient for training purposes and is much faster than using the full dataset.\n",
        "\n",
        "3. **Finding a Good Initial Learning Rate**:\n",
        "   - The learning rate plays a crucial role in the optimization process.\n",
        "   - A method to find a reasonable learning rate:\n",
        "     - Start with a very low learning rate and gradually increase it.\n",
        "     - Plot the loss against the learning rate.\n",
        "     - Choose a learning rate from the plot where the loss is still decreasing but before it starts to increase or become unstable.\n",
        "\n",
        "4. **Training Neural Network**:\n",
        "   - The training loop consists of the forward pass, backward pass, and parameter update.\n",
        "   - Regularly evaluating the loss provides insights into how the model is performing.\n",
        "   - Once the model starts plateauing (not improving much), a common practice is to reduce the learning rate (known as learning rate decay) to refine the model further.\n",
        "\n",
        "5. **Comparison with Bi-gram Model**:\n",
        "   - The neural network achieved a lower loss compared to the bi-gram language model, indicating better performance.\n",
        "\n",
        "In summary, the lecture provides an overview of how to implement a simple neural network in PyTorch for language modeling, efficiently calculate the loss using built-in functions, optimize the training process using mini-batches, and determine an effective learning rate.\n",
        "\n",
        "---\n",
        "\n",
        "# Neural Networks for Text Generation\n",
        "\n",
        "## Introduction\n",
        "Text generation using neural networks is a popular approach in natural language processing. In this lecture, we focus on generating names or words, treating them as sequences of characters.\n",
        "\n",
        "## Model Architecture\n",
        "\n",
        "### Input and Output\n",
        "- **Input**: A sequence of characters (e.g., 'abc').\n",
        "- **Output**: The next character in the sequence (e.g., 'd' for 'abcd').\n",
        "\n",
        "### Embedding Layer\n",
        "- Maps each character to a fixed-size vector.\n",
        "- Helps the model learn relationships between characters.\n",
        "- Initial embeddings are small (2-dimensional) but can be increased.\n",
        "\n",
        "### Hidden Layer\n",
        "- Fully connected layer that processes the embedded characters.\n",
        "- The number of neurons can be varied. More neurons can increase capacity but may also risk overfitting.\n",
        "\n",
        "### Softmax Layer\n",
        "- Converts the output of the hidden layer to a probability distribution over all possible next characters.\n",
        "\n",
        "## Training\n",
        "\n",
        "### Data Preparation\n",
        "- Convert words into numerical representations.\n",
        "- Split the dataset into:\n",
        "  - Training set (80%)\n",
        "  - Validation set (Dev set) (10%)\n",
        "  - Test set (10%)\n",
        "\n",
        "### Loss Function\n",
        "- Cross-entropy loss is used.\n",
        "- Measures the difference between the predicted probability distribution and the actual distribution.\n",
        "\n",
        "### Overfitting\n",
        "- A large model with many parameters can memorize the training set.\n",
        "- It's important to evaluate the model on unseen data (validation and test sets) to ensure it generalizes well.\n",
        "\n",
        "### Hyperparameters\n",
        "- Include learning rate, batch size, embedding size, hidden layer size, etc.\n",
        "- They can be tuned based on performance on the validation set.\n",
        "\n",
        "## Results\n",
        "- The loss value indicates how well the model is performing (lower is better).\n",
        "- A well-trained model can generate text that resembles real words or names.\n",
        "\n",
        "## Sampling from the Model\n",
        "- To generate new text, start with an initial sequence and predict the next character.\n",
        "- Repeat the process using the predicted character as part of the new sequence.\n",
        "\n",
        "## Practical Tips\n",
        "1. Monitor training and validation loss to detect overfitting.\n",
        "2. Adjust the learning rate and try learning rate decay.\n",
        "3. Experiment with the model's architecture, including embedding and hidden layer sizes.\n",
        "4. Use tools like Google Colab for an interactive experience without installation hassles.\n",
        "\n",
        "## Conclusion\n",
        "Neural networks provide a powerful tool for text generation. By understanding the underlying principles and experimenting with different configurations, one can achieve impressive results in generating coherent and novel text sequences.\n",
        "\n"
      ],
      "metadata": {
        "id": "aZToiswqzAUu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# A Neural Probabilistic Language Model (summary)"
      ],
      "metadata": {
        "id": "XBlSE4_7wOfN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "(c 2003 Yoshua Bengio, Réjean Ducharme, Pascal Vincent, Christian Jauvin.)\n",
        "\n",
        "## Abstract\n",
        "\n",
        "The goal of statistical language modeling is to learn how likely different combinations of words are in a language.\n",
        "\n",
        "- \"Joint probability function\": This is a fancy way of saying \"how likely different things are to happen together\". In this case, it's about how likely different words are to appear together in a sequence.\n",
        "\n",
        "- \"Sequences of words\": This refers to a series of words that come one after the other, like a sentence or a phrase.\n",
        "\n",
        "In statistical language modeling, the aim is to figure out how likely it is that certain words will appear together in a certain order in a language.\n",
        "\n",
        "1. **Goal**: The goal of statistical language modeling is to learn how likely certain sequences of words are in a language. This is a hard task because there are so many possible word combinations (this is called the curse of dimensionality).\n",
        "\n",
        "2. **Traditional Approach**: Traditional approaches, like n-grams, deal with this by looking at short sequences of words that have been seen before and piecing them together. This works reasonably well, but it has limitations.\n",
        "\n",
        "3. **New Approach**: The authors suggest a new approach where words are represented in a way that captures their meaning. This is done by learning a distributed representation for words, which allows the model to understand the meaning of words in a way that can be shared across many different sentences. This way, even if the model encounters a new sentence, it can make good guesses about it if the words in the sentence are similar in meaning to words it has seen before.\n",
        "\n",
        "4. **How it works**: The model is trained to learn two things at the same time: a) how to represent words in a way that captures their meaning, and b) how likely different sequences of words are, based on these representations.\n",
        "\n",
        "5. **Generalization**: This approach allows the model to generalize to new sentences it hasn't seen before because it can understand the meaning of the words in the sentence. If a new sentence is made of words that are similar in meaning to words in a sentence the model has seen before, the model will give it a high probability.\n",
        "\n",
        "6. **Challenges**: Training these models is challenging because they can have millions of parameters, and it takes a long time to train them.\n",
        "\n",
        "7. **Results**: The authors report that they have used neural networks to model the probability function and that their new approach works better than traditional n-gram models on two text corpora. They also found that their approach can take advantage of longer contexts (i.e., longer sequences of words).\n"
      ],
      "metadata": {
        "id": "EKP46S-2KG9I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Introduction\n",
        "\n",
        "1. **Curse of Dimensionality**: The more variables (or dimensions) you have in your data, the harder it is to analyze. This is especially true when you're dealing with words in a language because there are so many possible combinations of words.\n",
        "\n",
        "2. **Discrete vs. Continuous Variables**: When dealing with continuous variables (like height or weight), it's easier to generalize because you can assume that nearby values are similar. But with discrete variables (like words), it's hard to tell how similar two values are. For example, changing one letter in a word can completely change its meaning.\n",
        "\n",
        "3. **Probability Mass Distribution**: One way to think about how learning algorithms generalize is by looking at how they spread out probability mass (or likelihood) from training data to new, unseen data. In high dimensions, it's important to spread this mass in the right directions, not just everywhere.\n",
        "\n",
        "4. **Statistical Language Models**: These are models that try to predict the next word in a sentence based on all the previous words. They're useful in many areas, like speech recognition and language translation.\n",
        "\n",
        "5. **N-gram Models**: These models simplify the task by only looking at the last few words (n-1 words) to predict the next word. But this means they might miss important context from earlier in the sentence.\n",
        "\n",
        "6. **Generalization in N-gram Models**: These models generalize by \"gluing\" together short, overlapping pieces of text that were seen in the training data. This works well for small contexts (like trigrams, where n=3), but misses out on longer contexts.\n",
        "\n",
        "7. **Similarity Between Words**: Current models don't consider that some words are similar in meaning or grammar. For example, \"cat\" and \"dog\" are similar because they're both animals and can play similar roles in sentences.\n",
        "\n",
        "8. **Proposed Approach**: The paper is proposing a new approach that addresses these issues by learning a distributed representation for words. This allows the model to understand the similarity between words and take into account longer contexts.\n",
        "\n",
        "9. **Implementation and Results**: The paper implements these ideas using multi-layer neural networks with shared parameters. The paper also discusses the challenge of training such large models on big datasets and shows that it's feasible and gives good results.\n",
        "\n",
        "10. **Matrix Notation**: The paper uses matrix notation for many operations, with specific symbols representing vectors and matrices.\n",
        "\n",
        "In essence, the section is discussing the problems with traditional language modeling techniques and introducing a new approach that addresses these problems. The new approach uses distributed representations for words and multi-layer neural networks to capture longer contexts and similarities between words."
      ],
      "metadata": {
        "id": "qwCl1QsHMjQc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  1.1 Fighting the Curse of Dimensionality with Distributed Representations\n",
        "\n",
        "1. **Distributed Word Feature Vector**: The proposed approach gives each word in the vocabulary a \"feature vector.\" Think of this as a unique fingerprint for the word, capturing its various characteristics. For example, a word like \"cat\" might have features relating to being an animal, a pet, and so on.\n",
        "\n",
        "2. **Joint Probability Function**: The model uses these fingerprints to predict the likelihood of sequences of words appearing together. Instead of considering each word individually, the model looks at their feature vectors.\n",
        "\n",
        "3. **Simultaneous Learning**: The approach learns the fingerprints and the probability function at the same time. This is done by adjusting them to better predict the training data.\n",
        "\n",
        "4. **Why Does it Work?**: The key idea is that similar words have similar fingerprints. So if the model has seen a sentence like \"The cat is walking in the bedroom,\" it can generalize to similar sentences like \"A dog was running in a room\" because the words \"cat\" and \"dog\" have similar fingerprints. The model is smart enough to realize that these sentences have similar structures and meanings.\n",
        "\n",
        "5. **Smooth Probability Function**: The probability function is \"smooth,\" meaning a small change in the fingerprints results in a small change in the probability. This allows the model to generalize from one sentence to many similar sentences. It's like knowing that \"The cat is walking in the bedroom\" makes it more likely to see \"A dog was running in a room\" or \"The dog was walking in the room.\"\n",
        "\n",
        "6. **Regularized Criterion**: The approach uses a technique called regularization to prevent the model from fitting the training data too closely. This is like adding a penalty for making the model too complex.\n",
        "\n",
        "7. **Semantic Features**: The fingerprints for each word can be learned from the data, but could also be initialized using prior knowledge about the words.\n",
        "\n",
        "In summary, this section is introducing a new approach to language modeling that represents each word with a feature vector or fingerprint. The model uses these fingerprints to predict sequences of words and learns the fingerprints and the prediction function at the same time. The key idea is that similar words have similar fingerprints, allowing the model to generalize from sentences it has seen to similar sentences it hasn't seen."
      ],
      "metadata": {
        "id": "mrM1AI0xN19R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.2 Relation to Previous Work\n",
        "\n",
        "1. **Previous Work with Neural Networks**: The idea of using neural networks to model high-dimensional discrete distributions (like words in a sentence) has been explored before. In these models, the joint probability of a sequence of variables (like words in a sentence) is expressed as a product of conditional probabilities, with each probability being modeled by a neural network.\n",
        "\n",
        "2. **Modifications for Language Modeling**: The approach in this paper is different because it has to deal with variable-length data (like sentences of different lengths) and all the variables (words in a sentence) are of the same type (words). So, the same neural network is used for all positions in the sentence, sharing parameters across time and input words.\n",
        "\n",
        "3. **Distributed Representation**: The model learns a distributed representation for words, or a \"feature vector\" for each word. This is an old idea from the early days of connectionism that represents symbolic data as real-valued vectors.\n",
        "\n",
        "4. **Similarities Between Words**: The model takes advantage of the similarities between words to generalize from seen sentences to new sentences. Instead of using a hard or soft partition of words into classes (like word clustering approaches), this model uses a continuous real-valued vector for each word to represent similarity.\n",
        "\n",
        "5. **Vector-Space Representation**: Using a vector-space representation for words has been used in information retrieval, where feature vectors for words are learned based on their co-occurrence in documents. The difference here is that this model is looking for a representation that helps compactly represent the probability distribution of word sequences.\n",
        "\n",
        "6. **Joint Learning**: The paper suggests that learning the word features and the model at the same time is very useful. They tried using fixed word features based on co-occurrence frequencies, similar to Latent Semantic Indexing in information retrieval, but it didn't work as well.\n",
        "\n",
        "7. **Parameter Sharing Layer**: The idea of a vector-space representation for symbols in the context of neural networks has also been framed as a parameter sharing layer, which has been used for secondary structure prediction and text-to-speech mapping.\n",
        "\n",
        "In summary, this section is discussing how the proposed approach is related to previous work. It's taking ideas from earlier neural network models for high-dimensional discrete distributions and adapting them for language modeling. The model learns a distributed representation for words and uses this to generalize from seen sentences to new sentences. This approach is compared to other methods of representing words and modeling language."
      ],
      "metadata": {
        "id": "tO1EDFHOPTDw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. A Neural Model\n",
        "\n",
        "This section outlines a neural model for learning a statistical language model.\n",
        "\n",
        "1. **Objective**: The goal is to learn a model \\($f(w_t, \\ldots, w_{t-n+1})$\\) that gives the probability of a word \\(w_t\\) given the previous \\(n-1\\) words. The aim is to make this model give high out-of-sample likelihood (i.e., perform well on unseen data).\n",
        "\n",
        "2. **Decomposing the Model**: The model \\(f\\) is decomposed into two parts:\n",
        "   - A mapping \\(C\\) that associates each word in the vocabulary \\(V\\) with a feature vector \\($C(i)$\\) in \\($R^m$\\), where \\(m\\) is the number of features. These feature vectors are stored in a matrix \\(C\\) of size \\($|V| \\times m$\\).\n",
        "   - A probability function \\(g\\) that takes a sequence of feature vectors for the words in context and outputs a probability distribution over the next word.\n",
        "\n",
        "3. **Combining the Parts**: The function \\(f\\) is a composition of \\(C\\) and \\(g\\), with \\(C\\) being shared across all the words in the context. The overall parameter set is \\($\\theta = (C, \\omega)$\\), where \\(C\\) is the feature vectors and \\($\\omega$\\) are the parameters of \\(g\\).\n",
        "\n",
        "4. **Training the Model**: The model is trained by maximizing the penalized log-likelihood of the training data, which is the sum of the log probabilities of the observed word sequences minus a regularization term \\($R(\\theta)$\\). This regularization term prevents overfitting.\n",
        "\n",
        "5. **Neural Network Details**: The function \\(g\\) is implemented by a neural network with one hidden layer and a softmax output layer. The input to the network is the concatenation of the feature vectors for the words in context. The network computes the unnormalized log-probabilities for each output word \\(i\\), which are then normalized to get the probabilities.\n",
        "\n",
        "6. **Stochastic Gradient Ascent**: Training is done using stochastic gradient ascent, which iteratively updates the parameters \\($\\theta$\\) by moving them in the direction that increases the log-likelihood of the current word in the training corpus.\n",
        "\n",
        "7. **Mixture of Models**: In the experiments, the authors found that combining the probability predictions of the neural network with those of an interpolated trigram model (a traditional n-gram model) improved performance.\n",
        "\n",
        "To summarize, the authors propose a neural model for language modeling that learns feature vectors for each word in the vocabulary and a probability function for word sequences. The model is trained on a large corpus of text to maximize the likelihood of the observed word sequences. Combining the neural model with a traditional n-gram model further improves performance."
      ],
      "metadata": {
        "id": "Zau-imMGPqkF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Parallel Implementation\n",
        "\n",
        "This section describes how the neural model for language modeling can be implemented efficiently using parallel processing. The authors discuss two approaches to parallelization: data-parallel processing and parameter-parallel processing.\n",
        "\n",
        "1. **Data-Parallel Processing**:\n",
        "    - In shared-memory processors, parallelization is straightforward because all processors can access the shared memory.\n",
        "    - Each processor works on a different subset of the data and computes the gradient for its examples.\n",
        "    - Initially, the authors used synchronization commands to ensure that processors do not overwrite each other's updates, but this was slow because processors spent a lot of time waiting for locks to be released.\n",
        "    - Instead, they chose an asynchronous implementation where each processor can write to the shared memory at any time. Sometimes, an update by one processor is overwritten by another processor, but this introduces only a small amount of noise in the parameter updates and doesn't slow down training.\n",
        "\n",
        "2. **Parameter-Parallel Processing**:\n",
        "    - For networked CPUs, frequent exchange of all parameters among processors is impractical because it would take too much time.\n",
        "    - Instead, the authors parallelize across the parameters, specifically the parameters of the output units, where most of the computation happens.\n",
        "    - Each CPU is responsible for computing the unnormalized probability for a subset of the outputs and updating the corresponding output unit parameters.\n",
        "    - CPUs need to communicate only two pieces of information: the normalization factor for the output softmax and the gradients for the hidden and word feature layers.\n",
        "    - All CPUs duplicate the computations for the word features and hidden layer, but these computations are a small part of the total computation.\n",
        "\n",
        "3. **Implementation Details**:\n",
        "    - The authors provide an outline of the computation for a single example, executed in parallel by CPU i in a cluster of M processors.\n",
        "    - They describe the forward phase, where the word features, hidden layer, and output units are computed, and the backward/update phase, where the gradients are computed and parameters updated.\n",
        "    - The weight decay regularization is not shown in the implementation but can easily be added by subtracting the weight decay factor times the learning rate times the value of the parameter from each parameter at each update.\n",
        "    - There could be a numerical problem in the computation of the exponentials in the forward phase, where all the p_j could be numerically zero, or one of them could be too large for computing the exponential. To avoid this problem, the authors subtract the maximum of the y_j’s before taking the exponentials in the softmax.\n",
        "    - By comparing the clock time of the parallel version with the clock time on a single processor, the authors found that the communication overhead was only 1/15th of the total time for one training epoch, leading to an almost perfect speed-up through parallelization.\n",
        "\n",
        "In summary, the authors describe how to implement their neural model for language modeling efficiently using parallel processing. They discuss two approaches to parallelization: data-parallel processing and parameter-parallel processing. The authors provide an outline of the computation for a single example and discuss potential numerical problems and solutions. They also mention that their parallelization approach achieves an almost perfect speed-up on a fast network."
      ],
      "metadata": {
        "id": "8M6_AgxtSi3M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusion\n",
        "\n",
        "This section provides a conclusion and summary of the main findings and contributions of the paper, along with some suggestions for future research.\n",
        "\n",
        "1. **Main Findings**: The experiments conducted on two large corpora, one with over a million examples and another with over 15 million words, demonstrated that the proposed approach significantly outperforms the smoothed trigram, a state-of-the-art language model, in terms of perplexity. The perplexity reduction was between 10 and 20%, which is a substantial improvement.\n",
        "\n",
        "2. **Key Contributions**: The authors attribute their success to the use of learned distributed representations of words. This approach effectively fights the curse of dimensionality by allowing each training sentence to inform the model about a combinatorial number of other sentences. In other words, the model can learn and generalize from similar sentences even if they haven't been seen in the training data.\n",
        "\n",
        "3. **Future Directions**: The authors suggest that there are several areas where the model can be improved, including architecture, computational efficiency, and incorporation of prior knowledge. They also identify the need to develop techniques for scaling up the model to handle larger corpora without increasing training time significantly. One possibility is to use time-delay and recurrent neural networks to capture longer-term dependencies in the data without increasing the number of parameters or computation time too much.\n",
        "\n",
        "4. **Applications**: The authors mention that evaluations of their model in practical contexts would be beneficial. In fact, some work has already been done using this type of model to improve speech recognition word error rates.\n",
        "\n",
        "5. **Implications**: The authors conclude by highlighting the potential of their approach to improve statistical language models. Instead of using traditional \"tables of conditional probabilities,\" their model uses compact and smooth distributed representations that can accommodate more conditioning variables. While traditional language models have focused on restricting or summarizing the conditioning variables to avoid overfitting, the approach presented in this paper shifts the challenge to increased computation and memory requirements. However, these requirements scale linearly, not exponentially, with the number of conditioning variables, making it more feasible to handle large amounts of data.\n",
        "\n",
        "In summary, the paper presents a successful approach to language modeling using learned distributed representations of words, which significantly reduces perplexity compared to state-of-the-art methods. The authors suggest several areas for future improvement and highlight the potential for their approach to revolutionize statistical language models by accommodating more conditioning variables without exponential scaling."
      ],
      "metadata": {
        "id": "skRoXxADSoSt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multi-Layer Perceptron"
      ],
      "metadata": {
        "id": "YRrj6dm6bMcT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## Embeddings\n",
        "\n",
        "1. **What are embeddings?**: Embeddings are a way of converting categorical data, like words or items, into numerical data that a machine learning model can understand. In other words, an embedding is a translation of a high-dimensional categorical data into a lower-dimensional continuous vector. This vector captures the relationships and structure in the data.\n",
        "\n",
        "2. **Why do we need embeddings?**: Machine learning models need numbers, not words or categories. For example, a model can't understand the word \"cat\" or the item \"toothbrush.\" So, we have to turn those things into numbers. Embeddings are a way to do this that captures the relationships between words or items.\n",
        "\n",
        "3. **How do embeddings work?**: Embeddings work by learning a vector for each category in a way that puts similar categories close together in the vector space. For example, in a word embedding, the vector for \"cat\" might be close to the vector for \"kitten\" because those words have similar meanings. This is done by training on a lot of data and adjusting the vectors to put similar things closer together.\n",
        "\n",
        "4. **Examples of widely used embeddings**:\n",
        "\n",
        "   - **Word2Vec**: This is a popular word embedding that captures the meaning of words by looking at the words that often appear nearby in text. For example, \"cat\" and \"kitten\" often appear near words like \"pet,\" so their vectors end up close together.\n",
        "\n",
        "   - **GloVe (Global Vectors for Word Representation)**: Another word embedding that is similar to Word2Vec, but it's trained on the co-occurrence of words in a corpus.\n",
        "\n",
        "   - **FastText**: An extension of Word2Vec that can create vectors for words not seen during training by breaking words down into subwords.\n",
        "\n",
        "   - **BERT (Bidirectional Encoder Representations from Transformers)**: A powerful word embedding that looks at words in context, so it can understand that the word \"bank\" in \"river bank\" and \"savings bank\" have different meanings.\n",
        "\n",
        "   - **Item2Vec**: Similar to Word2Vec but for items. For example, it can be used to learn embeddings for products in a store based on which products are often bought together.\n",
        "\n",
        "   - **Node2Vec**: Used for embedding nodes in a network or graph based on their connections to other nodes.\n",
        "\n",
        "   - **Entity Embeddings of Categorical Variables**: Used for embedding categorical variables in tabular data.\n",
        "\n",
        "5. **Example in Everyday Language**: Imagine you're trying to explain different fruits to an alien. You could give the alien a list of fruits and say, \"These fruits are similar because they're all citrus: oranges, lemons, limes.\" Instead of explaining each fruit individually, you group them by their similarity. Embeddings do the same thing but in a mathematical way. They group similar words or items together by placing them close together in a space.\n",
        "\n",
        "In summary, embeddings are a way to turn categories, like words or items, into numbers in a way that captures the relationships between those categories. They are used in many areas of machine learning to handle categorical data.\n"
      ],
      "metadata": {
        "id": "UmNRYTvjXapJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Discussion of embeddings\n",
        "\n",
        "1. **Starting Point - Vocabulary**: The researchers have a vocabulary of 17,000 words. These are the words that the model will learn about.\n",
        "\n",
        "2. **Creating a Feature Vector for Each Word**: For each word in the vocabulary, they create a feature vector. A feature vector is just a list of numbers (or \"features\") that represent that word. In this case, the feature vector has 30 numbers (or dimensions).\n",
        "\n",
        "3. **Embedding Words in a 30-Dimensional Space**: When the researchers create a 30-dimensional feature vector for a word, they are effectively \"placing\" that word in a 30-dimensional space. Each number in the feature vector corresponds to a coordinate in that space. Imagine a 3D space with x, y, and z coordinates, but instead, there are 30 coordinates.\n",
        "\n",
        "4. **Random Initialization**: At the start of training, they don't know what numbers should be in each word's feature vector. So, they just put random numbers in the vectors. This is like scattering the words randomly in the 30-dimensional space.\n",
        "\n",
        "5. **Training - Moving Words Around**: During training, they use data to adjust the numbers in the feature vectors. This is done using a process called backpropagation. When they adjust the numbers in a word's feature vector, they are effectively moving the word around in the 30-dimensional space.\n",
        "\n",
        "6. **Words with Similar Meanings Cluster Together**: As the training progresses, words that often appear in similar contexts or have similar meanings start to move closer together in the space. They end up in similar parts of the space because their feature vectors become similar.\n",
        "\n",
        "7. **Intuition**: Think of the words as points in a 30-dimensional space. At first, these points are scattered randomly. As the model trains, it \"pulls\" these points around so that words with similar meanings end up close to each other. The \"pulling\" is just adjusting the numbers in the feature vectors.\n",
        "\n",
        "In summary, the process starts with randomly placing words in a high-dimensional space. Then, as the model trains, it moves the words around in this space. Words with similar meanings end up close together. The final positions of the words in the space (i.e., their feature vectors) are a learned representation that captures the relationships between words."
      ],
      "metadata": {
        "id": "G7er3-wqas9R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating Dataset"
      ],
      "metadata": {
        "id": "r77KCUpSSb_o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/karpathy/makemore/master/names.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xXta0sLbbcwa",
        "outputId": "d473cc32-616b-45ff-db74-087f08fd93c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-08-21 07:45:01--  https://raw.githubusercontent.com/karpathy/makemore/master/names.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 228145 (223K) [text/plain]\n",
            "Saving to: ‘names.txt’\n",
            "\n",
            "names.txt           100%[===================>] 222.80K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2023-08-21 07:45:01 (11.3 MB/s) - ‘names.txt’ saved [228145/228145]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt # for making figures\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "_AQ7OfxmaYmA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words = open(\"names.txt\", \"r\").read().splitlines()\n",
        "words[:8]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A3Mv8RMUbk1H",
        "outputId": "bab5c596-ac13-4964-b1af-b62ab6187956"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5SmuXXllbyiW",
        "outputId": "67724aef-4b6b-4c0e-8136-12b0976f528f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "32033"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# build the vocabulary of characters and mappings to/from integers\n",
        "chars = sorted(list(set(''.join(words))))\n",
        "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
        "stoi['.'] = 0\n",
        "itos = {i:s for s,i in stoi.items()}\n",
        "print(itos)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tpuMkR4cb20M",
        "outputId": "2fa91a9a-90ab-442a-d7ee-df5ed1f6f360"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: '.'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# build the dataset\n",
        "block_size = 3 # context length: how many characters do we take to predict the next one?\n",
        "\n",
        "X, Y = [], []\n",
        "for w in words[:5]:\n",
        "\n",
        "  #print(w)\n",
        "  context = [0] * block_size\n",
        "  for ch in w + '.':\n",
        "    ix = stoi[ch]\n",
        "    X.append(context)\n",
        "    Y.append(ix)\n",
        "    print(''.join(itos[i] for i in context), '--->', itos[ix])\n",
        "    context = context[1:] + [ix] # crop and append\n",
        "\n",
        "X = torch.tensor(X)\n",
        "Y = torch.tensor(Y)\n",
        "print(X.shape, Y.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x6X_0HMLcXm2",
        "outputId": "0fed2455-8a04-4f0e-b335-22b72499c67e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "... ---> e\n",
            "..e ---> m\n",
            ".em ---> m\n",
            "emm ---> a\n",
            "mma ---> .\n",
            "... ---> o\n",
            "..o ---> l\n",
            ".ol ---> i\n",
            "oli ---> v\n",
            "liv ---> i\n",
            "ivi ---> a\n",
            "via ---> .\n",
            "... ---> a\n",
            "..a ---> v\n",
            ".av ---> a\n",
            "ava ---> .\n",
            "... ---> i\n",
            "..i ---> s\n",
            ".is ---> a\n",
            "isa ---> b\n",
            "sab ---> e\n",
            "abe ---> l\n",
            "bel ---> l\n",
            "ell ---> a\n",
            "lla ---> .\n",
            "... ---> s\n",
            "..s ---> o\n",
            ".so ---> p\n",
            "sop ---> h\n",
            "oph ---> i\n",
            "phi ---> a\n",
            "hia ---> .\n",
            "torch.Size([32, 3]) torch.Size([32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape, X.dtype, Y.shape, Y.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fn307BNjdrs1",
        "outputId": "3b91e63c-0013-4e38-ca36-ce4933e3e7a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([32, 3]), torch.int64, torch.Size([32]), torch.int64)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GwnV1gNqeG4w",
        "outputId": "cafe8d08-fd64-468c-a807-d04b1a31cc31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0,  0,  0],\n",
              "        [ 0,  0,  5],\n",
              "        [ 0,  5, 13],\n",
              "        [ 5, 13, 13],\n",
              "        [13, 13,  1],\n",
              "        [ 0,  0,  0],\n",
              "        [ 0,  0, 15],\n",
              "        [ 0, 15, 12],\n",
              "        [15, 12,  9],\n",
              "        [12,  9, 22],\n",
              "        [ 9, 22,  9],\n",
              "        [22,  9,  1],\n",
              "        [ 0,  0,  0],\n",
              "        [ 0,  0,  1],\n",
              "        [ 0,  1, 22],\n",
              "        [ 1, 22,  1],\n",
              "        [ 0,  0,  0],\n",
              "        [ 0,  0,  9],\n",
              "        [ 0,  9, 19],\n",
              "        [ 9, 19,  1],\n",
              "        [19,  1,  2],\n",
              "        [ 1,  2,  5],\n",
              "        [ 2,  5, 12],\n",
              "        [ 5, 12, 12],\n",
              "        [12, 12,  1],\n",
              "        [ 0,  0,  0],\n",
              "        [ 0,  0, 19],\n",
              "        [ 0, 19, 15],\n",
              "        [19, 15, 16],\n",
              "        [15, 16,  8],\n",
              "        [16,  8,  9],\n",
              "        [ 8,  9,  1]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dcsTHs0meIhp",
        "outputId": "52738e9b-5102-4c44-fcc8-a1a3bb932901"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 5, 13, 13,  1,  0, 15, 12,  9, 22,  9,  1,  0,  1, 22,  1,  0,  9, 19,\n",
              "         1,  2,  5, 12, 12,  1,  0, 19, 15, 16,  8,  9,  1,  0])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introduction to our Embedding Layer\n",
        "\n",
        "1. **Data Preparation**:\n",
        "   - First, you have a list of words, and you want to build a character-level language model.\n",
        "   - You're using a context of 3 characters to predict the next character. This is specified by the `block_size` variable.\n",
        "   - For each word, you add a '.' at the end to indicate the end of the word.\n",
        "   - You initialize a context with 3 zeros, and then for each character in the word (including the '.'), you add the character index to the context and shift the context to the right.\n",
        "   - You save the context and the character index in the `X` and `Y` lists, respectively.\n",
        "\n",
        "2. **Neural Network**:\n",
        "   - You want to create a neural network that takes the `X` values (the contexts) and predicts the `Y` values (the next characters).\n",
        "   - To do this, you'll first use an embedding layer to convert the character indices into vectors. This is the embedding lookup table `C`.\n",
        "   - You have 27 possible characters (26 letters plus the '.') and you want to embed them in a 2-dimensional space.\n",
        "\n",
        "3. **Embedding Layer**:\n",
        "   - The embedding layer is a lookup table that maps each character index to a 2-dimensional vector.\n",
        "   - These vectors represent the characters in a way that the model can understand.\n",
        "   - At the beginning, the vectors are initialized randomly. During training, the model adjusts these vectors to make them more useful for predicting the next character.\n",
        "   - As the model trains, characters that are used in similar contexts will have vectors that are close together in the 2-dimensional space.\n",
        "\n",
        "4. **Training the Model**:\n",
        "   - You'll use the `X` and `Y` values to train the model. The model will take the context (the `X` values), look up the vectors for the characters in the context, and use those vectors to predict the next character (the `Y` values).\n",
        "   - You'll use a loss function to measure how well the model is doing. The loss function will compare the model's predictions to the actual next characters.\n",
        "   - You'll use an optimization algorithm to adjust the vectors in the embedding layer and the other parameters in the model to minimize the loss.\n",
        "\n",
        "5. **Using the Model**:\n",
        "   - Once the model is trained, you can use it to predict the next character in a given context.\n",
        "   - You can also use the embedding layer to analyze the relationships between characters. For example, you could see which characters have vectors that are close together in the 2-dimensional space.\n",
        "\n",
        "In summary, you're building a character-level language model that uses an embedding layer to convert characters into vectors. You'll train the model to predict the next character in a given context by adjusting the vectors in the embedding layer and the other parameters in the model. After training, you can use the model to make predictions and analyze the relationships between characters."
      ],
      "metadata": {
        "id": "GJO9mUzZfyjY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Example of one-hot encoding vs. direct access"
      ],
      "metadata": {
        "id": "B2oe9TzASmvc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "C = torch.randn(27,2)"
      ],
      "metadata": {
        "id": "0YGP3wITgQ1V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "C"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4hidEDyLgaE3",
        "outputId": "ba514050-640d-4a2b-ce8a-a8d78d3baf30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.1736,  2.5156],\n",
              "        [-1.7108, -0.1335],\n",
              "        [ 0.2373, -0.4529],\n",
              "        [-0.5976, -0.3273],\n",
              "        [-0.7368,  0.5991],\n",
              "        [-0.4620,  0.9481],\n",
              "        [-1.3752,  0.7982],\n",
              "        [ 0.0927,  0.9669],\n",
              "        [ 0.0268, -0.5085],\n",
              "        [ 0.7192, -0.2711],\n",
              "        [ 0.3026,  0.5687],\n",
              "        [ 2.1832,  0.3560],\n",
              "        [ 1.4499,  0.1446],\n",
              "        [-1.1552, -0.2751],\n",
              "        [-1.1790, -0.1472],\n",
              "        [-0.1523, -0.8020],\n",
              "        [-0.0259, -1.0257],\n",
              "        [-0.6875,  0.2655],\n",
              "        [-0.5366,  1.5467],\n",
              "        [-1.4107,  0.9552],\n",
              "        [-0.2712, -0.8011],\n",
              "        [-0.6116,  0.1317],\n",
              "        [-3.0937,  0.0304],\n",
              "        [ 1.0960, -0.2363],\n",
              "        [ 0.4697,  1.3960],\n",
              "        [-1.4112,  0.5048],\n",
              "        [ 0.3605, -0.8901]])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "C[5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W66qZfn2hNMP",
        "outputId": "12cb0459-d482-4963-d0f7-84b4723d52d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.4620,  0.9481])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# previously used one-hot\n",
        "F.one_hot(torch.tensor(5), num_classes=27).float()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sm_difrMhZYY",
        "outputId": "98f6c0d7-b9be-4ebf-b7c6-d440804eaeab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "F.one_hot(torch.tensor(5), num_classes=27).float() @ C"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OFdmxuZxiE3q",
        "outputId": "80329205-f59e-4e36-fb71-6f60f4d8d79b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.4620,  0.9481])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Embedding Layer Discussion\n",
        "\n",
        "1. **Integer Indexing**:\n",
        "   - When you're building a character-level language model, each character is represented by an integer index.\n",
        "   - For example, the character 'a' might be represented by the integer 1, 'b' by 2, and so on.\n",
        "\n",
        "2. **Lookup Table C**:\n",
        "   - The lookup table C is an important concept here. It's a table where each row corresponds to a character's vector representation in a certain dimensional space.\n",
        "   - You can think of this table as a dictionary that maps each character (represented by its integer index) to a vector.\n",
        "   - This table is crucial because it allows the neural network to work with a more informative representation of the characters than just their integer indices.\n",
        "\n",
        "3. **Embedding Layer**:\n",
        "   - The process of converting integer indices into vectors is known as \"embedding\", and it's done by the embedding layer of the neural network.\n",
        "   - The embedding layer is essentially the lookup table C. When an integer index is input to the embedding layer, it returns the corresponding vector from the lookup table.\n",
        "\n",
        "4. **First Layer of a Bigger Neural Network**:\n",
        "   - The embedding layer can be thought of as the first layer of a larger neural network.\n",
        "   - The weights of the neurons in this layer are the vectors in the lookup table C.\n",
        "   - These neurons are linear, which means that they don't apply any activation function to their inputs. They simply return the vectors from the lookup table.\n",
        "\n",
        "5. **Feeding Integers into a Neural Network**:\n",
        "   - When you feed an integer index into the neural network, it goes into the embedding layer first.\n",
        "   - The embedding layer converts the integer into a vector by looking it up in the table C.\n",
        "   - This vector is then passed to the subsequent layers of the neural network.\n",
        "\n",
        "6. **Intuition**:\n",
        "   - The embedding layer allows the neural network to work with a richer representation of the characters than just their integer indices.\n",
        "   - The vectors in the lookup table C are adjusted during training to make them more useful for predicting the next character.\n",
        "   - Characters that appear in similar contexts will have vectors that are close together in the embedding space.\n",
        "\n",
        "In summary, the embedding layer is a crucial part of the neural network. It converts integer indices into vectors, allowing the neural network to work with a more informative representation of the characters. This layer is essentially a lookup table C, and it can be thought of as the first layer of a larger neural network. The vectors in this layer are adjusted during training to make them more useful for the task at hand."
      ],
      "metadata": {
        "id": "pq0CTrEal7n6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Embedding Layer Code"
      ],
      "metadata": {
        "id": "_ZXCBZDKSyzh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# embedding single value is easy i.e. C[5]\n",
        "# how do we simultaneously embed all these 32 x 3 intgers stored in array X\n",
        "# Pytorch indexing is flexible and powerful"
      ],
      "metadata": {
        "id": "R_B72lr-jvP0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "C[[5,6,7,7]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p63jXGwJkRsz",
        "outputId": "c0e2eb03-27bf-42f2-f7ca-15bc2987762f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.4620,  0.9481],\n",
              "        [-1.3752,  0.7982],\n",
              "        [ 0.0927,  0.9669],\n",
              "        [ 0.0927,  0.9669]])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "C[torch.tensor([5,6,7,7])]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G9vnqCXekcPM",
        "outputId": "3fdc6eec-1e36-4b5d-bb17-a39520bd4a1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.4620,  0.9481],\n",
              "        [-1.3752,  0.7982],\n",
              "        [ 0.0927,  0.9669],\n",
              "        [ 0.0927,  0.9669]])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qaJ9HZ1ok0-f",
        "outputId": "f89f535c-491d-47c2-bf49-81d989659645"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "C.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J581ZIHXk2wd",
        "outputId": "3ee4f01d-817b-4281-d690-7ea8781ab5f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([27, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "C[X].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y7Y6VfJ6lYSj",
        "outputId": "a1273b7e-5e73-4674-a3b1-0768defe4db5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 3, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# multi-dimensional indexing\n",
        "C[X]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xjERC0TAktxM",
        "outputId": "3a17026a-85a8-4ee7-d7a0-a5783ea16e3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-0.1736,  2.5156],\n",
              "         [-0.1736,  2.5156],\n",
              "         [-0.1736,  2.5156]],\n",
              "\n",
              "        [[-0.1736,  2.5156],\n",
              "         [-0.1736,  2.5156],\n",
              "         [-0.4620,  0.9481]],\n",
              "\n",
              "        [[-0.1736,  2.5156],\n",
              "         [-0.4620,  0.9481],\n",
              "         [-1.1552, -0.2751]],\n",
              "\n",
              "        [[-0.4620,  0.9481],\n",
              "         [-1.1552, -0.2751],\n",
              "         [-1.1552, -0.2751]],\n",
              "\n",
              "        [[-1.1552, -0.2751],\n",
              "         [-1.1552, -0.2751],\n",
              "         [-1.7108, -0.1335]],\n",
              "\n",
              "        [[-0.1736,  2.5156],\n",
              "         [-0.1736,  2.5156],\n",
              "         [-0.1736,  2.5156]],\n",
              "\n",
              "        [[-0.1736,  2.5156],\n",
              "         [-0.1736,  2.5156],\n",
              "         [-0.1523, -0.8020]],\n",
              "\n",
              "        [[-0.1736,  2.5156],\n",
              "         [-0.1523, -0.8020],\n",
              "         [ 1.4499,  0.1446]],\n",
              "\n",
              "        [[-0.1523, -0.8020],\n",
              "         [ 1.4499,  0.1446],\n",
              "         [ 0.7192, -0.2711]],\n",
              "\n",
              "        [[ 1.4499,  0.1446],\n",
              "         [ 0.7192, -0.2711],\n",
              "         [-3.0937,  0.0304]],\n",
              "\n",
              "        [[ 0.7192, -0.2711],\n",
              "         [-3.0937,  0.0304],\n",
              "         [ 0.7192, -0.2711]],\n",
              "\n",
              "        [[-3.0937,  0.0304],\n",
              "         [ 0.7192, -0.2711],\n",
              "         [-1.7108, -0.1335]],\n",
              "\n",
              "        [[-0.1736,  2.5156],\n",
              "         [-0.1736,  2.5156],\n",
              "         [-0.1736,  2.5156]],\n",
              "\n",
              "        [[-0.1736,  2.5156],\n",
              "         [-0.1736,  2.5156],\n",
              "         [-1.7108, -0.1335]],\n",
              "\n",
              "        [[-0.1736,  2.5156],\n",
              "         [-1.7108, -0.1335],\n",
              "         [-3.0937,  0.0304]],\n",
              "\n",
              "        [[-1.7108, -0.1335],\n",
              "         [-3.0937,  0.0304],\n",
              "         [-1.7108, -0.1335]],\n",
              "\n",
              "        [[-0.1736,  2.5156],\n",
              "         [-0.1736,  2.5156],\n",
              "         [-0.1736,  2.5156]],\n",
              "\n",
              "        [[-0.1736,  2.5156],\n",
              "         [-0.1736,  2.5156],\n",
              "         [ 0.7192, -0.2711]],\n",
              "\n",
              "        [[-0.1736,  2.5156],\n",
              "         [ 0.7192, -0.2711],\n",
              "         [-1.4107,  0.9552]],\n",
              "\n",
              "        [[ 0.7192, -0.2711],\n",
              "         [-1.4107,  0.9552],\n",
              "         [-1.7108, -0.1335]],\n",
              "\n",
              "        [[-1.4107,  0.9552],\n",
              "         [-1.7108, -0.1335],\n",
              "         [ 0.2373, -0.4529]],\n",
              "\n",
              "        [[-1.7108, -0.1335],\n",
              "         [ 0.2373, -0.4529],\n",
              "         [-0.4620,  0.9481]],\n",
              "\n",
              "        [[ 0.2373, -0.4529],\n",
              "         [-0.4620,  0.9481],\n",
              "         [ 1.4499,  0.1446]],\n",
              "\n",
              "        [[-0.4620,  0.9481],\n",
              "         [ 1.4499,  0.1446],\n",
              "         [ 1.4499,  0.1446]],\n",
              "\n",
              "        [[ 1.4499,  0.1446],\n",
              "         [ 1.4499,  0.1446],\n",
              "         [-1.7108, -0.1335]],\n",
              "\n",
              "        [[-0.1736,  2.5156],\n",
              "         [-0.1736,  2.5156],\n",
              "         [-0.1736,  2.5156]],\n",
              "\n",
              "        [[-0.1736,  2.5156],\n",
              "         [-0.1736,  2.5156],\n",
              "         [-1.4107,  0.9552]],\n",
              "\n",
              "        [[-0.1736,  2.5156],\n",
              "         [-1.4107,  0.9552],\n",
              "         [-0.1523, -0.8020]],\n",
              "\n",
              "        [[-1.4107,  0.9552],\n",
              "         [-0.1523, -0.8020],\n",
              "         [-0.0259, -1.0257]],\n",
              "\n",
              "        [[-0.1523, -0.8020],\n",
              "         [-0.0259, -1.0257],\n",
              "         [ 0.0268, -0.5085]],\n",
              "\n",
              "        [[-0.0259, -1.0257],\n",
              "         [ 0.0268, -0.5085],\n",
              "         [ 0.7192, -0.2711]],\n",
              "\n",
              "        [[ 0.0268, -0.5085],\n",
              "         [ 0.7192, -0.2711],\n",
              "         [-1.7108, -0.1335]]])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oev4QpyFnOHW",
        "outputId": "aef1e20a-ef10-4592-f521-20cc923a32fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0,  0,  0],\n",
              "        [ 0,  0,  5],\n",
              "        [ 0,  5, 13],\n",
              "        [ 5, 13, 13],\n",
              "        [13, 13,  1],\n",
              "        [ 0,  0,  0],\n",
              "        [ 0,  0, 15],\n",
              "        [ 0, 15, 12],\n",
              "        [15, 12,  9],\n",
              "        [12,  9, 22],\n",
              "        [ 9, 22,  9],\n",
              "        [22,  9,  1],\n",
              "        [ 0,  0,  0],\n",
              "        [ 0,  0,  1],\n",
              "        [ 0,  1, 22],\n",
              "        [ 1, 22,  1],\n",
              "        [ 0,  0,  0],\n",
              "        [ 0,  0,  9],\n",
              "        [ 0,  9, 19],\n",
              "        [ 9, 19,  1],\n",
              "        [19,  1,  2],\n",
              "        [ 1,  2,  5],\n",
              "        [ 2,  5, 12],\n",
              "        [ 5, 12, 12],\n",
              "        [12, 12,  1],\n",
              "        [ 0,  0,  0],\n",
              "        [ 0,  0, 19],\n",
              "        [ 0, 19, 15],\n",
              "        [19, 15, 16],\n",
              "        [15, 16,  8],\n",
              "        [16,  8,  9],\n",
              "        [ 8,  9,  1]])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X[13]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A3nkv2rfnE0s",
        "outputId": "ebd1f26b-1219-46fa-94b0-7d0ffd0b2cba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X[13,2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sSgWZPrqnLKS",
        "outputId": "2d55a444-708c-4389-929f-718a8fe149b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "C[X[13,2]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KyWqiJOnnUAG",
        "outputId": "d18ed644-ce0a-4cc0-87d4-f5976ef6ef73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-1.7108, -0.1335])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "C[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KEtBOgQJnb_-",
        "outputId": "62b3896e-b48f-4b12-e1e0-d423ea7a5de8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-1.7108, -0.1335])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "emb = C[X]"
      ],
      "metadata": {
        "id": "zUlF1b3GoB_Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emb.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4F2jvf7poEnO",
        "outputId": "e36d2c98-cc78-4ace-fcb9-a89d97da6411"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 3, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Here, we're constructing the hidden layer of a neural network, which is a key component in the learning process. The hidden layer transforms the input data (in this case, the embeddings of the characters) into a format that makes it easier for the output layer to make predictions. This transformation is done through a combination of linear and nonlinear operations.\n",
        "\n",
        "Let's break down the steps:\n",
        "\n",
        "1. **Input data**: The input data, denoted as `emb`, is the embeddings of the characters. It has a shape of `[32, 3, 2]`, where 32 is the batch size, 3 is the block size (context length), and 2 is the embedding dimension. Each row in `emb` represents the embeddings of the characters in the context.\n",
        "\n",
        "2. **Flattening the input data**: We need to flatten the input data so that it can be used in the hidden layer. The `view` function in PyTorch is used to reshape the data. In this case, we're reshaping the data from `[32, 3, 2]` to `[32, 6]`. This operation essentially concatenates the embeddings of the characters in the context into a single vector.\n",
        "\n",
        "3. **Linear transformation**: The hidden layer performs a linear transformation on the input data. This transformation is defined by the weight matrix `W1` and the bias vector `b1`. The weight matrix has a shape of `[6, 100]`, where 6 is the input dimension (flattened embedding size) and 100 is the number of neurons in the hidden layer. The bias vector has a shape of `[100]`, which matches the number of neurons. The linear transformation is done by multiplying the input data with the weight matrix and adding the bias vector: `h = emb.view(-1, 6) @ W1 + b1`.\n",
        "\n",
        "4. **Activation function**: After the linear transformation, we apply the hyperbolic tangent (`tanh`) activation function to introduce nonlinearity into the model. This nonlinearity allows the model to learn more complex patterns in the data. The activation function is applied element-wise to the output of the linear transformation: `h = torch.tanh(emb.view(32, 6) @ W1 + b1)`.\n",
        "\n",
        "In summary, the hidden layer transforms the input data (character embeddings) through a combination of linear and nonlinear operations. This transformation helps the model learn and represent complex patterns in the data, making it easier for the output layer to make predictions."
      ],
      "metadata": {
        "id": "tiBdbxIdFu1w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating the Hidden Layer"
      ],
      "metadata": {
        "id": "yWPXzwRBTPQf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "W1 = torch.randn(6,100)\n",
        "b1 = torch.rand(100)\n"
      ],
      "metadata": {
        "id": "PqDwsErdGcHa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# alternative approach to concatenate inputs\n",
        "# grabs embeddins for first char\n",
        "emb[:,0,:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D1nYd3BrHpMY",
        "outputId": "c84e1511-2769-4a9e-ea8e-e0563393caf6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.1736,  2.5156],\n",
              "        [-0.1736,  2.5156],\n",
              "        [-0.1736,  2.5156],\n",
              "        [-0.4620,  0.9481],\n",
              "        [-1.1552, -0.2751],\n",
              "        [-0.1736,  2.5156],\n",
              "        [-0.1736,  2.5156],\n",
              "        [-0.1736,  2.5156],\n",
              "        [-0.1523, -0.8020],\n",
              "        [ 1.4499,  0.1446],\n",
              "        [ 0.7192, -0.2711],\n",
              "        [-3.0937,  0.0304],\n",
              "        [-0.1736,  2.5156],\n",
              "        [-0.1736,  2.5156],\n",
              "        [-0.1736,  2.5156],\n",
              "        [-1.7108, -0.1335],\n",
              "        [-0.1736,  2.5156],\n",
              "        [-0.1736,  2.5156],\n",
              "        [-0.1736,  2.5156],\n",
              "        [ 0.7192, -0.2711],\n",
              "        [-1.4107,  0.9552],\n",
              "        [-1.7108, -0.1335],\n",
              "        [ 0.2373, -0.4529],\n",
              "        [-0.4620,  0.9481],\n",
              "        [ 1.4499,  0.1446],\n",
              "        [-0.1736,  2.5156],\n",
              "        [-0.1736,  2.5156],\n",
              "        [-0.1736,  2.5156],\n",
              "        [-1.4107,  0.9552],\n",
              "        [-0.1523, -0.8020],\n",
              "        [-0.0259, -1.0257],\n",
              "        [ 0.0268, -0.5085]])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "emb[:,0,:].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g0WtLlWwHuS9",
        "outputId": "28f4302b-1e1f-4996-b5a0-f0a08cf14372"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cat([emb[:,0,:], emb[:,1,:], emb[:,2,:]], dim=1).shape\n",
        "\n",
        "# what happens if we change block size? we have to change this code. Not good."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mo-2brfGIaRs",
        "outputId": "61965cf1-e463-4437-8af9-00a0bc4e52b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 6])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# another approach\n",
        "torch.unbind(emb,1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M2-dv-xDJbCx",
        "outputId": "c2e8788e-8621-462a-9b5d-2c7b0f3594df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[-0.1736,  2.5156],\n",
              "         [-0.1736,  2.5156],\n",
              "         [-0.1736,  2.5156],\n",
              "         [-0.4620,  0.9481],\n",
              "         [-1.1552, -0.2751],\n",
              "         [-0.1736,  2.5156],\n",
              "         [-0.1736,  2.5156],\n",
              "         [-0.1736,  2.5156],\n",
              "         [-0.1523, -0.8020],\n",
              "         [ 1.4499,  0.1446],\n",
              "         [ 0.7192, -0.2711],\n",
              "         [-3.0937,  0.0304],\n",
              "         [-0.1736,  2.5156],\n",
              "         [-0.1736,  2.5156],\n",
              "         [-0.1736,  2.5156],\n",
              "         [-1.7108, -0.1335],\n",
              "         [-0.1736,  2.5156],\n",
              "         [-0.1736,  2.5156],\n",
              "         [-0.1736,  2.5156],\n",
              "         [ 0.7192, -0.2711],\n",
              "         [-1.4107,  0.9552],\n",
              "         [-1.7108, -0.1335],\n",
              "         [ 0.2373, -0.4529],\n",
              "         [-0.4620,  0.9481],\n",
              "         [ 1.4499,  0.1446],\n",
              "         [-0.1736,  2.5156],\n",
              "         [-0.1736,  2.5156],\n",
              "         [-0.1736,  2.5156],\n",
              "         [-1.4107,  0.9552],\n",
              "         [-0.1523, -0.8020],\n",
              "         [-0.0259, -1.0257],\n",
              "         [ 0.0268, -0.5085]]),\n",
              " tensor([[-0.1736,  2.5156],\n",
              "         [-0.1736,  2.5156],\n",
              "         [-0.4620,  0.9481],\n",
              "         [-1.1552, -0.2751],\n",
              "         [-1.1552, -0.2751],\n",
              "         [-0.1736,  2.5156],\n",
              "         [-0.1736,  2.5156],\n",
              "         [-0.1523, -0.8020],\n",
              "         [ 1.4499,  0.1446],\n",
              "         [ 0.7192, -0.2711],\n",
              "         [-3.0937,  0.0304],\n",
              "         [ 0.7192, -0.2711],\n",
              "         [-0.1736,  2.5156],\n",
              "         [-0.1736,  2.5156],\n",
              "         [-1.7108, -0.1335],\n",
              "         [-3.0937,  0.0304],\n",
              "         [-0.1736,  2.5156],\n",
              "         [-0.1736,  2.5156],\n",
              "         [ 0.7192, -0.2711],\n",
              "         [-1.4107,  0.9552],\n",
              "         [-1.7108, -0.1335],\n",
              "         [ 0.2373, -0.4529],\n",
              "         [-0.4620,  0.9481],\n",
              "         [ 1.4499,  0.1446],\n",
              "         [ 1.4499,  0.1446],\n",
              "         [-0.1736,  2.5156],\n",
              "         [-0.1736,  2.5156],\n",
              "         [-1.4107,  0.9552],\n",
              "         [-0.1523, -0.8020],\n",
              "         [-0.0259, -1.0257],\n",
              "         [ 0.0268, -0.5085],\n",
              "         [ 0.7192, -0.2711]]),\n",
              " tensor([[-0.1736,  2.5156],\n",
              "         [-0.4620,  0.9481],\n",
              "         [-1.1552, -0.2751],\n",
              "         [-1.1552, -0.2751],\n",
              "         [-1.7108, -0.1335],\n",
              "         [-0.1736,  2.5156],\n",
              "         [-0.1523, -0.8020],\n",
              "         [ 1.4499,  0.1446],\n",
              "         [ 0.7192, -0.2711],\n",
              "         [-3.0937,  0.0304],\n",
              "         [ 0.7192, -0.2711],\n",
              "         [-1.7108, -0.1335],\n",
              "         [-0.1736,  2.5156],\n",
              "         [-1.7108, -0.1335],\n",
              "         [-3.0937,  0.0304],\n",
              "         [-1.7108, -0.1335],\n",
              "         [-0.1736,  2.5156],\n",
              "         [ 0.7192, -0.2711],\n",
              "         [-1.4107,  0.9552],\n",
              "         [-1.7108, -0.1335],\n",
              "         [ 0.2373, -0.4529],\n",
              "         [-0.4620,  0.9481],\n",
              "         [ 1.4499,  0.1446],\n",
              "         [ 1.4499,  0.1446],\n",
              "         [-1.7108, -0.1335],\n",
              "         [-0.1736,  2.5156],\n",
              "         [-1.4107,  0.9552],\n",
              "         [-0.1523, -0.8020],\n",
              "         [-0.0259, -1.0257],\n",
              "         [ 0.0268, -0.5085],\n",
              "         [ 0.7192, -0.2711],\n",
              "         [-1.7108, -0.1335]]))"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cat(torch.unbind(emb,1), dim=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M55zHViMJsPd",
        "outputId": "168193e4-e6b6-4f80-a3b6-7a5f5d4a8c3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.1736,  2.5156, -0.1736,  2.5156, -0.1736,  2.5156],\n",
              "        [-0.1736,  2.5156, -0.1736,  2.5156, -0.4620,  0.9481],\n",
              "        [-0.1736,  2.5156, -0.4620,  0.9481, -1.1552, -0.2751],\n",
              "        [-0.4620,  0.9481, -1.1552, -0.2751, -1.1552, -0.2751],\n",
              "        [-1.1552, -0.2751, -1.1552, -0.2751, -1.7108, -0.1335],\n",
              "        [-0.1736,  2.5156, -0.1736,  2.5156, -0.1736,  2.5156],\n",
              "        [-0.1736,  2.5156, -0.1736,  2.5156, -0.1523, -0.8020],\n",
              "        [-0.1736,  2.5156, -0.1523, -0.8020,  1.4499,  0.1446],\n",
              "        [-0.1523, -0.8020,  1.4499,  0.1446,  0.7192, -0.2711],\n",
              "        [ 1.4499,  0.1446,  0.7192, -0.2711, -3.0937,  0.0304],\n",
              "        [ 0.7192, -0.2711, -3.0937,  0.0304,  0.7192, -0.2711],\n",
              "        [-3.0937,  0.0304,  0.7192, -0.2711, -1.7108, -0.1335],\n",
              "        [-0.1736,  2.5156, -0.1736,  2.5156, -0.1736,  2.5156],\n",
              "        [-0.1736,  2.5156, -0.1736,  2.5156, -1.7108, -0.1335],\n",
              "        [-0.1736,  2.5156, -1.7108, -0.1335, -3.0937,  0.0304],\n",
              "        [-1.7108, -0.1335, -3.0937,  0.0304, -1.7108, -0.1335],\n",
              "        [-0.1736,  2.5156, -0.1736,  2.5156, -0.1736,  2.5156],\n",
              "        [-0.1736,  2.5156, -0.1736,  2.5156,  0.7192, -0.2711],\n",
              "        [-0.1736,  2.5156,  0.7192, -0.2711, -1.4107,  0.9552],\n",
              "        [ 0.7192, -0.2711, -1.4107,  0.9552, -1.7108, -0.1335],\n",
              "        [-1.4107,  0.9552, -1.7108, -0.1335,  0.2373, -0.4529],\n",
              "        [-1.7108, -0.1335,  0.2373, -0.4529, -0.4620,  0.9481],\n",
              "        [ 0.2373, -0.4529, -0.4620,  0.9481,  1.4499,  0.1446],\n",
              "        [-0.4620,  0.9481,  1.4499,  0.1446,  1.4499,  0.1446],\n",
              "        [ 1.4499,  0.1446,  1.4499,  0.1446, -1.7108, -0.1335],\n",
              "        [-0.1736,  2.5156, -0.1736,  2.5156, -0.1736,  2.5156],\n",
              "        [-0.1736,  2.5156, -0.1736,  2.5156, -1.4107,  0.9552],\n",
              "        [-0.1736,  2.5156, -1.4107,  0.9552, -0.1523, -0.8020],\n",
              "        [-1.4107,  0.9552, -0.1523, -0.8020, -0.0259, -1.0257],\n",
              "        [-0.1523, -0.8020, -0.0259, -1.0257,  0.0268, -0.5085],\n",
              "        [-0.0259, -1.0257,  0.0268, -0.5085,  0.7192, -0.2711],\n",
              "        [ 0.0268, -0.5085,  0.7192, -0.2711, -1.7108, -0.1335]])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cat(torch.unbind(emb,1), dim=1).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YKWWH4TdJe60",
        "outputId": "0ba2f011-94d0-4cad-e43e-0c3b9a8d9909"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 6])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# best approach uses view\n",
        "\n",
        "a = torch.arange(18)\n",
        "a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YLieyS_ZKKTP",
        "outputId": "4f57e9a5-95ea-449d-ed1e-b1cd8580ca3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a.view(3,6)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uOAPlYKeKbS_",
        "outputId": "26d77a10-aae1-4803-acdf-eae70bc7d5b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0,  1,  2,  3,  4,  5],\n",
              "        [ 6,  7,  8,  9, 10, 11],\n",
              "        [12, 13, 14, 15, 16, 17]])"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a.view(9,2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-hP-TDiaKfwf",
        "outputId": "31cf2675-7ed0-4342-c726-7686ed96f44d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0,  1],\n",
              "        [ 2,  3],\n",
              "        [ 4,  5],\n",
              "        [ 6,  7],\n",
              "        [ 8,  9],\n",
              "        [10, 11],\n",
              "        [12, 13],\n",
              "        [14, 15],\n",
              "        [16, 17]])"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "emb.view(32,6)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xue6Smj3LBDT",
        "outputId": "dd5ea196-f6c3-46fb-d5f6-224f1aa547b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.1736,  2.5156, -0.1736,  2.5156, -0.1736,  2.5156],\n",
              "        [-0.1736,  2.5156, -0.1736,  2.5156, -0.4620,  0.9481],\n",
              "        [-0.1736,  2.5156, -0.4620,  0.9481, -1.1552, -0.2751],\n",
              "        [-0.4620,  0.9481, -1.1552, -0.2751, -1.1552, -0.2751],\n",
              "        [-1.1552, -0.2751, -1.1552, -0.2751, -1.7108, -0.1335],\n",
              "        [-0.1736,  2.5156, -0.1736,  2.5156, -0.1736,  2.5156],\n",
              "        [-0.1736,  2.5156, -0.1736,  2.5156, -0.1523, -0.8020],\n",
              "        [-0.1736,  2.5156, -0.1523, -0.8020,  1.4499,  0.1446],\n",
              "        [-0.1523, -0.8020,  1.4499,  0.1446,  0.7192, -0.2711],\n",
              "        [ 1.4499,  0.1446,  0.7192, -0.2711, -3.0937,  0.0304],\n",
              "        [ 0.7192, -0.2711, -3.0937,  0.0304,  0.7192, -0.2711],\n",
              "        [-3.0937,  0.0304,  0.7192, -0.2711, -1.7108, -0.1335],\n",
              "        [-0.1736,  2.5156, -0.1736,  2.5156, -0.1736,  2.5156],\n",
              "        [-0.1736,  2.5156, -0.1736,  2.5156, -1.7108, -0.1335],\n",
              "        [-0.1736,  2.5156, -1.7108, -0.1335, -3.0937,  0.0304],\n",
              "        [-1.7108, -0.1335, -3.0937,  0.0304, -1.7108, -0.1335],\n",
              "        [-0.1736,  2.5156, -0.1736,  2.5156, -0.1736,  2.5156],\n",
              "        [-0.1736,  2.5156, -0.1736,  2.5156,  0.7192, -0.2711],\n",
              "        [-0.1736,  2.5156,  0.7192, -0.2711, -1.4107,  0.9552],\n",
              "        [ 0.7192, -0.2711, -1.4107,  0.9552, -1.7108, -0.1335],\n",
              "        [-1.4107,  0.9552, -1.7108, -0.1335,  0.2373, -0.4529],\n",
              "        [-1.7108, -0.1335,  0.2373, -0.4529, -0.4620,  0.9481],\n",
              "        [ 0.2373, -0.4529, -0.4620,  0.9481,  1.4499,  0.1446],\n",
              "        [-0.4620,  0.9481,  1.4499,  0.1446,  1.4499,  0.1446],\n",
              "        [ 1.4499,  0.1446,  1.4499,  0.1446, -1.7108, -0.1335],\n",
              "        [-0.1736,  2.5156, -0.1736,  2.5156, -0.1736,  2.5156],\n",
              "        [-0.1736,  2.5156, -0.1736,  2.5156, -1.4107,  0.9552],\n",
              "        [-0.1736,  2.5156, -1.4107,  0.9552, -0.1523, -0.8020],\n",
              "        [-1.4107,  0.9552, -0.1523, -0.8020, -0.0259, -1.0257],\n",
              "        [-0.1523, -0.8020, -0.0259, -1.0257,  0.0268, -0.5085],\n",
              "        [-0.0259, -1.0257,  0.0268, -0.5085,  0.7192, -0.2711],\n",
              "        [ 0.0268, -0.5085,  0.7192, -0.2711, -1.7108, -0.1335]])"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "h = emb.view(32, 6) @ W1 + b1\n",
        "h.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tgPLm9yLLmoW",
        "outputId": "f3ad6524-c17b-48c6-a194-a03db4186d1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 100])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "h = torch.tanh(emb.view(-1, 6) @ W1 + b1)"
      ],
      "metadata": {
        "id": "Y69ipxcEN2yC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The Hidden Layer"
      ],
      "metadata": {
        "id": "Vgh3wBkrwh95"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The hyperbolic tangent function:  $\\tanh(x)$\n",
        "\n",
        "The hyperbolic tangent function, or \\($\\tanh(x)$\\), is a mathematical function that describes a smooth curve that goes through the origin (0,0) and asymptotically approaches -1 for large negative values of \\(x\\) and +1 for large positive values of \\(x\\). The function is similar to the sigmoid function, but its output range is between -1 and 1, instead of 0 and 1 for the sigmoid function.\n",
        "\n",
        "Here is an easy-to-understand explanation of \\(\\tanh(x)\\):\n",
        "\n",
        "- It's like a \"smooth\" version of the step function. Instead of jumping abruptly from 0 to 1, it gradually transitions from -1 to 1.\n",
        "- The output of the \\(\\tanh(x)\\) function is always between -1 and 1, making it useful for normalizing values.\n",
        "- It has a derivative (slope) that is easy to calculate, making it useful for gradient-based optimization algorithms like gradient descent.\n",
        "\n",
        "Now, what does it offer?\n",
        "\n",
        "1. **Zero-centered output**: Unlike the sigmoid function, the output of the \\(\\tanh(x)\\) function is zero-centered, meaning its output is distributed around zero. This property can help accelerate the convergence of optimization algorithms.\n",
        "2. **Smooth transition**: The \\(\\tanh(x)\\) function provides a smooth transition between values, making it easier for models to learn complex patterns and relationships in the data.\n",
        "\n",
        "Why is it usually used?\n",
        "\n",
        "1. **Activation function in neural networks**: \\(\\tanh(x)\\) is commonly used as an activation function in neural networks, especially in the hidden layers, due to its zero-centered output and smooth transition between values.\n",
        "2. **Normalizing values**: The function can be used to normalize values to the range [-1, 1], which can be helpful for certain applications or preprocessing steps.\n",
        "3. **Simplifying optimization**: Because the function has a simple derivative, it simplifies the optimization process in machine learning models, making it easier for models to learn and adjust their parameters.\n",
        "\n",
        "In summary, the \\(\\tanh(x)\\) function is a useful mathematical tool that provides a smooth, zero-centered transition between values. It is commonly used as an activation function in neural networks and for normalizing values due to its simple derivative and ability to accelerate the convergence of optimization algorithms."
      ],
      "metadata": {
        "id": "8BoRXZe1NK0o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The Output Layer\n",
        "\n"
      ],
      "metadata": {
        "id": "EDvmdRAnOd3M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "W2 = torch.randn(100,27)\n",
        "b2 = torch.rand(27)"
      ],
      "metadata": {
        "id": "zOVpyFDCOtEX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "h.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PnwJvSELQGGw",
        "outputId": "b4c6413d-96e7-4075-f9aa-4f967ecf199e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 100])"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logits = h @ W2 + b2"
      ],
      "metadata": {
        "id": "fvIXG0JHP87V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logits.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-z9Wy2JjQAbG",
        "outputId": "e92757c4-5d3e-4040-a2ba-f24390c17e60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 27])"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "counts = logits.exp()\n",
        "probs = counts / counts.sum(1, keepdim=True)\n",
        "probs.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p1soKSVeQlvx",
        "outputId": "f48197a6-9871-4362-d6d4-8b7e373b90be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 27])"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# the current probabilities as asigned by this neural network\n",
        "# with this setting of its weights to the correct character in the sequence\n",
        "probs[torch.arange(32), Y]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5h__p4NQ4dY",
        "outputId": "b7d775dc-a515-4c1a-cc5c-e7e46c1eaa52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2.0326e-08, 2.2803e-10, 1.7229e-10, 7.8132e-05, 5.8525e-11, 1.3301e-09,\n",
              "        2.5308e-10, 4.5025e-04, 4.3895e-10, 9.1286e-12, 1.5302e-08, 1.9158e-11,\n",
              "        2.2634e-12, 1.5103e-14, 4.5998e-01, 1.2083e-08, 8.0534e-14, 9.5962e-08,\n",
              "        1.4174e-05, 7.5644e-03, 4.3709e-16, 2.1836e-13, 1.2989e-11, 2.7826e-11,\n",
              "        3.9933e-09, 2.5188e-13, 1.3896e-08, 8.5843e-09, 1.1749e-07, 3.1433e-03,\n",
              "        1.5348e-11, 4.4217e-11])"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "probs[torch.arange(32), Y].log()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vrArR-1FSdzA",
        "outputId": "ea610235-1f4e-47f7-da43-8ab50a142415"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-17.7114, -22.2015, -22.4818,  -9.4571, -23.5616, -20.4380, -22.0973,\n",
              "         -7.7057, -21.5466, -25.4196, -17.9953, -24.6783, -26.8141, -31.8239,\n",
              "         -0.7766, -18.2315, -30.1501, -16.1593, -11.1641,  -4.8843, -35.3664,\n",
              "        -29.1526, -25.0669, -24.3051, -19.3387, -29.0098, -18.0917, -18.5733,\n",
              "        -15.9569,  -5.7625, -24.9000, -23.8419])"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "-probs[torch.arange(32), Y].log().mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tljUA-dkSi4U",
        "outputId": "50e6e383-097d-4946-b4c8-cc6b39bbeb58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(20.1457)"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cross-entropy loss\n",
        "\n",
        "Cross-entropy loss is a measure used in machine learning to quantify how well the predicted probabilities of an algorithm match the true labels of the data. It is commonly used in classification problems, where the goal is to assign a label to an input based on certain features.\n",
        "\n",
        "Let's break it down step-by-step:\n",
        "\n",
        "1. **Probability Distributions**: In a classification problem, a model outputs a probability distribution across all possible classes for a given input. For example, in a binary classification problem (like spam or not spam), the model might output a probability of 0.8 for \"spam\" and 0.2 for \"not spam\".\n",
        "\n",
        "2. **True Labels**: The true labels of the data are represented as a one-hot encoded vector. In the binary classification example, if the true label is \"spam\", it would be represented as `[1, 0]`, and if the true label is \"not spam\", it would be represented as `[0, 1]`.\n",
        "\n",
        "3. **Calculating the Loss**: The cross-entropy loss measures the \"distance\" between the predicted probability distribution and the true label distribution. It does this by taking the negative logarithm of the predicted probability for the true class. In the binary example, if the true label is \"spam\", the loss would be `-log(0.8)`. If the true label is \"not spam\", the loss would be `-log(0.2)`.\n",
        "\n",
        "4. **Minimizing the Loss**: During training, the goal is to minimize the cross-entropy loss. This means that the model is encouraged to assign higher probabilities to the correct classes and lower probabilities to the incorrect classes.\n",
        "\n",
        "With Cross-entropy loss:\n",
        "\n",
        "1. **Forward Pass much more efficient**:\n",
        "\n",
        "1. **Backward Pass much more efficient**:\n",
        "\n",
        "Cross-entropy loss is often used in neural networks for several reasons:\n",
        "\n",
        "1. **Fused Kernel**: It runs in a fused kernel, which means that the computation of the loss and its gradient is combined into a single operation. This reduces computational overhead and makes training faster.\n",
        "\n",
        "2. **Simple Mathematical Form**: The mathematical form of the cross-entropy loss is simple and intuitive. It directly penalizes the model for assigning low probabilities to the correct classes.\n",
        "\n",
        "3. **Numerically Well-behaved**: The cross-entropy loss has good numerical properties. It is always non-negative, and it approaches zero as the predicted probabilities get closer to the true labels.\n",
        "\n",
        "In summary, cross-entropy loss is a measure that quantifies how well the predicted probabilities of a model match the true labels of the data. It is commonly used in classification problems and has several benefits, including efficient computation, simple mathematical form, and good numerical properties."
      ],
      "metadata": {
        "id": "f3O5ExheTL_C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training the model"
      ],
      "metadata": {
        "id": "Czm6HDtMW0lV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hyperparameters\n",
        "\n",
        "The key hyperparameters in a neural network:\n",
        "\n",
        "1. **Learning Rate**: The learning rate determines the step size at each iteration while moving toward a minimum of the loss function. If the learning rate is too small, it will take many iterations to converge. If it's too large, it may overshoot the minimum and never converge.\n",
        "\n",
        "2. **Batch Size**: This is the number of training examples utilized in one iteration. A smaller batch size often provides a regularizing effect and lower generalization error. A larger batch size often results in faster training but may have a higher generalization error.\n",
        "\n",
        "3. **Number of Epochs**: An epoch is one complete forward and backward pass of all the training examples. The total number of epochs is the number of times the learning algorithm will work through the entire training dataset.\n",
        "\n",
        "4. **Weight Initialization**: Proper weight initialization can help prevent the loss function from getting stuck during training. Strategies include random initialization, Xavier/Glorot initialization, and He initialization.\n",
        "\n",
        "5. **Activation Functions**: These functions introduce non-linearity into the network. Popular choices include the sigmoid function, hyperbolic tangent (tanh), and rectified linear unit (ReLU).\n",
        "\n",
        "6. **Number of Hidden Layers and Units**: The number of hidden layers represents the depth of the network, while the number of units in each hidden layer represents its width. Too few layers and units can result in underfitting, while too many can lead to overfitting.\n",
        "\n",
        "7. **Dropout Rate**: Dropout is a regularization technique where randomly selected neurons are ignored during training. The dropout rate is the fraction of the neurons to drop.\n",
        "\n",
        "8. **Optimization Algorithms**: The optimization algorithm updates the network's weights. Examples include Stochastic Gradient Descent (SGD), Momentum, Adam, and RMSprop.\n",
        "\n",
        "9. **Loss Function**: This function measures how far off our predictions are from the actual values. Common choices include mean squared error for regression tasks and cross-entropy for classification tasks.\n",
        "\n",
        "10. **Momentum**: This hyperparameter helps accelerate SGD in the relevant direction and dampens oscillations. It can be thought of as a moving average of our gradients.\n",
        "\n",
        "11. **Regularization**: Techniques like L1 and L2 regularization can prevent overfitting by adding a penalty for large weights.\n",
        "\n",
        "12. **Learning Rate Decay**: Over time, it can be helpful to reduce the learning rate as the algorithm converges to the minimum.\n",
        "\n",
        "It's worth noting that finding the right combination of hyperparameters can be a time-consuming process and often involves a lot of trial and error. However, there are more systematic approaches like grid search, random search, and Bayesian optimization that can help in finding a good set of hyperparameters."
      ],
      "metadata": {
        "id": "4GqpbO3t2Olg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training example on 5 words"
      ],
      "metadata": {
        "id": "b06HqrkkTXbt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape, Y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9LyhWyaiYAKU",
        "outputId": "8469ae9a-af0a-4bf5-ab55-4d75460cf3fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([32, 3]), torch.Size([32]))"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# initially get it training for first 5 words\n",
        "g = torch.Generator().manual_seed(2147483647) # for reproducibility\n",
        "C = torch.randn((27, 10), generator=g)\n",
        "W1 = torch.randn((30, 200), generator=g)\n",
        "b1 = torch.randn(200, generator=g)\n",
        "W2 = torch.randn((200, 27), generator=g)\n",
        "b2 = torch.randn(27, generator=g)\n",
        "parameters = [C, W1, b1, W2, b2]"
      ],
      "metadata": {
        "id": "hcFguMy3TLGG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sum(p.nelement() for p in parameters) # number of parameters in total"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jqkwbUqzW9tL",
        "outputId": "d63c69d6-f03f-49a1-c455-e86c91fdb068"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11897"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for p in parameters:\n",
        "  p.requires_grad = True"
      ],
      "metadata": {
        "id": "aRgC0QSmXA6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for _ in range(1000):\n",
        "\n",
        "  # forward pass\n",
        "  emb = C[X] # (32, 3, 2)\n",
        "  h = torch.tanh(emb.view(-1, 30) @ W1 + b1) # (32, 100)\n",
        "  logits = h @ W2 + b2 # (32, 27)\n",
        "  loss = F.cross_entropy(logits, Y)\n",
        "  #print(loss.item())\n",
        "\n",
        "  # backward pass\n",
        "  for p in parameters:\n",
        "    p.grad = None\n",
        "  loss.backward()\n",
        "\n",
        "  # update\n",
        "  for p in parameters:\n",
        "    p.data += -0.1* p.grad\n",
        "\n",
        "print(loss.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yY8SKPCUXS33",
        "outputId": "8d441ab9-bf94-4848-c52e-99d8379ff5d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.2519921660423279\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# low loss - overfitting 32 examples and 11987 parameters"
      ],
      "metadata": {
        "id": "tVQo1anvYO44"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logits.max(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-vqMQgXYymG",
        "outputId": "8f6575a6-ae18-440b-e2d5-9f5a48b1b769"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.return_types.max(\n",
              "values=tensor([ 7.2575, 17.4018, 17.4931, 16.5615, 24.3243,  7.2575, 16.7670, 16.5181,\n",
              "        38.4164, 21.8628, 23.6642, 32.6847,  7.2575, 20.6324, 16.3724, 28.8270,\n",
              "         7.2575, 20.0542, 28.1885, 22.1231, 21.9437, 31.3218, 23.0178, 22.4147,\n",
              "        24.1816,  7.2575, 19.5633, 20.7496, 27.9423, 25.0990, 25.5303, 30.2009],\n",
              "       grad_fn=<MaxBackward0>),\n",
              "indices=tensor([ 1, 13, 13,  1,  0,  1, 12,  9, 22,  9,  1,  0,  1, 22,  1,  0,  1, 19,\n",
              "         1,  2,  5, 12, 12,  1,  0,  1, 15, 16,  8,  9,  1,  0]))"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mini-batches\n",
        "\n",
        "When training a neural network, we need to show it examples from our dataset so it can learn. We call these examples \"training data\". However, instead of showing the network one example at a time, or showing it the entire dataset at once, we often use a middle ground approach called \"mini-batches\".\n",
        "\n",
        "**1. What is a Mini-batch?**\n",
        "\n",
        "A mini-batch is simply a small subset of the training data. Instead of processing the entire dataset or a single example at a time, we process a few examples together as a group. This group of examples is the mini-batch.\n",
        "\n",
        "**2. Why Use Mini-batches?**\n",
        "\n",
        "Mini-batches offer several advantages:\n",
        "\n",
        "- **Speed**: It's often faster to process a small group of examples together due to the way computer hardware, especially GPUs, work. They can handle multiple examples at once more efficiently than one by one.\n",
        "\n",
        "- **Memory**: Processing the entire dataset might not fit in memory, especially for large datasets. Mini-batches allow us to fit a manageable chunk of data in memory.\n",
        "\n",
        "- **Stability**: Mini-batches help make the training process more stable. If we use the entire dataset, the network might have a hard time dealing with the sheer amount of data. If we use a single example, the network might be swayed too much by that one example. Mini-batches strike a balance.\n",
        "\n",
        "- **Convergence**: Mini-batches can help the network to converge (find the best solution) faster. It gets to see more examples in a shorter amount of time compared to processing one example at a time.\n",
        "\n",
        "**3. How to Choose Mini-batch Size?**\n",
        "\n",
        "Choosing the right mini-batch size can be tricky. If it's too small, we might not get the full benefits of hardware acceleration. If it's too large, we might run out of memory. A common strategy is to start with a small size, like 32, and then try larger sizes, like 64, 128, or 256, as long as the hardware can handle it.\n",
        "\n",
        "**4. Stochastic Gradient Descent (SGD) and Mini-batches**\n",
        "\n",
        "In machine learning, we often use an optimization algorithm called Stochastic Gradient Descent (SGD) to train neural networks. The \"stochastic\" part means that it uses randomness. By using mini-batches, we're introducing some randomness into the training process. This randomness can actually help the network escape from bad solutions and find better ones.\n",
        "\n",
        "**In summary**, mini-batches are small groups of examples from the training data that we process together when training a neural network. They offer advantages in terms of speed, memory usage, stability, and convergence. Choosing the right mini-batch size is important and depends on the specific problem and hardware."
      ],
      "metadata": {
        "id": "AP8O2iAQbKzA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training with Mini-batches\n",
        "\n",
        "1. **Forward Pass**: For each mini-batch, we do a forward pass. This means that we input the examples in the mini-batch into the network and compute the output for each example. We also compute the loss for each example, which tells us how far off our network's predictions are from the true values.\n",
        "\n",
        "2. **Backward Pass**: We then do a backward pass for each mini-batch. This is where we compute the gradients of the loss with respect to the network's parameters. The gradients tell us the direction and magnitude to adjust the parameters to reduce the loss.\n",
        "\n",
        "3. **Update Weights**: After computing the gradients, we update the network's parameters (weights and biases) using an optimization algorithm like Stochastic Gradient Descent (SGD). This step is done once per mini-batch.\n",
        "\n",
        "4. **Epochs**: An epoch is one complete pass through the entire training dataset. Even when using mini-batches, epochs are still relevant. In each epoch, we divide the training dataset into mini-batches and process each mini-batch one by one. After processing all the mini-batches (completing one epoch), we usually shuffle the training data and start the next epoch.\n",
        "\n",
        "5. **Iterations**: In the context of mini-batches, an iteration refers to processing one mini-batch (forward pass, backward pass, update weights). The number of iterations in one epoch is equal to the total number of training examples divided by the mini-batch size.\n",
        "\n",
        "To summarize, when using mini-batches, we do a full forward pass, backward pass, and update the weights for each mini-batch. Epochs are still relevant and refer to one complete pass through the entire training dataset. Mini-batches can affect training in terms of speed, memory usage, stability, convergence, and randomness."
      ],
      "metadata": {
        "id": "oqmxNowlcbt8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mini-batches: Why it Works Well\n",
        "\n",
        "1. **Quality of the Gradient**: When we use mini-batches, we're only using a subset of the training data to compute the gradient in each step. Because of this, the gradient we compute is an approximation of the \"true\" gradient (the gradient computed using the entire training dataset). This means the direction of the gradient may not be as reliable, and it might not point exactly in the direction of the steepest descent. This is what the lecturer means by \"the quality of the gradient is lower.\"\n",
        "\n",
        "2. **Trade-off between Gradient Quality and Number of Steps**: Even though the gradient quality is lower with mini-batches, the advantage is that we can take more steps (update the weights more times) in the same amount of time. Since we're only using a subset of the training data in each step, each step is faster. So, we're trading off gradient quality for more frequent updates.\n",
        "\n",
        "3. **Approximate Gradient vs. Exact Gradient**: The lecturer is saying that, in practice, it's often better to have an approximate gradient and take more steps than to have an exact gradient and take fewer steps. Even though the gradient from a mini-batch might not be as reliable, taking more steps allows the model to learn more quickly. The randomness introduced by using different mini-batches can also help prevent the model from getting stuck in bad solutions.\n",
        "\n",
        "4. **Why it Works Well**: Despite the lower quality of the gradient, mini-batch training often works well in practice for several reasons:\n",
        "\n",
        "   - **Frequency of Updates**: More frequent updates can help the model learn faster, even if each update is based on an approximate gradient.\n",
        "   - **Randomness**: The randomness introduced by using different mini-batches can help the model escape from bad solutions and find better ones.\n",
        "   - **Computational Efficiency**: Processing mini-batches can be more computationally efficient than processing the entire dataset at once or one example at a time, especially on hardware like GPUs.\n",
        "\n",
        "To summarize, when using mini-batches, the gradient quality is lower because we're only using a subset of the training data to compute the gradient. However, this allows us to take more steps in the same amount of time, which can help the model learn more quickly. In practice, the trade-off between gradient quality and the number of steps often works well, and mini-batch training is widely used in deep learning."
      ],
      "metadata": {
        "id": "TlGLu9Mdg5ZJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introducing mini-batches\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "YZz2sHeyZ11O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# full data set\n",
        "\n",
        "X, Y = [], []\n",
        "for w in words:\n",
        "\n",
        "  #print(w)\n",
        "  context = [0] * block_size\n",
        "  for ch in w + '.':\n",
        "    ix = stoi[ch]\n",
        "    X.append(context)\n",
        "    Y.append(ix)\n",
        "    #print(''.join(itos[i] for i in context), '--->', itos[ix])\n",
        "    context = context[1:] + [ix] # crop and append\n",
        "\n",
        "X = torch.tensor(X)\n",
        "Y = torch.tensor(Y)\n",
        "print(X.shape, Y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RrFNoxe4dt_L",
        "outputId": "34f0ad95-4599-4a78-822c-d4df0dd80b0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([228146, 3]) torch.Size([228146])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# towards mini-batches\n",
        "torch.randint(0,5,(32,))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BqsPkLhkdGNj",
        "outputId": "2c12ad8e-5353-418f-ba8c-c99f4c966b75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 0, 3, 0, 2, 4, 2, 4, 4, 0, 1, 3, 2, 0, 4, 4, 3, 4, 2, 4, 4, 2, 3, 3,\n",
              "        3, 0, 2, 3, 4, 2, 0, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qXwrT-zidiE9",
        "outputId": "14b69316-4467-4ec4-f143-28d4c326917c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "228146"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.randint(0,X.shape[0],(32,))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j4OPGSkEdYcn",
        "outputId": "bd41ff35-1d9c-4580-f67d-5d8891e917de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 82154,  64551, 124620, 155895,  67209, 219569, 146012, 127471, 156809,\n",
              "         31621, 211190,   6059,  71510,  71513, 217094,  14728, 206095,  42852,\n",
              "         52569, 118386,  17360,  21079, 141509,  52599,  14567,  19536,  37430,\n",
              "        198843, 131228, 167800, 117949, 129706])"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "g = torch.Generator().manual_seed(2147483647) # for reproducibility\n",
        "C = torch.randn((27, 10), generator=g)\n",
        "W1 = torch.randn((30, 200), generator=g)\n",
        "b1 = torch.randn(200, generator=g)\n",
        "W2 = torch.randn((200, 27), generator=g)\n",
        "b2 = torch.randn(27, generator=g)\n",
        "parameters = [C, W1, b1, W2, b2]\n",
        "\n",
        "for p in parameters:\n",
        "  p.requires_grad = True"
      ],
      "metadata": {
        "id": "nkJb-fMUeMlk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for _ in range(1000):\n",
        "\n",
        "  # mini-batch\n",
        "  ix = torch.randint(0,X.shape[0],(32,))\n",
        "\n",
        "  # forward pass\n",
        "  emb = C[X[ix]] # (32, 3, 2) - this would be (20000, 3, 2) without mini-batch\n",
        "  h = torch.tanh(emb.view(-1, 30) @ W1 + b1) # (32, 100)\n",
        "  logits = h @ W2 + b2 # (32, 27)\n",
        "  loss = F.cross_entropy(logits, Y[ix])\n",
        "  # print(loss.item())\n",
        "\n",
        "  # backward pass\n",
        "  for p in parameters:\n",
        "    p.grad = None\n",
        "  loss.backward()\n",
        "\n",
        "  # update\n",
        "  for p in parameters:\n",
        "    p.data += -0.1* p.grad\n",
        "\n",
        "print(loss.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Jw46e0qeVnV",
        "outputId": "cf69f7a0-c99c-403f-c0e1-e850fa8b8336"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.3868608474731445\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# quickly get the loss on full set\n",
        "emb = C[X] # (32, 3, 2)\n",
        "h = torch.tanh(emb.view(-1, 30) @ W1 + b1) # (32, 100)\n",
        "logits = h @ W2 + b2 # (32, 27)\n",
        "loss = F.cross_entropy(logits, Y)\n",
        "print(loss.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-DsObZ8vf-Rm",
        "outputId": "4f10e78c-cf52-4790-c9c6-d16c1e943386"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.555955410003662\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we carried out some training iterations."
      ],
      "metadata": {
        "id": "4arHxSrniDIh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The learning rate\n",
        "\n",
        "The learning rate is a crucial concept in training neural networks.\n",
        "\n",
        "1. **What is the learning rate?**\n",
        "   - The learning rate is a small number that determines the step size during optimization. When training a neural network, we iteratively update the model's weights to minimize a loss function. The learning rate controls how much we change the weights in each update. A small learning rate means slow, cautious updates, while a large learning rate means fast, aggressive updates.\n",
        "\n",
        "2. **Why is the learning rate important?**\n",
        "   - The learning rate directly affects how quickly the model converges to a good solution. Too small of a learning rate can lead to slow convergence, while too large of a learning rate can cause the model to overshoot the optimal solution or even diverge.\n",
        "\n",
        "3. **How to find a reasonable learning rate?**\n",
        "   - **Trial and error**: Start with a small learning rate (e.g., 0.001) and gradually increase it until the model starts to diverge. Then, use a value slightly smaller than the one that caused divergence.\n",
        "   - **Learning rate schedule**: Start with a large learning rate and decrease it over time, either gradually or in steps. This approach combines the benefits of both large and small learning rates.\n",
        "   - **Learning rate finder**: Train the model for a few epochs with an exponentially increasing learning rate, plot the loss against the learning rate, and choose the rate where the loss decreases the fastest.\n",
        "\n",
        "4. **Adaptive learning rate methods**: Some optimization algorithms, like Adam and AdaGrad, automatically adjust the learning rate based on the training progress. These methods can be helpful, especially when the optimal learning rate is unknown or changes over time.\n",
        "\n",
        "In summary, the learning rate is a hyperparameter that determines the step size during optimization. Choosing a suitable learning rate is crucial for training neural networks effectively. There are several strategies to find a reasonable learning rate, including trial and error, learning rate schedules, learning rate finders, and adaptive learning rate methods."
      ],
      "metadata": {
        "id": "_sqnfECuiPtT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using a logarithmic scale to search for a good learning rate\n",
        "\n",
        "The lecturer is using a logarithmic scale to search for a good learning rate. This approach is based on the observation that the performance of a neural network is often more sensitive to changes in the learning rate when the learning rate is small. By using a logarithmic scale, the lecturer is able to explore a wider range of learning rates more efficiently.\n",
        "\n",
        "Here's a breakdown of the code:\n",
        "\n",
        "- `torch.linspace(-3, 0, 1000)` generates a tensor with 1000 equally spaced values between -3 and 0.\n",
        "- `10**lre` raises 10 to the power of each element in the tensor `lre`. This operation transforms the linearly spaced values in `lre` into logarithmically spaced values in `lrs`.\n",
        "\n",
        "The result is a tensor `lrs` with 1000 logarithmically spaced values between \\(10^{-3}\\) (0.001) and \\(10^0\\) (1).\n",
        "\n",
        "Using a logarithmic scale allows the lecturer to search more densely for good learning rates in the range where changes in the learning rate have a larger impact on performance. In contrast, using a linear scale, as in `torch.linspace(0.001, 1, 1000)`, would search more densely for good learning rates in the range where changes in the learning rate have a smaller impact on performance."
      ],
      "metadata": {
        "id": "rHLAT206mPSk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exploring learning rate"
      ],
      "metadata": {
        "id": "IyjXamLtTw_q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lre = torch.linspace(-3, 0, 1000)\n",
        "lrs = 10**lre"
      ],
      "metadata": {
        "id": "Q09NXE0SmacX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "\n",
        "# Linearly spaced values\n",
        "linear_lrs = torch.linspace(0.001, 1, 1000)\n",
        "\n",
        "# Logarithmically spaced values\n",
        "lre = torch.linspace(-3, 0, 1000)\n",
        "log_lrs = 10**lre\n",
        "\n",
        "# Plot the values\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(linear_lrs, label=\"Linearly spaced\")\n",
        "plt.plot(log_lrs, label=\"Logarithmically spaced\")\n",
        "plt.xlabel(\"Index\")\n",
        "plt.ylabel(\"Learning rate\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "1DalmjCwmeD6",
        "outputId": "2e9e2a87-4b31-4792-cf30-97ca7a82fe6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "g = torch.Generator().manual_seed(2147483647) # for reproducibility\n",
        "C = torch.randn((27, 10), generator=g)\n",
        "W1 = torch.randn((30, 200), generator=g)\n",
        "b1 = torch.randn(200, generator=g)\n",
        "W2 = torch.randn((200, 27), generator=g)\n",
        "b2 = torch.randn(27, generator=g)\n",
        "parameters = [C, W1, b1, W2, b2]\n",
        "\n",
        "for p in parameters:\n",
        "  p.requires_grad = True"
      ],
      "metadata": {
        "id": "gIZbdmlbpcGF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lre = torch.linspace(-3, 0, 1000)\n",
        "lrs = 10**lre"
      ],
      "metadata": {
        "id": "Jzqsb5RFpngE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lri = []\n",
        "lossi = []"
      ],
      "metadata": {
        "id": "0YdttkXJpvUP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(1000):\n",
        "\n",
        "  # mini-batch\n",
        "  ix = torch.randint(0,X.shape[0],(32,))\n",
        "\n",
        "  # forward pass\n",
        "  emb = C[X[ix]] # (32, 3, 2) - this would be (20000, 3, 2) without mini-batch\n",
        "  h = torch.tanh(emb.view(-1, 30) @ W1 + b1) # (32, 100)\n",
        "  logits = h @ W2 + b2 # (32, 27)\n",
        "  loss = F.cross_entropy(logits, Y[ix])\n",
        "  # print(loss.item())\n",
        "\n",
        "  # backward pass\n",
        "  for p in parameters:\n",
        "    p.grad = None\n",
        "  loss.backward()\n",
        "\n",
        "  lr = lrs[i]\n",
        "  # update\n",
        "  for p in parameters:\n",
        "    p.data += -lr* p.grad\n",
        "\n",
        "  # track stats for learning rate\n",
        "  lri.append(lre[i])\n",
        "  lossi.append(loss.item())\n",
        "\n",
        "print(loss.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q77QBR7ypjxI",
        "outputId": "5b8d0461-50c1-4f4d-8cc7-2022e4273f82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14.434767723083496\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# reset the model, run 1000 iterations\n",
        "# look at the exponent of the learning rate vs loss\n",
        "plt.plot(lri, lossi)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "3SYJBi7aqRvx",
        "outputId": "c4306add-849e-4c1a-dd29-0f8fbe373a16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7acd35042350>]"
            ]
          },
          "metadata": {},
          "execution_count": 102
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "g = torch.Generator().manual_seed(2147483647) # for reproducibility\n",
        "C = torch.randn((27, 10), generator=g)\n",
        "W1 = torch.randn((30, 200), generator=g)\n",
        "b1 = torch.randn(200, generator=g)\n",
        "W2 = torch.randn((200, 27), generator=g)\n",
        "b2 = torch.randn(27, generator=g)\n",
        "parameters = [C, W1, b1, W2, b2]\n",
        "\n",
        "for p in parameters:\n",
        "  p.requires_grad = True"
      ],
      "metadata": {
        "id": "pjyHewNcsPpC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# good learning rate is about 0.1\n",
        "# time to crank up the iterations 3 X 10,000, lower learning rate to 0.01 and another iteration\n",
        "\n",
        "for i in range(10000):\n",
        "\n",
        "  # mini-batch\n",
        "  ix = torch.randint(0,X.shape[0],(32,))\n",
        "\n",
        "  # forward pass\n",
        "  emb = C[X[ix]] # (32, 3, 2) - this would be (20000, 3, 2) without mini-batch\n",
        "  h = torch.tanh(emb.view(-1, 30) @ W1 + b1) # (32, 100)\n",
        "  logits = h @ W2 + b2 # (32, 27)\n",
        "  loss = F.cross_entropy(logits, Y[ix])\n",
        "  # print(loss.item())\n",
        "\n",
        "  # backward pass\n",
        "  for p in parameters:\n",
        "    p.grad = None\n",
        "  loss.backward()\n",
        "\n",
        "  lr = 0.01\n",
        "  # update\n",
        "  for p in parameters:\n",
        "    p.data += -lr* p.grad\n",
        "\n",
        "print(loss.item())"
      ],
      "metadata": {
        "id": "tyGdjc3Yrx2y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# quickly get the loss on full set\n",
        "emb = C[X] # (32, 3, 2)\n",
        "h = torch.tanh(emb.view(-1, 30) @ W1 + b1) # (32, 100)\n",
        "logits = h @ W2 + b2 # (32, 27)\n",
        "loss = F.cross_entropy(logits, Y)\n",
        "print(loss.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "syrHtbJMsczr",
        "outputId": "b4f5c76f-35e6-43ce-feda-1f9ac3a2976e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.194960594177246\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training, Validation and Test sets\n",
        "\n",
        "When training a machine learning model, it's common practice to split the dataset into three parts: training, validation, and test. Each of these sets has a different role in the process of developing and evaluating the model:\n",
        "\n",
        "1. **Training Set (80% of the dataset):** This set is used to train the model. It's the data that the algorithm \"sees\" and learns from. The model's parameters are optimized on this dataset. It's typically the largest portion of the dataset because learning from more data generally leads to better models.\n",
        "\n",
        "2. **Validation Set (10% of the dataset):** After training the model on the training set, the validation set is used to evaluate the model's performance. It helps in tuning the model's hyperparameters (like learning rate, batch size, etc.) and in selecting the best model. The validation set is used during the development phase to make decisions about the model, but it's not used to directly train the model.\n",
        "\n",
        "3. **Test Set (10% of the dataset):** This set is used to evaluate the model's performance after the model has been finalized. It provides an estimate of the model's performance on unseen data. The test set should only be used once, at the very end of the model development process. Every time you evaluate the model on the test set, you risk leaking information from the test set into the model, which can lead to overfitting.\n",
        "\n",
        "Here's a step-by-step breakdown of the process:\n",
        "\n",
        "1. **Training Phase:** Use the training set to train the model. Adjust the model's parameters based on the training data.\n",
        "\n",
        "2. **Validation Phase:** Use the validation set to tune the model's hyperparameters and select the best model. This phase is iterative – you might go back and forth between training and validation multiple times to fine-tune the model.\n",
        "\n",
        "3. **Testing Phase:** Once the model and hyperparameters are finalized, evaluate the model's performance on the test set to get an unbiased estimate of how well the model is likely to perform on unseen data.\n",
        "\n",
        "This process of splitting the dataset into training, validation, and test sets helps prevent overfitting, ensures that the model generalizes well to new data, and provides a way to objectively evaluate the model's performance."
      ],
      "metadata": {
        "id": "Yub1-ENZt452"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training with training and validation sets"
      ],
      "metadata": {
        "id": "Qd6WGBHbT8ap"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/karpathy/makemore/master/names.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2DVpn8ltD3HB",
        "outputId": "235c83c0-4fc2-4285-904e-ecebc231caa8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-08-21 07:47:30--  https://raw.githubusercontent.com/karpathy/makemore/master/names.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 228145 (223K) [text/plain]\n",
            "Saving to: ‘names.txt.1’\n",
            "\n",
            "\rnames.txt.1           0%[                    ]       0  --.-KB/s               \rnames.txt.1         100%[===================>] 222.80K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2023-08-21 07:47:30 (8.50 MB/s) - ‘names.txt.1’ saved [228145/228145]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt # for making figures\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "ulw5x2IkDov2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words = open(\"names.txt\", \"r\").read().splitlines()"
      ],
      "metadata": {
        "id": "0LaJcVvKDvJ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# build the vocabulary of characters and mappings to/from integers\n",
        "chars = sorted(list(set(''.join(words))))\n",
        "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
        "stoi['.'] = 0\n",
        "itos = {i:s for s,i in stoi.items()}\n",
        "print(itos)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TviDUbSCD9n1",
        "outputId": "567bd462-e8c5-4f1a-8b00-79135334051f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: '.'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# build the dataset\n",
        "block_size = 3 # context length: how many characters do we take to predict the next one?\n",
        "\n",
        "def build_dataset(words):\n",
        "  X, Y = [], []\n",
        "  for w in words:\n",
        "\n",
        "    #print(w)\n",
        "    context = [0] * block_size\n",
        "    for ch in w + '.':\n",
        "      ix = stoi[ch]\n",
        "      X.append(context)\n",
        "      Y.append(ix)\n",
        "      #print(''.join(itos[i] for i in context), '--->', itos[ix])\n",
        "      context = context[1:] + [ix] # crop and append\n",
        "\n",
        "  X = torch.tensor(X)\n",
        "  Y = torch.tensor(Y)\n",
        "  print(X.shape, Y.shape)\n",
        "  return X, Y\n",
        "\n",
        "import random\n",
        "random.seed(42)\n",
        "random.shuffle(words)\n",
        "n1 = int(0.8*len(words))\n",
        "n2 = int(0.9*len(words))\n",
        "\n",
        "Xtr, Ytr = build_dataset(words[:n1])\n",
        "Xdev, Ydev = build_dataset(words[n1:n2])\n",
        "Xte, Yte = build_dataset(words[n2:])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fs3tJwJhwXD8",
        "outputId": "3c5680e6-3e36-4e33-e3c5-d72c5a309f25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([182625, 3]) torch.Size([182625])\n",
            "torch.Size([22655, 3]) torch.Size([22655])\n",
            "torch.Size([22866, 3]) torch.Size([22866])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_training_words = n1\n",
        "num_validation_words = n2 - n1\n",
        "num_test_words = len(words)  - (num_training_words + num_validation_words)\n",
        "num_training_words, num_validation_words, num_test_words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fgUb99RjELtJ",
        "outputId": "2b713fcd-d4f4-419e-a513-84df1770ee3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25626, 3203, 3204)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Xtr.shape, Ytr.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZmJYPC9TFcwW",
        "outputId": "581ec32d-a7c4-4650-ec6b-f44380c7449f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([182625, 3]), torch.Size([182625]))"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "g = torch.Generator().manual_seed(2147483647) # for reproducibility\n",
        "C = torch.randn((27, 2), generator=g)\n",
        "W1 = torch.randn((6, 100), generator=g)\n",
        "b1 = torch.randn(100, generator=g)\n",
        "W2 = torch.randn((100, 27), generator=g)\n",
        "b2 = torch.randn(27, generator=g)\n",
        "parameters = [C, W1, b1, W2, b2]\n",
        "\n",
        "for p in parameters:\n",
        "  p.requires_grad = True"
      ],
      "metadata": {
        "id": "gy39kXNJFhh4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1 x 30,000 @ 0.1, 1 x 10,000 @ 0.001\n",
        "\n",
        "for i in range(10000):\n",
        "\n",
        "  # mini-batch\n",
        "  ix = torch.randint(0,Xtr.shape[0],(32,))\n",
        "\n",
        "  # forward pass\n",
        "  emb = C[Xtr[ix]] # (32, 3, 2) - this would be (20000, 3, 2) without mini-batch\n",
        "  h = torch.tanh(emb.view(-1, 6) @ W1 + b1) # (32, 100)\n",
        "  logits = h @ W2 + b2 # (32, 27)\n",
        "  loss = F.cross_entropy(logits, Ytr[ix])\n",
        "\n",
        "  # backward pass\n",
        "  for p in parameters:\n",
        "    p.grad = None\n",
        "  loss.backward()\n",
        "\n",
        "  lr = 0.01\n",
        "  # update\n",
        "  for p in parameters:\n",
        "    p.data += -lr* p.grad"
      ],
      "metadata": {
        "id": "_mUNaVGvFjWE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(loss.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XRjq1v4WF2W7",
        "outputId": "4baa816f-53db-442f-b050-b3ab7854f588"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.1322646141052246\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# quickly get the loss on training set\n",
        "emb = C[Xtr] # (32, 3, 2)\n",
        "h = torch.tanh(emb.view(-1, 6) @ W1 + b1) # (32, 100)\n",
        "logits = h @ W2 + b2 # (32, 27)\n",
        "loss = F.cross_entropy(logits, Ytr)\n",
        "print(loss.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CtMiFqdgGXrh",
        "outputId": "821d78e8-cbe0-498e-922e-ca202c224837"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.3432955741882324\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# quickly get the loss on validation set\n",
        "emb = C[Xdev] # (32, 3, 2)\n",
        "h = torch.tanh(emb.view(-1, 6) @ W1 + b1) # (32, 100)\n",
        "logits = h @ W2 + b2 # (32, 27)\n",
        "loss = F.cross_entropy(logits, Ydev)\n",
        "print(loss.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xk7RtQKTGYvN",
        "outputId": "031a94dd-f688-4d0b-8007-7bce2100acc5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.345912456512451\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What is underfitting?\n",
        "\n",
        "1. **What is underfitting?**\n",
        "   Underfitting is a scenario where a machine learning model, including neural networks, performs poorly not just on new, unseen data (validation or test set) but also on the training data. Essentially, the model fails to capture the underlying patterns in the data. It's like trying to fit a straight line to a set of data points that are clearly following a curved pattern.\n",
        "\n",
        "2. **Symptoms of underfitting:**\n",
        "   - Poor performance on the training data (high training error).\n",
        "   - The validation or test error is similar to the training error, but both are unacceptably high.\n",
        "   - The model's predictions may be too simplistic.\n",
        "\n",
        "3. **Causes of underfitting:**\n",
        "   - The model is too simple to capture the complexity of the data. For example, using a linear model for nonlinear data.\n",
        "   - The features used for training may not contain enough information to represent the target variable accurately.\n",
        "   - Over-regularization, where the model is too penalized to learn the patterns in the data.\n",
        "\n",
        "4. **How to prevent underfitting:**\n",
        "   - **Increase model complexity**: If your model is too simple, consider making it more complex. For neural networks, this could mean adding more layers or neurons per layer.\n",
        "   - **Feature engineering**: Create new features or transform existing ones to provide more relevant information to the model.\n",
        "   - **Reduce regularization**: If you're using regularization techniques like L1 or L2, try reducing the regularization strength.\n",
        "   - **Change the model architecture**: If your current model is inherently too simple for your data, consider switching to a more complex model.\n",
        "   - **Use non-linear activation functions**: If you're using a neural network, non-linear activation functions like ReLU, sigmoid, or tanh can help the model learn more complex patterns.\n",
        "\n",
        "5. **Detecting underfitting:**\n",
        "   - Monitor your model's performance on both training and validation data. If both errors are high, you may be underfitting.\n",
        "   - Visualize the data and the model's predictions. If the model's predictions are too simplistic and fail to capture obvious patterns in the data, it's likely underfitting.\n",
        "   - Analyze the learning curves. If both the training and validation losses are high and plateau early, your model might be underfitting.\n",
        "\n",
        "Remember, the goal is to find a balance between underfitting and overfitting, where your model performs well on the training data but also generalizes well to new, unseen data.\n",
        "\n",
        "---\n",
        "\n",
        "The dev losses and training losses are roughly equal. We might be underfitting. One way to deal with this is increasing the size of our hidden layer."
      ],
      "metadata": {
        "id": "p7tWHr6gHR_8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Increase model complexity - Larger Hidden Layer"
      ],
      "metadata": {
        "id": "GhpJvYXXJM7S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sum(p.nelement() for p in parameters)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tmjy_n-HIXwJ",
        "outputId": "191d5f5f-5b72-4ef3-92db-817ac4e5667c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3481"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "g = torch.Generator().manual_seed(2147483647) # for reproducibility\n",
        "C = torch.randn((27, 2), generator=g)\n",
        "W1 = torch.randn((6, 300), generator=g)\n",
        "b1 = torch.randn(300, generator=g)\n",
        "W2 = torch.randn((300, 27), generator=g)\n",
        "b2 = torch.randn(27, generator=g)\n",
        "parameters = [C, W1, b1, W2, b2]\n",
        "\n",
        "for p in parameters:\n",
        "  p.requires_grad = True"
      ],
      "metadata": {
        "id": "tLno_artL2fC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sum(p.nelement() for p in parameters)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XKq-QtaTL7jo",
        "outputId": "57f7f4f4-a672-4428-a0fa-7499ef7d413c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10281"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lossi = []\n",
        "stepi = []"
      ],
      "metadata": {
        "id": "FgyXG7nCOMvE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2 x 40,000 @ 0.1, 1 x 40,000 @ 0.05 , 2 x 40,000 @ 0.01\n",
        "\n",
        "for i in range(40000):\n",
        "\n",
        "  # mini-batch\n",
        "  ix = torch.randint(0,Xtr.shape[0],(32,))\n",
        "\n",
        "  # forward pass\n",
        "  emb = C[Xtr[ix]] # (32, 3, 2) - this would be (20000, 3, 2) without mini-batch\n",
        "  h = torch.tanh(emb.view(-1, 6) @ W1 + b1) # (32, 100)\n",
        "  logits = h @ W2 + b2 # (32, 27)\n",
        "  loss = F.cross_entropy(logits, Ytr[ix])\n",
        "\n",
        "  # backward pass\n",
        "  for p in parameters:\n",
        "    p.grad = None\n",
        "  loss.backward()\n",
        "\n",
        "  lr = 0.01\n",
        "  # update\n",
        "  for p in parameters:\n",
        "    p.data += -lr* p.grad\n",
        "\n",
        "  # track stats\n",
        "  stepi.append(i)\n",
        "  lossi.append(loss.item())\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "BRtoNR1PM6IF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(loss.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sqqRV3TtNbFV",
        "outputId": "f56ae105-1d4b-4419-c2d0-cafccbf32d87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.223733901977539\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# quickly get the loss on training set\n",
        "emb = C[Xtr] # (32, 3, 2)\n",
        "h = torch.tanh(emb.view(-1, 6) @ W1 + b1) # (32, 100)\n",
        "logits = h @ W2 + b2 # (32, 27)\n",
        "loss = F.cross_entropy(logits, Ytr)\n",
        "print(loss.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yqqeLUB8NJum",
        "outputId": "f87a0991-b85c-420f-9709-ce8071b589c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.2251408100128174\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# quickly get the loss on validation set\n",
        "emb = C[Xdev] # (32, 3, 2)\n",
        "h = torch.tanh(emb.view(-1, 6) @ W1 + b1) # (32, 100)\n",
        "logits = h @ W2 + b2 # (32, 27)\n",
        "loss = F.cross_entropy(logits, Ydev)\n",
        "print(loss.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xRuRIoO9NpC3",
        "outputId": "f53b1067-aeb5-4702-80a8-f972403322ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.234853506088257\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "plt.plot(stepi, lossi)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "kk_v99VyOjZ1",
        "outputId": "197dd9a0-c00f-4496-904e-e6258071a99b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7e58290bf3d0>]"
            ]
          },
          "metadata": {},
          "execution_count": 83
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualize Embeddings (trained by the neural netweok)"
      ],
      "metadata": {
        "id": "U48Ah8RPUOOt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize dimensions 0 and 1 of the embedding matrix C for all characters\n",
        "# we can visualize this with a 2-D embeddings\n",
        "# we won't be able to visualize when we increase the dimensions\n",
        "plt.figure(figsize=(8,8))\n",
        "plt.scatter(C[:,0].data, C[:,1].data, s=200)\n",
        "for i in range(C.shape[0]):\n",
        "    plt.text(C[i,0].item(), C[i,1].item(), itos[i], ha=\"center\", va=\"center\", color='white')\n",
        "plt.grid('minor')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676
        },
        "id": "ZAkKex-2Q0UN",
        "outputId": "0786476a-e763-4361-97b4-4f2f63398b60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x800 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualizing higher-dimensional data\n",
        "\n",
        "Visualizing higher-dimensional data can be challenging, but there are several techniques available that can help reduce the dimensionality of the data so that it can be visualized in two or three dimensions. Here are some popular techniques:\n",
        "\n",
        "1. **Principal Component Analysis (PCA)**: PCA is a dimensionality reduction technique that projects the data onto the directions (principal components) that maximize the variance in the data. The first two or three principal components can then be used to visualize the data in two or three dimensions.\n",
        "\n",
        "2. **t-distributed Stochastic Neighbor Embedding (t-SNE)**: t-SNE is a nonlinear dimensionality reduction technique that is particularly effective for visualizing high-dimensional data in two or three dimensions. t-SNE works by preserving the local structure of the data, making it well-suited for visualizing clusters of similar data points.\n",
        "\n",
        "3. **Uniform Manifold Approximation and Projection (UMAP)**: UMAP is another nonlinear dimensionality reduction technique that is similar to t-SNE but can be faster and more scalable. UMAP preserves both the local and global structure of the data, making it suitable for visualizing large, high-dimensional datasets.\n",
        "\n",
        "4. **Multidimensional Scaling (MDS)**: MDS is a dimensionality reduction technique that preserves the pairwise distances between data points. MDS is suitable for visualizing data that has a meaningful distance metric.\n",
        "\n",
        "5. **Autoencoders**: Autoencoders are neural networks that can be trained to compress high-dimensional data into a lower-dimensional representation (encoding) and then reconstruct the original data from the encoding. The encoding can be visualized in two or three dimensions.\n",
        "\n",
        "6. **Parallel Coordinates Plot**: Parallel coordinates plot is a technique for visualizing high-dimensional data by plotting each data point as a line that passes through a set of parallel axes, one for each dimension. This technique allows for the visualization of multiple dimensions at once, but it can become cluttered and difficult to interpret with large datasets.\n",
        "\n",
        "7. **Glyph-based Visualization**: Glyph-based visualization represents each data point as a glyph (e.g., a shape or symbol) with multiple visual attributes (e.g., size, color, orientation) that correspond to the dimensions of the data. This technique can be effective for visualizing a small number of dimensions, but it can become difficult to interpret with many dimensions.\n",
        "\n",
        "8. **Heatmaps**: Heatmaps can be used to visualize high-dimensional data by representing each data point as a cell in a matrix, with the color of the cell corresponding to the value of the data point. Heatmaps are suitable for visualizing data with a regular grid structure, such as images or time-series data.\n",
        "\n",
        "Each of these techniques has its own strengths and weaknesses, and the choice of technique will depend on the characteristics of your data and the goals of your visualization. When visualizing high-dimensional data, it's important to keep in mind that any reduction in dimensionality may result in a loss of information, so it's important to interpret the visualization in the context of the original data."
      ],
      "metadata": {
        "id": "-7eyLMLBV_a5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Increase model complexity - Larger Embedding Layer"
      ],
      "metadata": {
        "id": "PNaSlw8rUMfn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "g = torch.Generator().manual_seed(2147483647) # for reproducibility\n",
        "C = torch.randn((27, 10), generator=g)\n",
        "W1 = torch.randn((30, 200), generator=g)\n",
        "b1 = torch.randn(200, generator=g)\n",
        "W2 = torch.randn((200, 27), generator=g)\n",
        "b2 = torch.randn(27, generator=g)\n",
        "parameters = [C, W1, b1, W2, b2]\n",
        "\n",
        "for p in parameters:\n",
        "  p.requires_grad = True"
      ],
      "metadata": {
        "id": "2x333K9pXG4S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sum(p.nelement() for p in parameters)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7qUxPvG8XJYS",
        "outputId": "feb0d266-48fa-432b-c60a-2a91e38ca5e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11897"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lossi = []\n",
        "stepi = []"
      ],
      "metadata": {
        "id": "oVGOomnpXMaD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1 x 50,000 @ 0.1, 2 x 50,000 @ 0.01\n",
        "\n",
        "for i in range(50000):\n",
        "\n",
        "  # mini-batch\n",
        "  ix = torch.randint(0,Xtr.shape[0],(32,))\n",
        "\n",
        "  # forward pass\n",
        "  emb = C[Xtr[ix]] # (32, 3, 2) - this would be (20000, 3, 2) without mini-batch\n",
        "  h = torch.tanh(emb.view(-1, 30) @ W1 + b1) # (32, 100)\n",
        "  logits = h @ W2 + b2 # (32, 27)\n",
        "  loss = F.cross_entropy(logits, Ytr[ix])\n",
        "\n",
        "  # backward pass\n",
        "  for p in parameters:\n",
        "    p.grad = None\n",
        "  loss.backward()\n",
        "\n",
        "  lr = 0.01\n",
        "  # update\n",
        "  for p in parameters:\n",
        "    p.data += -lr* p.grad\n",
        "\n",
        "  # track stats\n",
        "  stepi.append(i)\n",
        "  lossi.append(loss.log10().item())"
      ],
      "metadata": {
        "id": "Z3Cj1fMqXP5d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(loss.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8lUIXiNvXabO",
        "outputId": "4a071929-8d11-491d-d5a4-8ddf179b2577"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.332001209259033\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# quickly get the loss on training set\n",
        "emb = C[Xtr] # (32, 3, 2)\n",
        "h = torch.tanh(emb.view(-1, 30) @ W1 + b1) # (32, 100)\n",
        "logits = h @ W2 + b2 # (32, 27)\n",
        "loss = F.cross_entropy(logits, Ytr)\n",
        "print(loss.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mmQL0zbhXczL",
        "outputId": "26047401-8317-4eb2-82d4-29b9ea6a369c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.17278790473938\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# quickly get the loss on validation set\n",
        "emb = C[Xdev] # (32, 3, 2)\n",
        "h = torch.tanh(emb.view(-1, 30) @ W1 + b1) # (32, 100)\n",
        "logits = h @ W2 + b2 # (32, 27)\n",
        "loss = F.cross_entropy(logits, Ydev)\n",
        "print(loss.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xJIFmpKCXe-x",
        "outputId": "ef8a13ef-63f3-43a4-d2df-d1df2534b4a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.201981544494629\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "plt.plot(stepi, lossi)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "1P1iU_D5XhzU",
        "outputId": "7b71d246-913f-412f-d7de-ce0c197dba78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7e5828a4c1f0>]"
            ]
          },
          "metadata": {},
          "execution_count": 105
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sample from the model"
      ],
      "metadata": {
        "id": "jT7YzqPJaND0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# sample from the model\n",
        "g = torch.Generator().manual_seed(2147483647 + 10)\n",
        "\n",
        "for _ in range(20):\n",
        "\n",
        "    out = []\n",
        "    context = [0] * block_size # initialize with all ...\n",
        "    while True:\n",
        "      emb = C[torch.tensor([context])] # (1,block_size,d)\n",
        "      h = torch.tanh(emb.view(1, -1) @ W1 + b1)\n",
        "      logits = h @ W2 + b2\n",
        "      probs = F.softmax(logits, dim=1)\n",
        "      ix = torch.multinomial(probs, num_samples=1, generator=g).item()\n",
        "      context = context[1:] + [ix]\n",
        "      out.append(ix)\n",
        "      if ix == 0:\n",
        "        break\n",
        "\n",
        "    print(''.join(itos[i] for i in out))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HxS0yG70aPfh",
        "outputId": "79816cf2-8463-46aa-f0f6-1c38c0b01f60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mora.\n",
            "mayah.\n",
            "see.\n",
            "mad.\n",
            "rylla.\n",
            "emmaniendrarf.\n",
            "adelyn.\n",
            "eliighly.\n",
            "jenleigh.\n",
            "estanaraylyn.\n",
            "malara.\n",
            "noshubergihahies.\n",
            "kin.\n",
            "rendy.\n",
            "panthona.\n",
            "uvenned.\n",
            "ryyah.\n",
            "fael.\n",
            "yuma.\n",
            "myston.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise 1:\n",
        "Optimization of the Neural Network"
      ],
      "metadata": {
        "id": "5pxbzfUBdyJS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Neural Network Optimization\n",
        "\n",
        "When optimizing a neural network, there are several aspects to consider. We can categorize them into two groups: architecture-related and training-related.\n",
        "\n",
        "### Architecture-Related\n",
        "\n",
        "1. **Hidden Layer**: The size of the hidden layer can significantly affect the performance of the neural network. Increasing the size of the hidden layer can make the network more powerful, but it can also lead to overfitting and longer training times. Finding the right balance is crucial.\n",
        "\n",
        "2. **Embeddings Layer**: The size of the embeddings layer determines the dimensionality of the vector representation of the input characters. Higher-dimensional embeddings can capture more complex relationships between characters, but they can also increase the computational cost and risk overfitting.\n",
        "\n",
        "3. **Context Size**: The size of the context window affects the amount of information the network receives as input. A larger context window may provide more information for prediction but increases the dimensionality of the input and may make the model more complex.\n",
        "\n",
        "### Training-Related\n",
        "\n",
        "1. **Number of Iterations**: The number of training iterations affects how well the model can learn the training data. Too few iterations may result in underfitting, while too many iterations may lead to overfitting.\n",
        "\n",
        "2. **Batch Size**: The batch size determines how many examples are used in each iteration to compute the gradient and update the parameters. A larger batch size provides a more accurate gradient estimate but requires more memory and computational resources. A smaller batch size can lead to faster training but may result in a noisier gradient.\n",
        "\n",
        "3. **Learning Rate**: The learning rate controls the step size in the gradient descent optimization. A high learning rate may lead to faster convergence but may also overshoot the optimal solution. A low learning rate may result in slow convergence.\n",
        "\n",
        "4. **Learning Rate Decay**: Decaying the learning rate over time can help stabilize the optimization process. Starting with a higher learning rate and gradually reducing it can combine the benefits of fast initial progress and fine-tuning towards the end.\n",
        "\n",
        "### Other Considerations\n",
        "\n",
        "1. **Regularization**: Techniques such as L1 or L2 regularization can help prevent overfitting by penalizing large parameter values.\n",
        "\n",
        "2. **Dropout**: Dropout is a regularization technique that randomly deactivates a fraction of the neurons in the hidden layer during training. It can help prevent overfitting and improve generalization.\n",
        "\n",
        "3. **Activation Functions**: Different activation functions in the hidden layer, such as ReLU, sigmoid, or leaky ReLU, can affect the network's ability to capture non-linear relationships.\n",
        "\n",
        "4. **Optimizers**: Advanced optimization algorithms like Adam, RMSprop, or Adagrad can adapt the learning rate for each parameter and accelerate convergence.\n",
        "\n",
        "5. **Early Stopping**: Monitoring the validation loss and stopping the training when it starts to increase can prevent overfitting and save training time.\n",
        "\n",
        "6. **Weight Initialization**: Properly initializing the weights can have a significant impact on the training dynamics and final performance.\n",
        "\n",
        "When optimizing the model, it is essential to experiment with different combinations of these hyperparameters and techniques. Using techniques like grid search or random search can help systematically explore the hyperparameter space and find the best configuration for the model.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "RvCEWp7zdmbE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A step-by-step plan for optimizing the model\n",
        "\n",
        "Optimizing a machine learning model involves fine-tuning the architecture, hyperparameters, and training process to achieve the best performance on the validation set while maintaining good generalization on the test set. Here's a step-by-step plan for optimizing the model:\n",
        "\n",
        "1. **Establish a Baseline**: Start with a basic model architecture and training process, and measure its performance on the validation set. This gives you a baseline to compare against as you make changes.\n",
        "\n",
        "2. **Prioritize Hyperparameters**: Some hyperparameters have a more significant impact on performance than others. Prioritize tuning the learning rate, batch size, and hidden layer size, as these tend to have the most substantial effects on the model's performance.\n",
        "\n",
        "3. **Tune the Learning Rate**: The learning rate is often the most critical hyperparameter. Experiment with different learning rates on a logarithmic scale (e.g., 0.1, 0.01, 0.001). Once you've found a good learning rate, you can fine-tune it further.\n",
        "\n",
        "4. **Adjust the Batch Size**: Experiment with different batch sizes. A larger batch size can provide a more accurate gradient estimate but requires more memory. A smaller batch size can lead to faster training but may result in a noisier gradient.\n",
        "\n",
        "5. **Tune the Hidden Layer Size**: Adjust the size of the hidden layer. A larger hidden layer can increase the model's capacity but may also lead to overfitting.\n",
        "\n",
        "6. **Experiment with Regularization**: If you observe overfitting, try adding L1 or L2 regularization, or use dropout in the hidden layer.\n",
        "\n",
        "7. **Adapt the Learning Rate**: Implement learning rate decay or use adaptive learning rate optimizers like Adam or RMSprop.\n",
        "\n",
        "8. **Early Stopping**: Monitor the validation loss during training and stop when it starts to increase, indicating overfitting.\n",
        "\n",
        "9. **Adjust the Context Size**: Experiment with different context window sizes. A larger context window may provide more information for prediction but increases the input dimensionality.\n",
        "\n",
        "10. **Fine-tune the Embeddings Layer**: Experiment with different embedding dimensions. Higher-dimensional embeddings can capture more complex relationships but increase the computational cost.\n",
        "\n",
        "11. **Evaluate on the Test Set**: Once you've optimized the model on the validation set, evaluate it on the test set to measure its generalization performance.\n",
        "\n",
        "12. **Analyze the Results**: Inspect the model's predictions on the validation and test sets. Identify any patterns in the errors and consider additional changes to address them.\n",
        "\n",
        "13. **Iterate**: Optimization is an iterative process. Based on the results of your experiments, update the model, and repeat the steps above.\n",
        "\n",
        "Remember that optimization is a trade-off between model performance, computational cost, and generalization. It's essential to strike the right balance to achieve the best results on the task at hand. Keep in mind that it's not always necessary to achieve the highest possible performance; a model that performs well enough for the specific application is often sufficient."
      ],
      "metadata": {
        "id": "Y3GtR4cveM_6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Tuning the learning rate\n",
        "\n",
        "A good way to tune the learning rate for your model is to use the learning rate range test, also known as the learning rate finder. This technique involves running a single pass through the training data while gradually increasing the learning rate and plotting the loss. The optimal learning rate is then chosen based on the loss curve. Here are the steps to follow:\n",
        "\n",
        "1. **Initialize the Model**: Start with your baseline model, including the architecture and initial parameter values.\n",
        "\n",
        "2. **Choose a Learning Rate Range**: Define a range of learning rates to test. Typically, this range spans several orders of magnitude, e.g., from \\($1 \\times 10^{-5}$\\) to \\(1\\) or even higher.\n",
        "\n",
        "3. **Run a Single Training Epoch**: Train your model for one epoch while gradually increasing the learning rate within the chosen range. For each mini-batch, update the learning rate according to a pre-defined schedule (e.g., exponentially increasing).\n",
        "\n",
        "4. **Plot the Loss Curve**: Plot the training loss against the learning rate on a logarithmic scale. Observe the loss curve's shape and identify the learning rate that corresponds to the steepest drop in loss.\n",
        "\n",
        "5. **Choose the Optimal Learning Rate**: Select a learning rate slightly below the point of the steepest drop in loss. This learning rate should be aggressive enough to converge quickly but not so high that it causes instability.\n",
        "\n",
        "6. **Train the Model**: Train your model using the chosen learning rate and monitor the validation loss to ensure that it decreases over time.\n",
        "\n",
        "Once you have the plot, observe the loss curve and choose the learning rate that corresponds to the steepest drop in loss. Use this learning rate to train your model.\n",
        "\n",
        "\n",
        "### Examining the loss curve\n",
        "\n",
        "When you're looking at the loss curve and trying to determine the best learning rate, you generally want to look for the steepest descending portion of the curve. This represents a learning rate where the model is learning quickly, but not so fast that it's unstable. If you pick a learning rate in the middle of this steep descending portion, it's likely to be a good choice.\n",
        "\n",
        "Regarding the single point with the lowest loss that doesn't have many neighbors: It could be an outlier or an effect of noise in the loss curve. In general, you should be cautious about selecting a learning rate based on a single data point.\n",
        "\n",
        "Now, about the noise in the graph: Increasing the batch size can help reduce the noise in the loss curve. Larger batches provide a more accurate estimate of the gradient, which can lead to smoother updates and less noise in the loss. However, larger batches also require more memory, and the computation might become slower. So it's a trade-off you need to consider.\n",
        "\n",
        "You could try increasing the batch size and see if it results in a smoother loss curve, which might make it easier to pick a suitable learning rate. Alternatively, you could also try running the learning rate finder for more epochs or using a larger dataset to get a more stable estimate of the loss at different learning rates.\n",
        "\n",
        "Let's think step-by-step:\n",
        "\n",
        "1. Try increasing the batch size and see if the loss curve becomes smoother.\n",
        "2. Look for the steepest descending portion of the loss curve and select a learning rate in the middle of this region.\n",
        "3. Be cautious about selecting a learning rate based on a single data point, especially if it doesn't have many neighbors with similar losses.\n",
        "4. Consider running the learning rate finder for more epochs or using a larger dataset to get a more stable estimate of the loss at different learning rates.\n",
        "\n",
        "Remember that finding the optimal learning rate is part art and part science. It may require some experimentation and fine-tuning to find the best value for your specific problem and dataset."
      ],
      "metadata": {
        "id": "ZLBXYAVhfaDJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "g = torch.Generator().manual_seed(2147483647) # for reproducibility\n",
        "C = torch.randn((27, 10), generator=g)\n",
        "W1 = torch.randn((30, 200), generator=g)\n",
        "b1 = torch.randn(200, generator=g)\n",
        "W2 = torch.randn((200, 27), generator=g)\n",
        "b2 = torch.randn(27, generator=g)\n",
        "parameters = [C, W1, b1, W2, b2]\n",
        "\n",
        "for p in parameters:\n",
        "  p.requires_grad = True"
      ],
      "metadata": {
        "id": "p870Lbfchvij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Define the learning rate range and the schedule\n",
        "min_lr = 1e-5\n",
        "max_lr = 1\n",
        "lr_schedule = np.linspace(min_lr, max_lr, len(Xtr)//32)"
      ],
      "metadata": {
        "id": "j2_7etMah16F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize lists to store the learning rates and losses\n",
        "lrs = []\n",
        "losses = []\n",
        "\n",
        "batch_size = 32\n",
        "num_batches = len(Xtr) // batch_size\n",
        "\n",
        "# Generate random indices for the entire dataset\n",
        "indices = torch.randint(0, Xtr.shape[0], (len(Xtr),))\n",
        "\n",
        "# Loop over batches of indices\n",
        "for i in range(num_batches):\n",
        "    # Extract batch of indices\n",
        "    ix = indices[i * batch_size : (i + 1) * batch_size]\n",
        "\n",
        "    # Set the learning rate\n",
        "    lr = min_lr * (max_lr/min_lr)**(i/num_batches)\n",
        "    lrs.append(lr)\n",
        "\n",
        "    # Forward pass\n",
        "    emb = C[Xtr[ix]]\n",
        "    h = torch.tanh(emb.view(-1, 30) @ W1 + b1)\n",
        "    logits = h @ W2 + b2\n",
        "    loss = F.cross_entropy(logits, Ytr[ix])\n",
        "    losses.append(loss.log10().item())\n",
        "\n",
        "    # Backward pass\n",
        "    for p in parameters:\n",
        "        p.grad = None\n",
        "    loss.backward()\n",
        "\n",
        "    # Update parameters\n",
        "    for p in parameters:\n",
        "        p.data += -lr * p.grad\n"
      ],
      "metadata": {
        "id": "OKieMMI-hp27"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the loss curve\n",
        "plt.plot(lrs, losses)\n",
        "plt.xscale('log')\n",
        "plt.xlabel('Learning Rate')\n",
        "plt.ylabel('Loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "id": "ipnkeF0Jp1nI",
        "outputId": "875e30fb-2a68-40e1-cebb-03678a61c3a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "g = torch.Generator().manual_seed(2147483647) # for reproducibility\n",
        "C = torch.randn((27, 10), generator=g)\n",
        "W1 = torch.randn((30, 200), generator=g)\n",
        "b1 = torch.randn(200, generator=g)\n",
        "W2 = torch.randn((200, 27), generator=g)\n",
        "b2 = torch.randn(27, generator=g)\n",
        "parameters = [C, W1, b1, W2, b2]\n",
        "\n",
        "for p in parameters:\n",
        "  p.requires_grad = True"
      ],
      "metadata": {
        "id": "Cc33UszSrfro"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Define the learning rate range and the schedule\n",
        "min_lr = 1e-5\n",
        "max_lr = 1\n",
        "lr_schedule = np.linspace(min_lr, max_lr, len(Xtr)//256)"
      ],
      "metadata": {
        "id": "Qnsmv4rprp2o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize lists to store the learning rates and losses\n",
        "lrs = []\n",
        "losses = []\n",
        "\n",
        "batch_size = 256\n",
        "num_batches = len(Xtr) // batch_size\n",
        "\n",
        "# Generate random indices for the entire dataset\n",
        "indices = torch.randint(0, Xtr.shape[0], (len(Xtr),))\n",
        "\n",
        "# Loop over batches of indices\n",
        "for i in range(num_batches):\n",
        "    # Extract batch of indices\n",
        "    ix = indices[i * batch_size : (i + 1) * batch_size]\n",
        "\n",
        "    # Set the learning rate\n",
        "    lr = min_lr * (max_lr/min_lr)**(i/num_batches)\n",
        "    lrs.append(lr)\n",
        "\n",
        "    # Forward pass\n",
        "    emb = C[Xtr[ix]]\n",
        "    h = torch.tanh(emb.view(-1, 30) @ W1 + b1)\n",
        "    logits = h @ W2 + b2\n",
        "    loss = F.cross_entropy(logits, Ytr[ix])\n",
        "    losses.append(loss.log10().item())\n",
        "\n",
        "    # Backward pass\n",
        "    for p in parameters:\n",
        "        p.grad = None\n",
        "    loss.backward()\n",
        "\n",
        "    # Update parameters\n",
        "    for p in parameters:\n",
        "        p.data += -lr * p.grad"
      ],
      "metadata": {
        "id": "biFhQWccrm_1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the loss curve\n",
        "plt.plot(lrs, losses)\n",
        "plt.xscale('log')\n",
        "plt.xlabel('Learning Rate')\n",
        "plt.ylabel('Loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "id": "AbdvET6Br3-G",
        "outputId": "76cde1ab-d950-4fe3-f51b-909256ae78f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAG1CAYAAAAFuNXgAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABt2ElEQVR4nO3dd3hUZdoG8Hv6pIeQEAiEhI60EDoIAgoiKCqsny6oIK5YsbGuKxYUXMV1VVh3cS2oKHYUsayigLD0TijSe4CQENLb9O+PZM6cM3OmhUmm5P5dV65v5sw5M2/O+mUenvd530dhs9lsICIiIooQymAPgIiIiCiQGNwQERFRRGFwQ0RERBGFwQ0RERFFFAY3REREFFEY3BAREVFEYXBDREREEYXBDREREUUUdbAH0NisVivOnz+PuLg4KBSKYA+HiIiIfGCz2VBeXo60tDQolZ5zM00uuDl//jzS09ODPQwiIiKqh9zcXLRp08bjOU0uuImLiwNQe3Pi4+ODPBoiIiLyRVlZGdLT04XvcU+aXHBjn4qKj49ncENERBRmfCkpYUExERERRRQGN0RERBRRGNwQERFRRGFwQ0RERBGFwQ0RERFFFAY3REREFFEY3BAREVFEYXBDREREEYXBDREREUUUBjdEREQUURjcEBERUURhcENEREQRhcFNkBw4X4ZXVxxCeY2pXtfbbLYAj8j1/ef9dBBLd+T6dd3JwkqsOVzQQKMiIiLyjsFNkIx7cz3eWnscb64+6ve1m49fQv+XVmPF/rwGGFndZ5y4hHfWncBfvt7r13UjX1uLaR9ux87TRQEby/GLFcjJLQnY+xERUWRjcBNkRwsqfDqvvMaE1QfzYbHaMOWDrSisMOD+T3b59Vnesj2rDuTji21nAADFlfXLKNntPlNyWdeLXfP6/3Dzwo0oKKsJ2HsSEVHkUgd7AE1dQpTG6zkWqw23/GczDueX47X/y4LJ4v+U1JwffsdP+/Lww4yhaBGvd3ndZrPhno93AAD6t0uCQuH3R6DaaPH/Ii9qTI73zC2ulh27HJvNhmmLt8NiteHjuwdAUZ9fiIiIwhIzN0Hw8eZTwuN4vffgZuvJSzicXw4AWHPIcz2Lu+zMhxtPIb/MgNd+PSz7eoXBLDwuKDNIXjNbrB4/M6+0Gkfyy5E191eP59VHWbUjg6T0Iz6pNFqw9vBFrD9aiLPF1cLxjzadwis/HwrkEImIKMQwc9PIiiqNmP3d78LzWL37/wmqjRbc+s5mFFY4go3jF91PY7264hCW7jyLHx8eipIqEz7fdgYPjeyIlDidcM7es6Wy116qMAqPKwxmiOMIo8UKtUo+DjZZrBg87zeX477WOxeU1yC3qAp9M5JkXy8RBTf+ZIYsouxWmaho+/nva+/9Db1aoUfrhLqx2mC0WKFTq3x+fyIiCl3M3DSAnaeLcevbm7H/nDSQOJJfjj4vrpQcqzSY8cd3N2PuDwdc3ufHveex71wp8kodtSaeanTeWnscF8sNeGvNMUx8ayMWbzqFv3y9R3LOoQvlqDCYsfFYISxWRwBwqdIRQF2qMEimpQwm95kbcVAkZrXZPNb4lFaZsOl4IYa+sgZ/+M9mbD8lX4BcUuUITMTZJW+MomxTad17iMdTKgqa7l68HX3mrhTOIyKi8MbgpgHc+s5mbDtVhDve3yo5LhfAfLEtF1tOFOGDjSddXjPKTAeJAxJ30zQGsxWVdVmOrSdcg4YHPtmJ2xdtxaL1J4RjhaIgpbDCAPFHy41DfK6c00VV6Pe3VfiXm9VgUz7chsnvbRXee/3RQtnzSqoc46ryI3NjEo35UmXte5hF987+uZuPX8KawxdRabTglwMXfH5/d6qMvgdgRETUMBjcNAB7AGLPOhjMFhzNL8eGY65f4OLAwWi2wmK1wWj2XONip9eosHDNMTz97T5JVkJccFxtcg0I7IHE+xtOoqTKiAqDWZKBKawwwmhxXOdpPO6Cm8+2nsGlSiNeX3lE9vU9Tku73ZXTiDMs/mRuzKJ7UFQX3Jic7vXR/HJMem+LcOxShRFPLN2DTcflAy2xi+UGGM1WmC1W3PbOZty9eDu+3X0W3Wb/gq/83BuIiIgCizU3DSwntwS3vr3ZY/bDLr+sBvct2Ylygwm//XmE17oVvUaFf/xSWyD8hz6theNmq/SzytxsFFhQbsDI19aiRZweY3u2FI4XVhgkAY3B7D5jUuhmWspf7n5VcXDjnBU5VlCOlDi97Iozo0zmRvw7mSxWl71z/r6ittD4651nceqV62XHU2204N11JzB/1RF0SY3DM9dfga0na7Njv9UVez/59V7c2i/dzW9EREQNjcFNAF0orcErPx+UHJvzw+8+BTYAMOzVNcLjU4WVbr/w7cTZDvEKJ7PTUvFeL7hfxVRcZUJxlUkSEF2qMDoFN55qbuQzN2IWqw2Pf5mDbmnxuH94B6/ni4lrbnJyS3DdgnV49JpOUKuUuHfJDgxu3xyfTR/kcp04S1NUV08k/t+hxmSVzWp5M2vZXizPOQ8AOJxfjm0nA7dZIRERBQaDmwD647ubcepSleSYeNqmdWIUzpVUO1/mlrcl2OIaFHF2xtdgSuz4xUrJexlFAZKn4MbdtJTY+qMX8f2e8/h+z3ncO6w9lDLFQm+uPoq+Gc0wvHOK5HhJtSMz9NO+2pqYBz7dhWitCjYbsOn4JVwsN0hWhAHSAO+TLWfQq3UiruyULByrMpo9rr6y2Wyye+PYAxu7g3llbt8jUH7el4cqowV/6NvG5bWCshrYAKT6uP8PEVFTwJqbADFZrC6BDQDkFjmCmRbxOpfX3dl2qghzZAqQxcSZh0XrHQXJ3oIib8pqTJLMjaeam4Jy78FNpcExzn4vrcKcH36XPW/qB9tw35Id6Pj0T3hvXW2xs7siYvHxdUcuurzuHOA9+c1eXDd/nWRMnjI3WXN+FXZrtpNb/VWfQNIfVqsND3y6C39eugd5pdLA2GSxYsDLqzHw5dUepw79VWOyYPXBfFT6UeNERBRKGNwEiPOybzlJ0Vqf3++Zb/f79fniJeImiw1aN/vS+KK8xuzTtJTNZpNdjeXsu5xzwuOiSiM+3HjK7bm//J4Ps9WGl346iHMl1R6zRnbOX/qAdFrKrlz0ZV1lNHv836ysxoynlu1DldEMm82GO9/fimve+J9PnyN2rKAck97dgk0yxeR2NSYLtp0scglKP9lyGo9/lSM8d95cUVyPVFYduEDkb/89gD99tAOPf5nj9VwiolDE4CZAsts2w0d3D/B4jlqlwGfTB6JvRjPMHN3Z789o6ePUw4ZjhT5nFAa1d908r7zGLMkETP1gm9AG4R+/HMJba48BAA7kleFCWQ2iNCrce1V7t5/x64F8n8bi7MpXfsN/97pvDto5NRYAUGFwzVp4Czr+9dsxrDrovXv55uOXUFRpxPqjhTghmrpzfI58ZdTXO88CAJ5eth+bT1zC5EVbZc8DgBe+/x23vrMZC1ZJl80/u3w/vhNNg9mzVfvPleK+JTskU2JWp6zS3rMlWLL5lKR9ha8+2VKbsarv/25ERMHG4CaAuraM8/i6SqnAkA7J+OaBIeidnuj3+7dMCGxdxVNju+I/t/d1OW6x2iRZAQCY++MBfLUjFwvXHMerKw5j95liIWszsH0Snh53RUDH5otRV6QCgJBd+f18qZBxEtfc9GmbiLfvcP09fXHgfJlkl2Rn7oKoJ5bugc1mw5kix1TlyNfWCgXIVqsNTyzdg4VrjuGL7bVLx/+95phwrtXqGjSV1tUf3bRwI375PR8Pihqnijda3JNbghv/vRHPffd7UAMUm83GfX+IKCgY3ARQMy/TTimxjpobrdr/W+9r5sZXN2alITFavrfV/vPSQtnPtp7Bk1/vFZ5/sPEU3qvbBLB/pnzrhPpqlxzj9Zz7h3cQloBXGMz4Ynsurn9zA55bXjudZ89c9c1ohmUPXonuafH1GsuBvDLJRoLOPGVGes9diQuiTuYnCysx7cNtAIDfz5fh651nhaX8zspl6l2K6jq12/dREp9jz7T978hF3LRwo3C8Pp3UA9Vj9M9L96Db7F9wpK4vGhFRY2FwE0CeApZWCXo8ck0n4blOdO6fhrZDrzYJXt//cjM3STHS4EuvUUGhUCBG6+ipZB+X8yZ7zn7Yc15oC9Evo9lljcvZ59MHYYCHgOnFm3vgiWs7I1pXu9hv2a5zmLVsHwDgy7oN9OwZFXXdyiy9pn59ow7klQlBhZyLHgqqnbNfAISdoyvdZDRqTBYs2XIahy+4BgTFHoIse23S1A+2eR2DN4Hqn75sV22tlXgnbCKixsDgJsCita5fonE6NdY8MQLNRZkbcZPG9GZR+OaBIV7fu2dr7wGQJ22ToiXP9Zra//n/+cdsALX1N74U8DrrG+DgJiVOh3fulJ9GSojS4M5BGVCrlIjVuQ9Y7MGNPeC0/65if7u5h9exnC2u9rjcvdjPflT2rEhxpXygMvfHA3hu+X5MFu2cbFdUaZT0vxKvqDeYLbKr5OoV3AQqdVNHpeSfGSJqXEH9q7Nu3TqMHz8eaWlpUCgUWL58uc/Xbty4EWq1Gr17926w8dXHVZ0c+7RMGtAWvz5+Fb5+YIhL5kAn+rJtEa+HRqXEB3f18/jemW6ma5rHaH1aHRWjU0m+5PV1AdaobqlY+fhVsvU33rwysafbjuH1pVIq0CxGK9TUiImDxxit/DZN/ztyUSj01ajswY30/q/7y0jcMSjD4zi0KiUsVhsOOE3RXQ57JqnITRbms621xbxmmZqb4kojTl5yFDWLTzGYrDiS79pU9dSlKuw87d9Gg+56ltWXOtBvSETkRVCDm8rKSmRlZWHhwoV+XVdSUoIpU6bgmmuuaaCR1d+LN/dA++QYTBqQjnkTe6Jzahy6yBQai4ORFnUb0F3dNRWPj3K/iqpFnPw+OUaz1acaHp1ahVido8ZGvJlep9Q4NIvxfam6XX2u8VWUTBYsShSkxOrkg5upH2wT6oM0KkXd/3Xcn3bJMWjbPFr2Wrs4nRptmkUBqF15FCjquixGUT3aVhRVGXGyUL4rvMFsxUWZDNO6Ixfxh/9sFvYC+mHPebe9rwrKa/Dw57vdrgAzW6x46NNdwmo5X6kY3BBRIwtqcDN27Fj87W9/w4QJE/y67v7778fkyZMxePDgBhpZ/aXE6bD6z8Mxb2Ivj+eJa25axDlqaWI8TLW42wRQo1b6FNzkldYgXu95U+q7hmR6fR8xd0XUL/ow5eNcAxSlUeFOUTYlWqZORhzwRLsJbsTkskoWmawIUJvNmTq49vP/NTkbbeqm8fac9b6HkZ1OrcR3D13pYTyeMzeeHMwrw7aTxbKvXao04qNNp9xe+/XOszh9qRIPf74bT369F4cuuGajftl/AT/sOS9zda1VB/Px3315eHWFfBG0OwxuiKixhd1k+IcffogTJ07g+eef9+l8g8GAsrIyyU9D86VmQSf64k6Oc3zJx4i+sO++sh3euDULzaI1+HBaf0mdjtjCyX18mpYqqjQg1ktw89wN3fD9DNcv5ymD5adwkmLkV1vd6TTlkxKnw9COycK02F1DMvHelL5IjtWiS2ocFk/rj92zR2PuTd2Fa+QyN+JgxVPNjZ3cfXEX3LRtHo1nb+iGrU9fgxFdWqC90zRgizidEPy40zYpGr3aJGBsj5ayr2tUSmw4Wojlu8/Jvu5JfpkBnzvtmmz39LJ9QuNOORfLDcKScwD4dpfr58sVTttsNuw8XYzSahMulLquvCqsMGDNoQLZpet2nJYiosYWVr2ljh49iqeeegrr16+HWu3b0OfNm4c5c+Y08Mj8lxClwfzbsqBRKREtqh1JFWVnmkVrMLFPG0zIbi0bMA3tmIxFU/tBr1HhjkFt8dqvR1zOyWgejYHtkpCTW4Inx3TFh5tOupwjplIqXAqXX7ypO24fmIGPN592OT9RlLmZNCAdn2/LxVVO/aHaJcdgzRMjANR+ya45VIDxWWmI0qqw/ZlRboNBbyucYnzI3NinpcTk2ig4zlcKfZruvao9FouyIf+alI0uLePwkcx9sLutfzoUCgX+c0dfPP3tPny29QzG9miJn/fX9sUymCy44333G/rVl7dNGwsrDDgjag/y+/kybD1xCZ9sPYMakwXjs9Ikfbzsfvk9H/d/shPtk2MwIdvReb7aaEGUVoUb3tyAC2U1eP3/siS9r8QBJDM3RNTYwia4sVgsmDx5MubMmYPOnX3f3XfWrFmYOXOm8LysrAzp6ekNMUS/Tch2bYQ4sF1z4fGluhU14i//+65qj0+3nsEPDw+V7Adz//AO6J6WgGmLtwvH2qfE4Lc/j5C8/9Kd8vUWYuLPu3NQBu4cnOn23MQoR+bm+fHdMaxTCoaKGlTWvp/jcUqcDrf2Txe95v6LT+5f/OIj0TIFxU+N7YpXfj4kPNfIZG48JBkk0hKjMD4rTZiqaZ8S6zZ7ZicODF+8qQceu6YTftybJwQ3lR6adTakgnIDWtfVEAHAmaIq3PauY0XWygP5GNKhuct1P+2r3SH6RGGlZF+dHi/8gl3PjRb28Vl5IF8S3Ih3uPaWubHZbCiuMrlMUxIR1VfYTEuVl5djx44dmDFjBtRqNdRqNebOnYs9e/ZArVbjt99+k71Op9MhPj5e8hPKYnRqIWgZ2bWFy+uzxl2B3bNHu2x0p1YpXc7/YcZQl+tbJ3oupLUb2aU2+3LXlZnCsUev6YQ4nVoyNSOeJtJrVBjXsxXi9dKpKmU9lxZ7+we/c0FxQpQG9w5rjy/uHSQckwtuLB4yN87EX8zJsVpJrZQccTZJpVSgRbzebebi35OzPb7XfR5aWvirtNokaTYq3jnZ7vhF12JlcQF3mWhZucVqwxrRNJjG6b6UiJese/kfcv6qo+jz4kqsqAsAiYguV9hkbuLj47Fv3z7Jsbfeegu//fYbvv76a7Rr1y5IIwu85Q9eiYMXyjCwnfxGdnJf2HLkpm0evaYT9p8vxc29W8tc4bBoan+UVZskq6EeH90Zj1zTCcVVRny27YzPOxOr6hncyGV1xIdUSgWeH98NZdVmXN21BaK0SiiVCq9tMDzVhzgb0SUF3+4+B71GCYVC4XX3Xrl9jkZ2aYHnIe2E/oc+bXB9z1Z4TJnjsuz7kas7Qq9VYfqw9nhnXeA2wPPWCiG/zHW1lXjpubhmB5AGLQoAM7/KQb+MJNzWPx1DXnH8Y8Pb7X5zdW1PrWeX78N1bmqViIj8EdTgpqKiAseOOZaVnjx5Ejk5OUhKSkLbtm0xa9YsnDt3Dh9//DGUSiV69JCuwGnRogX0er3L8XCXEK3BoPauUwSBeu+v7vO+ysy+14zc8eRYHXbPvlbyr3pP6rsnnFzGx/nItCtdg9o4UeZI7gvdn8zNjVlpsFhtyG7r20aFcgFl2+bRWPHYMFy3YL1wrF1yNBSK2nts3+X4riGZGNElBSO6uGbsAqG8xv8+T/ZeWHLECZnVB/NRabRg2a5zGNdTGqCYLVZ8v+c8nv9uP966vS8Gy0x/Ae67zxMR+Suo01I7duxAdnY2srNr0/MzZ85EdnY2Zs+eDQDIy8vDmTPyq0MouGJ1ap8LRQM5LeXLSjTxuORqXNytlpKjUCgwsU8bn/pdAfKZGwDomBIred4yobb+Rbw0/7FRnQIS2Pyxfzo+vKu/y/FCD60i6qNSVIMjvs/O++SY65qEFleZMElm52XHdQxuiCgwghrcjBgxAjabzeVn8eLFAIDFixdj7dq1bq9/4YUXkJOT0yhjpfqr72oZb7UavqiSaUDpR+LGb3JFzkBtbZJ4L6JmdQ1LxXVDcsXKr97SSzhX7LPpA/Hn0fKF9b3aJGJk1xYuwWGgi5nlprEA12aiJotVUodVKfO/CQChozsR0eUKm4JiCl/1jVHc7cjsj8vN3Mj5+dFhbl/zFMiJv+DtS+jFwZDcRoy39kvHrudGuxwf0iEZD1/TCSO6pLi8ZrHam4Y27P97X3DTcbzIqW+W2WJDc9EU54mLlbBabSirMeHrnWeF457+Zykoq8GaQwUel/G7c6qwEmU1/vfYIqLwxeCGGlx9GzFOyG6NSQPa4s1JjlVFCVHymwa6Uy0KbuxfsP0yHfUzH07rj6QYLd6f6rmvl9gVreq34k68h5F92bN4R2p3gZFCocAnfxoorNR6VNRdvkomeOuWVjs+X2ObwaL6rmFOy/g9yZfZ1A+QCW6sVlyqdGR5courcO+SHej1wq94Yukenz5r9Px1mLZ4O/5btzTdV8cvVmDEa2tx5Tz51ZREFJnCZrUUhZ9OLWJxtKACN/dOq9f1apUS8yb2BFC7wunddSfwwvjuXq6qNaxTMtYfLcTkgW2FY988MASfbz+De4Y6lliP7NICO591v5FgIIn3cbFPNfmyESEADO2UjMN/G4uL5QYkxzrex3k5/F+v64q+GbWr2HxdpdYpNRabT1wCAHRrFY/1Rwt9us5d5sa5i7rBZJUEPLlFVVh1UH43ZXd90uzdzVceyMcNvXz/72l9XU+tcjdTYUQUmRjcUINZev9g5OSWYFgn16kTf92c3Ro3Z3tevi723pR+OJJfLtlULzM5BrPGXuFybmMENoC0n5h9ispdjY47KU5Tdc+P7yZpu3CjKJCUywTp1EqXVUniMTQXBU4JURohqACAa7q2wGrRZ+X7OC11scIgmXLKLXbdY8duz9kSj1sM+Ft03IDlVUQUwjgtRQ0mMVqLEV1aBGX7fb1GhV5tEhstcPGFuGDYXiztS38sTzKax0im1MTNRuXuu9xqLvG2Sc1jHMHTANE+Sy9P6In3nVZgFbrpbH7JKbhx7kn1yRb3KyC99dwymv0LVy6zvIqIwhSDG6J6aCNqZeAruekWX6elPBEvtRc3G1XJFN3IZYrMoqXbiaKVWeLpL3vDU184T0vJNdx058e9ecKqqUXrT2DWsr2SImJfMjdv/+84Xv+1tnN5fQqQiSj8MbiJMO9N6YcojQpv3d4n2EOJaOIWD76yN57s1MKx582UwZlIidPhdlFtkL/EySnx1JfcRtbOmZvWiVGSaaq2SY72HM1ETVG99dQSu+SU0bHXu3hLorWI06G02oRNx2trfv7234P4fFsutpxwbCRoD26sVhtWHchHQXkNSqtM2H+uFEDtSrhXfj6Ef/12DLlFVbCKght/dqYmovDGmpsIM7pbKvbPGcNOzA2sTbNojLoiFasO5gvHbujVyuM1V3VOwfKHrpRsCJgUo8XWWddc1p4+4iySeBpOLiBJjdfjaIGjh9QX9w7C2/87LjzvlBqHf/6xN1LidDhwvkz0XrWR0p9Hd8brK127z4s519zYdUiJxbEC1/5VsTo1lj80BPN+OoTVhwqQX1YjybiIV1rZg5uvd57Fk9/sRevEKJgsVhSUG/DVfYMlNVaVRrNkTyOjxQq98vKmAYkoPDBzE4EY2DQOcSZi1cyrsOC23l6v6Z2e6LKc/XI3K+zYojYg+Wz6QMnxf/6xNxKiNJLppYzm0bhnaG3Liv8+MhTpSdEY6NTq46berTGkQ7KkuFhfV8sz4+qOuH94B4/j2VeXRXHWIUV+l+e7hmSiY4s4xNbt1lxeY5b02xK3jThaUIH1Ry/i+7pO7edKqlFQt/Py6oP5ko0AzRabpObGyB2QiZoMZm6I6kkck3Rs4blZZ0O7SaYRanbbZsiZPRo/77+ABz/dBQDIbB6D6Ve1xxNjuggByw09W0GpALLaJEqul0xL1dXcKBQKl80V35/aD3/6aIfL52tVSklA0SElFkC+y3n2OiH7svbyGrNkl+O/rzgkPC6pMuHO97fJTnGpVQoYLI7rDGarZFrKxB2QiZoMZm6I6mlo3RL3EFqQ5UKhUKB3eqLwvEXdRoJ6jXTl1g290pAuqrcBpCunxLU8JdXS3X4TojT49+RsjM+S7j8T47QSLNNNfy57A1Z7w9N/rj6KZ5fvd3xelevuwnJ1wmqlUpK5qTZaJPVEzNwQNR3M3BDV0+QBbRGrU6Ffhvt9WUJBqwQ9lIraZdHO2RlPkmLlC4rH9miJN1cfFZ7HR2nQLzMJN/RKw11DMvCH/2wGULsSrFgUmMi1igAcRc5xoiai3+Wc93mcdlq1NLipNJphMDsyOZfTu+pCaQ10aiWaiTZiJKLQxcwNUT2plApMyG7jkvEINQqFAuv/ejV+fHio2+yJnCTRtJTZ6ggMrmgVj9V/Hi48F6/A6iDqfq4VLdd69ZZebltnRMkEN/Wx41QRKg2OYKbaaIHBJMrc1DO4Ka02YdC81ch+ceVljY+IGg8zN0RNQOvEKLRO9G9vHvGeOWkJ0ms7pMTiL2O6oLzGjDbNHMGdOIAR180kRmkkwY7kczTSmpv6WnP4oiRTVGW0SDM3ddNSW05cwuqD+XhiTBeflriLV3jZbLaQ2hiSiOQxuCEitzbPuhqVBovsdMxDIzu6HBN/8YvrXRKjtW6DAvvGgnF6/5qiysnJLREeVxnNqJHJ3Pzx3S3CmOR+B2fiZekWqw1qFYMbolDHaSkicqtVQhQ6ijYd9Ic4c+Opm7vzaqlAccncOE1LHb5QjovlBny/57ww1mMF5cKGgHYW0XpyMzcCJAoLzNwQUYMQhwHitg7OAjUt5azKaJFmbixW/O3HA8Lz0moT+r+0CgAw96buSE+KxrQPtwMAfn38KnROrV3e77xXjnilGRGFJmZuiCigXrypO5pFa/DU2K7CMU+ZG3tBsrdSlnkTe+LXx6/yeRxVTquliiqNWLThpPB81+li4fG54mrJjsynCiuFx+JpKXEfLiIKXczcEFFA3Tk4E3cMysD+c45gwVO2wx7cdGkZh44t5Fs03DkoA5MG+Nd/q8JgxsZjl4TnpU7781QYHTsfl9WYJTt7V5ssqDFZ8Pv5MkntkC+NO4ko+BjcEFHAKRQK9Ggdj+nD2iGjuefl5/q64EajUuLXx67C93vO47EvcyTniAOTaVdm4sONp7yOYdmuc5LnizdJrxFvBFhWY4JWVChsMFnxwCc7sebwRQxq79jH6HL2yiGixsNpKSJqEAqFAs9c3w13DMoQjqUn1S4pH9DOETBEO+2WHB/l+m+u/LIa4fHT467Az48O83s8Jy5Wun2trNqECvEeOSYL1hy+CACSruQsKCYKD8zcEFGj+fbBK7HzdDFqTBZsO1kbNKid9r+Jl1kSfnO2o3eWRqXEFa3iAzqushozYnWOaapq0UovMU5LEYUHZm6IqNEkx+owpntLj53r24l2Ub6qcwo++dNA3Nov3e35nlZipcTpcH2vVl7HtSe3BD/vvyA8r2FwQxTWGNwQUaO7pmsqMptHY2K2azfz5rGOhp3HCyowtFOybDD01X2DcWu/Nnjquq4ur9lFa1XQudkZ2RP3mRtOSxGFA05LEVGji9KqsOaJEW53Lb6hVyv8uDcPdw7OkH0dqK3bGdAuCb/8fsHtOdFaNcoNZrevu1NRI3+Nr5mbH/ach16jwuhuqX5/NhFdPgY3RBQUnno0vfZ/WZg8oC36t/PecX1klxYYkJmE3m0T8e66E5LXYrQqOH/KkA7NEa1VYdXBArfvKS5gFvMluCkor8HDn+8GAJx4eRyUHqbgiKhhMLghopCj16gwpGOyT+dq1Up8df9gAHAJbqK0KjxyTSfYAKw8kA+gdsWTtyai50vcBTc2mCxWGM1WxLjZUflShdFxvtUKnZI7GhM1NtbcEFHE0qqU6NE6Ae9N6Sccs1ptSInTebgKOF9aLXvcZLZizPx16P78Lyircey9U15jwv+9vQn/WXtckt3hjsZEwcHMDRFFLLmZL7PVhngP7SAAoKTKJHvcbLXiRF1rhkc+34237+gLvUaF/6w9ju2nirH9VLH0fAY3REHBzA0RNSlWm012Lx1fiFsxrD18EfN+OggA2Hu2VPZ8I5eOEwUFgxsiihgfTuuPfhnNPJ5jttgQp5dPWo/p7nl1U7nTKqqvdpwFABwtKJf/LCuDG6JgYHBDRBFjZJcW+PqBIaIjrvNSaYl6t9NSdw1p5/H9xXU2gGM/nPwyg+z5nJYiCg4GN0TUJHx89wCM7JKCuTf1cDstZe9Q7k5Ztev+NxYP/aa4ozFRcLCgmIiahKs6p+CqzikAgDw3q6FaJeihVipgttrQs3UC9p2T1tKcLa5yuabrcz+7/Uw22iQKDgY3RBSxUuPll3zHucnctIjXY9mDQ1BpsOBihQGP1G3GZ/fj3jyXazy1ZGDmhig4OC1FRBHn7Tv64OquLfDna7vIvh7jYfqpV5tEDO7QHFrV5e8szJobouBg5oaIIs51PVrhuh7uu4F7av1gp6lHw01nXC1FFBxBzdysW7cO48ePR1paGhQKBZYvX+7x/A0bNuDKK69E8+bNERUVha5du2L+/PmNM1giikgf3z0A3VrF4+UJPSXH1QEIbthFnCg4gpq5qaysRFZWFu6++25MnDjR6/kxMTGYMWMGevXqhZiYGGzYsAH33XcfYmJicO+99zbCiIkoUmx/ZhTyy2rQo3WCUGgspglAw8tATEuZLFYoFQqo2ICTyGdBDW7Gjh2LsWPH+nx+dnY2srOzheeZmZlYtmwZ1q9fz+CGiPySEqfz2GMqIJkbqxVLNp/C/nNlmDexp98dwk0WK0b8Yy1idWqseGyYT9NpRBTmBcW7d+/Gpk2bMHz4cLfnGAwGlJWVSX6IiLzRBKig+LnvfseXO3Lxv6MXvZ5fUF6DCoNjL53Tl6pwrqQah/PLOcVF5IewDG7atGkDnU6Hfv364aGHHsI999zj9tx58+YhISFB+ElPT2/EkRJRuApEQbF4KXhFjRk2mw2lbppyFlcaMeCl1ej3t5Wio46AhsvKiXwXlsHN+vXrsWPHDrz99ttYsGABPv/8c7fnzpo1C6WlpcJPbm5uI46UiMKV2o/MTevEKMnzKE3tUnOD2SIcUykVeGLpXmTN/RW7z0i7hwPAgbzarHKNyQqbrTaoEe8ByOCGyHdhGdy0a9cOPXv2xPTp0/H444/jhRdecHuuTqdDfHy85IeIyBtx5kapACZmt3Z77sanrkbLeL3w3N6YU9yuQakAvtlV22jzrbXHXd5Dr3F8XqWxNigSt3Zgh3Ei34VlcCNmtVphMMg3rSMiqi+N0vHnUa9RQav2/OdSo3ZkehzBjWMKyibKwlhl2jIoRcXC9uuMZkdAw5obIt8FdbVURUUFjh07Jjw/efIkcnJykJSUhLZt22LWrFk4d+4cPv74YwDAwoUL0bZtW3Tt2hVA7T45r732Gh555JGgjJ+IIpd4WirKh+BGLQqG7F3HS0XBjUEUqFhtroGKOHgpr6nN+IizNeJAh4g8C2pws2PHDowcOVJ4PnPmTADA1KlTsXjxYuTl5eHMmTPC61arFbNmzcLJkyehVqvRoUMH/P3vf8d9993X6GMnosgmDm70GpXXAmNx8NE8RgsAKKtxBDc1Jkf9zZrDFzHs1d/w7p39EKdXo02zaElNjf06aeaGwQ2Rr4Ia3IwYMUIonJOzePFiyfOHH34YDz/8cAOPiogI0IqCGbVK4TW4ERcPx+pq/7R+teOscEwc3ABAblE1xv5zPQBgx7OjJFma+SuPYObozpLghpkbIt+xtxQRkQzxJn4qpcLrtFS10RG8yG0AWOMhOOn3t1WS55uOX8Km45vx9h19hGPM3BD5LuwLiomIGoJatJuwSqHw2iVcHLzIbQAoDn58ZWDmhqheGNwQEckQT0uVVJu8TkuJl22Li4vtxPU3vuJqKaL6YXBDRCRDqVTgpQk9oFIqMDG7tWRa6o5BbdE2KdrttXIbAJa42ZnYE3EdDqeliHzHmhsiIjduH5iB63u2QkKUBp9udazcnDwgA/dd1QF//moPpl/V3uU6uSxPcZXR78+3LwkHuIkfkT+YuSEi8iAxWguFQiGZporSqpCeFI2v7h+M0d1SXa5Ry3T/XndE2jjzuu4t8dk9Az1+dnGlIyBizQ2R7xjcEBH5QDwtZe8d5U6VTPGw86bEbZtHI0bnOXkuzvZwWorIdwxuiIh8IOqOIBvc2LM1PVsnIK+0Wjg+uH1z2ff7v75toPcSJBVVOup0GNwQ+Y7BDRGRD8yi1Up6reufzm8fvBI3ZqXhrdv74HxJjXD8tv7pLuc+Pa4rOqXGSZplyikRZW6MXC1F5DMGN0REPrCIdlPXyhQM92yTgDcnZSM9KRoT6jqID2qf5LIEvHd6Iu69qgMA79Nb4mkp1twQ+Y6rpYiIfCDex0ah8Lyh35TBGejSMg5Z6Yn4cc95yWvigEbnNbjhtBRRfTBzQ0TkA7NzRbAHapUSV3ZMRqxOjZuzW6NVgl54TVxE7G1aqki0WuqVnw/hw40nZc+7UFqDSoNZ9jWipojBDRGRD7q1iqvXdXqNCu/c2Vd43ik1VngsN73lyZwfDuBUYaXk2IHzZRg0bzXu/2RnvcZHFIkY3BAR+aBvRhLevqMvfnnsKr+vbRatFR53bekIkrxNb8n5dvc5yfN5Px8EAKw/Wuj3exFFKtbcEBH56LoeLet1XVKMI7jJbB5zWWMorDBInuecKREeW602KGU2ECRqahjcEBE1sGitCiO7pKDCYEb3tPjLei9xSwYAqDE7NgwsN5iREKW5rPcnigQMboiIGphCocCH0wYE5L0qRIXD1UaLpFt4WbWJwQ0RWHNDRBTSNE4dxstF++Y4T1HVp/M4USRicENEFMJGXSFtzCmelioolwY3pdUMbogABjdERCGtb0YzvHpLL6QnRQGoDW7yy2pw+6It+HTracm5d7y/FTUmC4xmK3KLqoIxXKKQwOCGiCgE9GydgA1/HelyPFqrxq390vHhXbU1O+dKqjHw5dXYeOwSlu0653L+hqOFmLZ4G4a9ugY7ThU1+LiJQhGDGyKiIHphfDfE6dV4eUJP2S7h0draY/F639Z/bDhWiI3HLgEAPt582svZRJGJq6WIiILorivbYcrgTCiVCtmaGXtwE+shuMlKT8Se3BIAwN6zJcLxapNF/gKiCMfMDRFRkNk33tOpXf8kR2trgxpPHcTvvjITS/5UO21VaXAENNVGBjfUNDFzQ0QUIjQyvaai6jI3nlo1tE6MEl6vMjlWU1UZ2UyTmiZmboiIQoRKpnWCWnTsuRu6yV7XulmUMH1VJc7cmKwBHiFReGBwQ0QUwmyix38a2g49WkvbN6iUCrSI0wvBzaVKo/DawbwyfL7tDGw2G4iaEgY3REQhSqkAOqfGSo6lxOokzxOiNFApFcL0lbNZy/Zhz9nSBhsjUShicENEFIJm39ANe18YIxQU26XESYMbe6Gx83liZX7uXGyyWPGftcex/xyDIgpPDG6IiEKQRq1ErM41YGmZECU9r673lKfVVIs2nMS8nw/6PD318ebT+PuKQ7jhXxv8GDFR6GBwQ0QUQsZnpSExWoMbe6XJvp6WoJc8t6+wUikVskvJAWDdkYt4538nsP1UsU9j+P08MzYU3rgUnIgohLz5x94wW22yy8IBoKVTcKMVBTTRWhUM5toVUt1axeNAXpnk3F1nijGgXZLXMbD+mMIdMzdERCFEoVC4DWwAoJXLtJQ4uHH8ezVOr8bwzimSc32toeHqKgp3DG6IiMJIy3jnaSnHPjjiFVMxOrXLNFVeaQ3Ol1Tjf0cuevwMK2MbCnMMboiIwkh8lBo3ZjnqcaSZG5XksXMjzrJqE4a88humfrANu8+4r79hbEPhjsENEVEYUSgUeHNStvBcXHMjXjEVp9e4ZG6OFlTIPnZm5bQUhTkGN0REYUw8TSXO3MTp1dBp3P+JV3noVcXUDYW7oAY369atw/jx45GWlgaFQoHly5d7PH/ZsmUYPXo0UlJSEB8fj8GDB+OXX35pnMESEYWQf0/OxrBOyfjLmC7CsTi9xvFYp4Ze7X7vm9ziKqzYfwGFFQaX15i5oXAX1OCmsrISWVlZWLhwoU/nr1u3DqNHj8ZPP/2EnTt3YuTIkRg/fjx2797dwCMlIgotN/RKw5I/DURzUTuGZtGO4CbWS+ZmwaqjuP+TnXj8yxyX1xjbULgL6j43Y8eOxdixY30+f8GCBZLnL7/8Mr777jv88MMPyM7Olr+IiKiJSIzWCo9jdWqU15i9XrPtZJHw2GyxotJgkWRubDYbFJ6msIhCUFjX3FitVpSXlyMpyf2mVAaDAWVlZZIfIqJIlBTjCG7i9GroPWRu7MQFyZPf24qsub/iTFGVcKzH87/go02nAjpOooYW1sHNa6+9hoqKCtx6661uz5k3bx4SEhKEn/T09EYcIRFR40kUTUvVrpZyX3NjV2W0CJv2bTtVm8U5dKFceL3SaMGqg/kBHilRwwrb4Oazzz7DnDlz8NVXX6FFixZuz5s1axZKS0uFn9zc3EYcJRFR42nmNC3lS+bGYrWh0mjxeg5ROAnL3lJffPEF7rnnHixduhSjRo3yeK5Op4NOp/N4DhFRJBBPS8Xq1T5lboDazf3kOpDbmS0Mbii8hF3m5vPPP8e0adPw+eef4/rrrw/2cIiIQkZClHQpuHgTP7XSfVFwWY3J4/vWmD1ndohCTVCDm4qKCuTk5CAnJwcAcPLkSeTk5ODMmTMAaqeUpkyZIpz/2WefYcqUKXj99dcxcOBAXLhwARcuXEBpqW/N4IiIIpm0oFgjWeXUJ6OZ2+tKq0xYtuus29drTAxuKLwENbjZsWMHsrOzhWXcM2fORHZ2NmbPng0AyMvLEwIdAHj33XdhNpvx0EMPoVWrVsLPo48+GpTxExGFkhidGkv+NABL/jQAUVoVKg2OpeDtk2PcXrfvXClmfrXH7es1JmtAx0nU0IJaczNixAihSl/O4sWLJc/Xrl3bsAMiIgpzwzqlCI/H9GiJz7adwdVdW+BiuetOxEM6NMem45ew75zn7DczNxRuwq7mhoiIfBOrU+ObB4bgoZEdJfU3vdMT8dHdA5ASV7vYYudp9x3CAQY3FH4Y3BARNQHi4Obeq9pjeOcUXN+zFQDgbHG1x2trzJyWovDC4IaIqAnQaRzLwjWq2j/9o7ulCtkbT4xmq8cSAqJQw+CGiKgJEGduNKraVVQKhQJdUuN8un71wQK887/jDHIoLITlJn5EROQfcXCjVTked0qNxYZjhV6vv+fjHcL5V3dNDfwAiQKImRsioiZAMi0lCnR6pCX49T7HCyoDNiaihsLghoioCZBOSzkej89Kw4s39/D5fcQrp8T76BCFEgY3RERNgLjPlL3mBgC0aiXuHJTh8/vYWzGsOpCP7s//grfWHgvcIIkChMENEVEToNPI19z4y1C3W/ETX9fuaPzqisOXNzCiBsDghoioCZAUFKtd//SrPDTWFLNnbjglRaGMwQ0RURMgnZZy/dOfHKt1OSanylgb3JgsXBJOoYvBDRFRE+CuoNhu0ZT+6Ngi1uv7lFWbfPq80ioTDl8o932ARAHE4IaIqAkQBzRyNTc92yRg1czhXt+ntNoEi9V71mb4a2swZsE67PfSlJOoITC4ISJqAsQlNRq1b/U1ckqqTHjuu/0+nQcAqw7m1/uziOqLwQ0RUROgUDgCGrWy/n/6q4wWfLb1jPA8WqvycDZgsrDpJjU+tl8gImoC2iXHoEtqHOL0ask+N/4Sb+IH1AY7F0pr0DJBL3u+mYXHFAQMboiImgCVUoGfHh0GBaRZHH9VOwU3ADBo3mqceuV62fONzNxQEHBaioioiVApFVD6uJ+N3cguKZLn1SaLz3viAJyWouBgcENERLJe+78svPKHXpJjNhuQEKXx+T1MZk5LUePjtBQREcm6pW8b2GyuwUlxldHlmNVqE7JC4qXizNxQMDBzQ0RELux74cjV58jEOzCYHUGMUfTYwOCGgoDBDRERCd65sy+SY7VYPK2/X9eJV1GJi4hNZgY31Pg4LUVERIIx3Vvi2m6pkozNgHZJ2HayyON19oaagHQqiqulKBiYuSEiIgnnqai3bu+Dx0d1hl7j/iujxiQ/LWVvtEnUmBjcEBGRR8mxOjw6qhPaJbtvrCmelhJnbioN5gYdG5EcBjdEROQTz5kbR3Dzzc6zwmMGNxQMDG6IiMgnpdUmt6/Zp6XOFlfhzd+OCccrDJyWosbH4IaIiHySW1Tl9jV7QbG9G7hdWY37gIiooTC4ISIin5g8NME01GVudGrp14rRbHVptknU0BjcEBGRTwa0S3L72vd7zmHM/HX4Yc95l9fKa1h3Q42LwQ0REfnkX5Oy3b72074LOJxfLqm3sePUFDU2BjdEROST1Hg9Zozs6Pd15TVmGMycmqLGU6/gJjc3F2fPOpb6bdu2DY899hjefffdgA2MiIhCz4yrO+KRazrh8+mDfL7m1RWH0G32L9h52vMux0SBUq/gZvLkyVizZg0A4MKFCxg9ejS2bduGZ555BnPnzg3oAImIKHToNSrMHN0ZvdMTfb5m0/FLsFhteObb/Q03MCKRegU3+/fvx4ABAwAAX331FXr06IFNmzbh008/xeLFiwM5PiIiCkEqpWu3cG+scu3EiRpAvYIbk8kEnU4HAFi1ahVuvPFGAEDXrl2Rl5cXuNEREVFIUtcruGmAgRDJqFdw0717d7z99ttYv349Vq5cieuuuw4AcP78eTRv3jygAyQiotCjrE9ww+iGGkm9gpu///3veOeddzBixAhMmjQJWVlZAIDvv/9emK7yxbp16zB+/HikpaVBoVBg+fLlHs/Py8vD5MmT0blzZyiVSjz22GP1GT4RETWAGK3K4+uclqLGoq7PRSNGjEBhYSHKysrQrFkz4fi9996L6Ohon9+nsrISWVlZuPvuuzFx4kSv5xsMBqSkpODZZ5/F/Pnz6zN0IiJqIH0ymmH90UK3rzNxQ42lXsFNdXU1bDabENicPn0a3377La644gqMGTPG5/cZO3Ysxo4d6/P5mZmZ+Oc//wkA+OCDD/wbNBERNahRV6RKgps/DW2H9zecFJ5bGN1QI6lXcHPTTTdh4sSJuP/++1FSUoKBAwdCo9GgsLAQb7zxBh544IFAj7PeDAYDDAaD8LysrCyIoyEiijx9M5rhwREd0LpZlHBsRJcUtErQS87jtBQ1lnrV3OzatQvDhg0DAHz99ddITU3F6dOn8fHHH+PNN98M6AAv17x585CQkCD8pKenB3tIREQRpUdaPK65IhUaleMrRa1UuDTRzCutwbGCisYeHjVB9QpuqqqqEBcXBwD49ddfMXHiRCiVSgwaNAinT58O6AAv16xZs1BaWir85ObmBntIREQRRaGoXTmlUYqDGyV0GtcC43FvrsfijSdRWGFweY0oUOoV3HTs2BHLly9Hbm4ufvnlF1x77bUAgIKCAsTHxwd0gJdLp9MhPj5e8kNERIGnUTuWh6tVrpkbADCarXjhhwO4b8lOl9d+P1+Kuz7chgPnWT5Al6dewc3s2bPxxBNPIDMzEwMGDMDgwYMB1GZxsrPdd40lIqLIo6zL3KiVztNS7peG7zxd7HLsj+9swdrDFzF50ZbAD5KalHoVFN9yyy0YOnQo8vLyhD1uAOCaa67BhAkTfH6fiooKHDt2THh+8uRJ5OTkICkpCW3btsWsWbNw7tw5fPzxx8I5OTk5wrUXL15ETk4OtFotunXrVp9fhYiILlNdbAOtSvrvZb3Gv38/lxvMAICSKlNAxkVNV72CGwBo2bIlWrZsKXQHb9OmjV8b+AHAjh07MHLkSOH5zJkzAQBTp07F4sWLkZeXhzNnzkiuEWeGdu7cic8++wwZGRk4depUPX8TIiK6HPbJKLVKumuxp8wNANSYLNDL1OUAwL9WH8XD13QKxPCoCarXtJTVasXcuXORkJCAjIwMZGRkIDExES+++CKsVqvP7zNixAjYbDaXH3vzzcWLF2Pt2rWSa+TOZ2BDRBQ8bZvXbt6qccrc6LxkbnKLqoTHBeU1ktdeX3kkQKOjpqhemZtnnnkG77//Pl555RVceeWVAIANGzbghRdeQE1NDV566aWADpKIiELPx3cPwPqjFzFpQFsAgEaUubEB0IsyN0kxWhRVGiXX259/v+c8Hvl8t8v722w2YSUWkT/qFdx89NFHWLRokdANHAB69eqF1q1b48EHH2RwQ0TUBFzVOQVXdU4RnosDEZtNmrlJjnUNbioMZuw9WyIb2ABAWY0ZCVGaAI+amoJ6TUsVFRWha9euLse7du2KoqKiyx4UERGFNxsgWQrepplr38HyGjNe/9X99FNBWY3b14g8qVdwk5WVhX//+98ux//973+jV69elz0oIiIKf+Ji4dR4vcvr5QazpO7G2QUGN1RP9ZqWevXVV3H99ddj1apVwh43mzdvRm5uLn766aeADpCIiMKPzWaTZG6SYlynl8prTDhfWu32PfLLuIsx1U+9MjfDhw/HkSNHMGHCBJSUlKCkpAQTJ07E77//jiVLlgR6jEREFGZqp6UcmZtm0VqXc3KLqlFjcr/CtqTK6PY1Ik/qvc9NWlqaS+Hwnj178P777+Pdd9+97IEREVF4E6+eSozWQqNSwGSxQaGoLTg+ml/u8XqTxdFF/Od9eXjuu9/x5qTeGNIhucHGTJGhXpkbIiIij2zS1VOtE6PwzQND8OR1XfDkmNoFKUe8BjeOrM4Dn+5CYYUBT369t2HGSxGl3pkbIiIib567oRtOX6rEoPZJUCgU6NUmEZ9vq915vqzG7PFacXBjF+VmR2MiMQY3REQUcDbUTin9aWg7l9didb599dinpSxWx/RUepLrknIiZ34FNxMnTvT4eklJyeWMhYiIIoTN5v61OL2vwU1t5uZ8iWNFVUqs7rLGRU2DX8FNQkKC19enTJlyWQMiIqLw5ym4ifdx12F7cJMv2u/GbPXwxkR1/ApuPvzww4YaBxERRZCebdz/YzhJZlm4HPu0VIXBUZtjlKnDIXLGmhsiIgqYFY8Nw/8OX8RdV2a6PadZjK/BTW0gU2W0CMeMZou704kEDG6IiChguraMR9eW8R7Pifej5ubwhXI8+Oku4ZjRLJ+52Xe2FBUGMwZ3aO77YCliMbghIqJGJd7/xhOzxYZHv5B2DHeelsotqsLZ4mpMem8LAGDzrKvRKiEqMAOlsMXghoiIQpLRYkVRpbQFg3PmZtirayTPD18oZ3BD3KGYiIhCk8liddkTx920lF1Jlakhh0RhgsENERGFhF8fv0ry3GyxIVon3ZHY4CW48dRlnJoOTksREVGj++t1XfH3FYfwr0nZ6JvRDGqVAi3i9JJzjBYrYrRql2OenC1mcEMMboiIKAjuH94et/Zrg+ZOOw73apOAvWdLAdROSzVz2hPH27TUOQY3BE5LERFRECgUCpfABgC+ffBKvHV7HwB101Ja6bSUOLixyOxWfLa4KsAjpXDE4IaIiEKGSqlAvL62PYPJYnXpAl5QbsCgl1fjYF4ZqoyuXcXPlVTD5qn3AzUJnJYiIqKQolHV7oNjtFhlszMXymow6b0tqDa67lZcY7LiUqURyWyw2aQxc0NERCFFo679ajJbbG4bZZZUmdyunGLdDTG4ISKikKJR1n41mSxWmK3+N8rkiilicENERCFFo66dljJZrEJn8KfHdfX5+goDN/Jr6hjcEBFRSNGo7Jkbm1BzE631vUTUaGFBcVPH4IaIiEKKfVqqtNqE3w4VAIDLqilPvO2FQ5GPwQ0REYUU+7SUmFqlgFbl21eWSbSL8Yajhbh90RacucT9b5oSBjdERBRSNDJBjEalhE7t+SsrXl87dWUSZW7ueH8rNh67hEe/3B3YQVJIY3BDREQhxT4tJaZWKhCj81x30yymtlWDXP+pvJKawAyOwgKDGyIiCinupqVidJ7rbux9qOSCG3f75VBkYnBDREQhRW5aSq1UQqv2FtzUtm2QKygurDBg6Y7cwAyQQh6DGyIiCikalRKPjeokOVZbUOya0RGzZ25MMpkbAPjL13sDM0AKeQxuiIgo5Dw2qjPuvrKd8FytVELtZbWUvebGZOYUVFPH4IaIiEKSTuP4ilKrFFArPWdukjwUFFPTEtTgZt26dRg/fjzS0tKgUCiwfPlyr9esXbsWffr0gU6nQ8eOHbF48eIGHycRETU+8dJvtVIhW4sjFqOtrclhcENBDW4qKyuRlZWFhQsX+nT+yZMncf3112PkyJHIycnBY489hnvuuQe//PJLA4+UiIgam1YS3Cih9lJzYy845g7F5HuzjgYwduxYjB071ufz3377bbRr1w6vv/46AOCKK67Ahg0bMH/+fIwZM6ahhklEREGgE62O0qi8Z240KkfDTWrawqrmZvPmzRg1apTk2JgxY7B582a31xgMBpSVlUl+iIgo9ImnpVRKhRC8yOnUIlbI9DC4obAKbi5cuIDU1FTJsdTUVJSVlaG6ulr2mnnz5iEhIUH4SU9Pb4yhEhHRZRJPS2lUSqhldi7u2jIOa58YgR8fGSr0njKaragxWRptnBR6wiq4qY9Zs2ahtLRU+MnN5SZOREThQFJQrFLgpt5pLueM6NICmckx0KlVwrTV9lPF6PviSpwvcf1Hr8FsQWGFQfbzNh0rxPsbTsJm41LycBfUmht/tWzZEvn5+ZJj+fn5iI+PR1RUlOw1Op0OOp2uMYZHREQB5DwtdXXXFvj2wSEoqzFj6gfbAECysZ8401NptODL7a7/mL1uwXqcLKzEmidGoF1yjOS1yYu2AgA6pMRgRJcWAf1dqHGFVeZm8ODBWL16teTYypUrMXjw4CCNiIiIGop4GkqjVEKhUCC7bTO0jNc7zlFJp67EYmUabZ4srAQA/LQvz21tjv0cCl9BDW4qKiqQk5ODnJwcALVLvXNycnDmzBkAtVNKU6ZMEc6///77ceLECTz55JM4dOgQ3nrrLXz11Vd4/PHHgzF8IiJqQCrRpn3iZeDRWvEqKsfXmDhzAwBxeveTE//45TAGvrwa1UbX2hwWJIe/oAY3O3bsQHZ2NrKzswEAM2fORHZ2NmbPng0AyMvLEwIdAGjXrh3++9//YuXKlcjKysLrr7+ORYsWcRk4EVEEUoqDG1EWJ0aUkREna7Reloo7K6o0YvupIpfjJgtrbsJdUGtuRowY4bFwS2734REjRmD37t0NOCoiIgoFKoX3zI04ENGopUvF67tiipsAhr+wqrkhIqKmQ7zyW9xXSlxoLA5EnDM3NX4EKVarI0jitJR7RZVGFFcagz0Mr8JqtRQRETUd4syNws1jcR8p54Jig8n3IEX8Pgxu5BnMFvR5cSUA4NhLY712aQ+m0B0ZERE1ad3S4gHIr3qyM4kzN2rnzI3v01ImSXDDmhs5hRWOjI0/WbFgYOaGiIhCUpxegz2zr3UJWsTEQUlitAbJsTphkz5fam6O5JejVYIeSTFa4Ri7isuziIK+UN/okJkbIiIKWQnRGkSJCoid6TWO13RqFVY+fhXuGpIJAKjxYVrqb/89iNHz1+Gv3+wTjsktDyfAIgpoLFYGN0RERAH18oSe6JfRDPcP7yA53ixGi1YJtZv8GcwWyV45nqw66Nj9vtJgDtxAI4hZlNEyh3hww2kpIiIKO5MHtsXkgW1lX7NncwwmK1QKBSzw74u4ipkbWQZRnQ0zN0RERI3IvlS8xmSBTCNxryqNzNzIMYZR5obBDRERRRQhc2O2SnY29lVFDYMbOeI9hSwhvqKMwQ0REUUUvUaUufGt5EbCvtqKpMTTUmZraK8oY3BDREQRRVeXuakxW2CfPXl8VGe35zsHQMVVpnq3bohkRtbcEBERBYej5sYKa93y5cRojdvz4/Sur10sd83emC1WHM0vD/k9XhqKOLgJ9Y0OGdwQEVFEsdfcHCuoEFY+eQpu5HZAvlBWg6+25+LHveeFY6+vPILR89fh6W/3uZzfFBhEOz4zc0NERNSIkqK1LscSojxlblyDm31nS/HkN3sx47Pdwhf59pNFAIDPt+WiognshXP6UiUe+GQn9uSWAJBmblhzQ0RE1Igyk2PQNilaciw1Xg+Fm+JiuczN/vOlwuPquvobcYDUFHYxvm/JTvy8/wJuWrgRgHQpuMWpi/pX23Nx5lJVo4/RHQY3REQUcewtGOySY3X4z+19cWu/Ni7nymVulu06Jzy2BzLuvtwj1bGCCuFxtdGC2d/9LjwX73PzyZbTePKbvRjx2ppGHZ8nDG6IiCjixDoFLCqlAtf1aImru6a6nBsjytwM6dDcpWXDuiMXcf2b67HlxCXhmKmJNddcvOmU5Lk4uNt+qna6LpTiPbZfICKiiBPnNNWkqpuT0sl0GBdnbprFaBGlUUlqav68dI/LNU0hcyP+DfPLaiSviTM3UZrQCyWYuSEioojjnLlR1H3baWWDG0ctjU6lFDYB9CTUC2oDwSpa8u5ckG0R/f4xOvdd24OFwQ0REUUc571r7Jkbjcr1a09cUKxRKaFTe/+yDvV9XgJBvJ2Pc3BjFv3+UVrH/QqVQmsGN0REFHGcV0DZ62iiNK6Bi/iYRq2Qnbpy1hSmpcTEAQwg/f3Vohql4ipjo43JEwY3REQUcZxXQCnrMjfNYlz3u9GoHF/OOrVKdurKWVMrKHbuAi5+Lt7/hsENERFRA3HO3NiTC81jdC7nakTBTIxOLexw7ElTy9yYnYI58e9fYxIFN5WmRhuTJwxuiIgo4kQ7TaMI01Ja18BFo3R8FcbqVD5NS60+VABrEwpwnIM5ceZG3JbhUqVBkskJFgY3REQUcRRO2xE7PxfTqB2vxejUQldxT/6z9jiW55zzel6kcC6gFq+WMoiCmYN55ej87M8Y9PLqRhubHAY3REQUkTzEMxLiFVQxWjX0PmRuAGDVwfz6DCssWZyWvpsl01KOzE1hRW03dXHAGAwMboiIKCLJLfv2dp6vmZumxjVzI56WcgQ+BeW1wY2nRqWNgcENERFFJJ0Pwc29V7WXrJaK8bHmBnA/1fXFtjP435GLvg0yTLjU3IiCHYOooPhiXXCTGOXamb0xMbghIqKI5G5J9xu3ZkGnVuLdO/vi6XFXuE5L+bBDMQDIhTY7TxfhqWX7MPWDbfUZcsgyWT2slhIVFNuDm4To4GZuQq8hBBERUQC4m5aa2KcNbsxKg7rudZdpKR92KBZbuiMXucXVeHxUJ2w/VSwcP32pEilxOkRrw/+r1mJxXS1ltdrwn/8dx+4zJcJxe81NYpCnpcL/jhMREcnwVNSqFgU04mmpWJ1aMi01uH1zbBZ1Axdbsf8C/vr1Xny5IxcAcGNWmqRz+PB/rEVagh6bZl1T798hVDhv4mexWvHz/gv4xy+HZc9PDHLmhtNSREQUkbQ+FhSLeyhF61SSTfz+0LcN+rRNlL3ObLUJgQ0ArD6Yj7WHpbU250trnC8LS86NQs1WG3KLq9yez4JiIiKiBuDrainxpnMxWmnmplOLWCx78Epc172l1/fZdabY6znhyiyzWipG537yhwXFREREDcDXVU8WUepGpVRInmc2jwHgvjhZrKgyNPoqNQTnpeD2mht3gl1QzOCGiIgiki8BCQAMbNccXVvGYUJ2awBAQZlBeM3+Je1LFkhcTBwONh+/hCeW7kFptfd+UMa63lL2Hl0Wqw0VBrPb8+M8ZHUaAwuKiYgoIvk6LaVVK/Hzo8OEfWt0MkvBtZex467NZnPZE+dYQQV+P1+KsT1a+RyEBdqk97YAqC2onjexl+Q1m02alak21i731mtUqDJaYLbYUF7jPriRu4eNicENERFFJF+DG0C6Id99V3XAiYuVuKVvG+GYc5dxf5gsNklwdCS/HNfOXwcAMN5ixf/1S6/3ewfCoQvlLsecV0fZm2PagxuL1YoKg8XlOjt/l9MHWkhMSy1cuBCZmZnQ6/UYOHAgtm1zv/mRyWTC3Llz0aFDB+j1emRlZWHFihWNOFoiIgoH9c2IJMVo8d6UfhgjKiK+f3gHtE+Jqdf7iTe5A4Dvc84Lj4urgl+nY8/KiJksVtlz7H23zFYbKuuCm+y2iXh5Qk/J+cHKRtkFPbj58ssvMXPmTDz//PPYtWsXsrKyMGbMGBQUFMie/+yzz+Kdd97Bv/71Lxw4cAD3338/JkyYgN27dzfyyImIKJT5uhTcF81jdfjtzyMwpnuq39eK2xMAwJrDju8350JdZ9tOFmH4P9Y0aDsHcW8oO5PZaVqqrjmmve+WxeqYlrq1XzqitNJ77Wsxd0MJenDzxhtvYPr06Zg2bRq6deuGt99+G9HR0fjggw9kz1+yZAmefvppjBs3Du3bt8cDDzyAcePG4fXXX2/kkRMRUSgTb84XKB4WCLkl7poNAGeKHPvDGGUCC7HJ723B6UtVDdrOQS5zY3TK3Px+vgyAI2gxW22oMNQWIsfq1C5TgE06c2M0GrFz506MGjVKOKZUKjFq1Chs3rxZ9hqDwQC9Xi85FhUVhQ0bNrg9v6ysTPJDRESRz5+aG185F9r6wjkzIg52nKd/nDnXvjSEapP34MZOnLmxr5aK1atdsmRNuuamsLAQFosFqanSNF9qaiouXLgge82YMWPwxhtv4OjRo7BarVi5ciWWLVuGvLw82fPnzZuHhIQE4Sc9PbiFW0RE1DgaIntwuZkbk8UqmYryFtw0BufMEuDaS8pOXHNTUTctFadTQ6Nm5uay/POf/0SnTp3QtWtXaLVazJgxA9OmTYNSKf+rzJo1C6WlpcJPbm6u7HlERBRZOrWIDfh7Wi8zc+McSHiruQm00moTxsxfhwWrjgjH5GpuLG5+z2htbUbGYLKgSrQ83DVz04SXgicnJ0OlUiE/P19yPD8/Hy1bym91nZKSguXLl6OmpgaXLl1CWloannrqKbRv3172fJ1OB51OF/CxExFRaLt9UAYKyg0Y2ik5YO9Zn8zNI5/vxt//0AtDOyW7TAG5m/5pKEs2n8Lh/HIczndd/i1mscqPq1l0bVuF8hqzMHadWimZAlQoALUy8PVO/ghqaKXVatG3b1+sXr1aOGa1WrF69WoMHjzY47V6vR6tW7eG2WzGN998g5tuuqmhh0tERGFEo1Liyeu6YkiHwAU3zjU3zaI1mDo4w+M150qqccf7WwEANUZp0GDyUlAcaDUm3z7PXczVLKYuuDGYhGJorVopmYbSqZUumxY2tqBPS82cORPvvfcePvroIxw8eBAPPPAAKisrMW3aNADAlClTMGvWLOH8rVu3YtmyZThx4gTWr1+P6667DlarFU8++WSwfgUiImoinKeltGolHhrZ0efrnTM3jV1zY4N86sm5T5RzF3C7ZnXtKMprzMLYtWqlZGVaIJfg11fQdyi+7bbbcPHiRcyePRsXLlxA7969sWLFCqHI+MyZM5J6mpqaGjz77LM4ceIEYmNjMW7cOCxZsgSJiYlB+g2IiKipcP7O16qVaBGvx6f3DMTti7Z6vd41uLHhzKUq6LVKtIjTu7kqcNyVDJmsVuiUjhVO9t+zeYwWl0QNQe2Zm7Jqk1AvpFUpJQGNfUVVMAU9uAGAGTNmYMaMGbKvrV27VvJ8+PDhOHDgQCOMioiISMo5c2OvNdH7+IXuvKdMQXkNrvrHGgDAqVeuD8AIPXNXM2Q0WyXLt+2ZmyitCh2iY3D8YiUAIKmu5qa4ytFs03laKhQyN8EfARERUZhQOtWSaIXgxvF16mnzQOfVUuK+TuZGmKJyt0+P86otexCnVioQq9cIxxPrghsxrVNBcbCbZgIMboiIiHw296bukudymZtorftJEedpKYsolWLfFK8huVvK7lz7Y64LdpRKBWJ1jt8tIUoD51phjVKaudG42ZqlMQV/BERERGGiU2ocVs0cLjy3Z2nEwU2MVn6KymazuUxLVYmel1W7BjeBXnTkrubGuQ2ERZy5EXVE16qlzzUqBZRKBRKjHNmdxgjSvGFwQ0RE5AfxBnX2zI1KFIXo3QQ3RotVyNzI7QNTVmNyOSYX21worcGlCoM/Qxa426bHeb8de0ZJqVAgRhTMqJRKxIumqezTcmrRtFQodDoPiYJiIiKicCH+srdLinHUooi//MUe+GSXcG18lAZFldIgwN5lW0yhUEjSLRUGMwbNq90b7uS8cX7vJ+PrtJQ9uFGrFOjUIg5AbVCXEqdDnF6cyXHNkVTJNOJsbAxuiIiI/GDf6wWAEKBo1UrsfHYUFAoFHvx0p+x1vx0qEB7H69UywY33zM2ZS46O4harDWo/O5/7PC1VF9yoFApMH9YOA9snIb1ZNGJ1anRPSxAKoYPdQ8qd0BwVERFRiBJnSy6Kpoeax+qQFKOF2oeC2vgo1+yOfOZG+ly8uV59+lK525zPXeZGpVRArVKiT9tmSImrbWV071WOdkcMboiIiCJMSZVrtkXlQ1+lWJmpLfnMjfS9zKLVVfY6meJKI37al+eSfZHj7hyjWRooiYMbZ/YgB5DWGvXLaAYACHJbqdoxBHsAREREkcSXppHywY3MKiPRWz27fB/OFlcLz+3ZlrsWb8eDn+6SdPp2R64DOCBTUGxzH9zEiJaGi7NHb07Kxo1ZaVj24JVex9HQGNwQERH5qUfreABAcqzrpna+ZG7kipK9rZb6ZMsZzPwyR3huD2725JYAAL7acdbr57rL3Dg38PSUuRHvZCwOltISo/DmpGz0Tk/0Oo6GxuCGiIjIT+/e2Q+39muDJX8a6PKaxof2A9Eyy8UrDGZYrDZJAOJac+PIlJicppKqjd73l3EX3Gw/XYQ/vrsZ+86WAhAHN55/F6M5+Cuj5DC4ISIi8lNaYhRevSULV7SKd3mtvjU3BrMVty/agmGv/oaj+eWY9uE21Jjc19E4TyVV+rAE29201Dv/O4EtJ4pw+6ItABxBlLfFWM5jCBVcCk5ERBRA9Z2WqjZasOVEEQBg9Px1Xt/DeYWTL7wVHZfV1f34nrkJzeCGmRsiIqIAcm6xIEcuuLlQVuPX59QnuDGIppFidWqM7pYqe54juPH8fu66jAcbgxsiIqIAKje4FgY7EzejtMsr8S+4qU/WRDwtpYD7fWqEHYpDoAlmfYTnqImIiEKU7JJuJ4HI3NSn3sX5Gq2b1IzQWyoUNq2pBwY3REREAVRW7T1zE6O9/JJX+x4z/uwSbHAqUNa4qRh2ZG4Y3BARETV5FQbvmRudWnnZO/na96YRLyv3NlUlydwoPExL2RxdweXYm2f62bez0TC4ISIiCqAyH6altGol1D7sh+OJvaBYL9pUT24jQDGDSVrs7G5PHm+Zm8/uGYR+Gc2w9L7BPo+3MTG4ISIiCqArWsYBqM3OuKNVK6G5zNSNPQtjEbX6LnWaErM5tQEXZ24U8F5zo3IzbdWzTQK+fmAI+mUm+T3uxsDghoiIKID+PbkPJg1Ix38fGer2HK1a6dN+OJ7Ya27ES8LFwc2Dn+7EmAXrhKkqm83mMm0lNy1VZTTjjZW1fapUoTrv5AWDGyIiogBKT4rGvIm90LFFHBKiNLLnaFVKn9o02HWtywaJ2YMacV8ocXDz074LOJJfgR2najcG/OX3fMm+NAqFQnYMr644LDy+3AAsWBjcEBERNZCtT1+DJ67t7HLc38zN3Jt6uBwTghtRZ277Si3xdJRCocCxggrc/8lOyfUjuqS4BDdKBbDpeKHwnMENERERSeg1KiTF6FyOa9X+ZW6iNK6b/hnN1tqpJtG01JpDBbDZbJKAR6kAcouqJNc+Pa4rXry5h8tScKVCgUqDo+iYS8GJiIjIhVxdi1blX+ZGp3F9D5PFJhT+2i3POY91RwslAY9KqZB8llIB3HtVB8TrNS7Bi1KhQLloxRU38SMiIiIXssGNWgm1t5bb4vNlsjwmi1WSobHbdKxQUjisUEgzMOJ4SOX0vgqFtLs4MzdERETkQi4w0aqUfgUO8pkbq2wLhszkGElwY7PV1t3IcV6OrlQoJNkgd5v4hToGN0RERA1Ibr8btUrpU1PK5FgthnVKlg2Qtp4owsnCStnrxMGN3PSVnfPUmHMsE66Zm8tvbkFERERuuWtx4K3mRqEANj11DVRKBaqddhYGgG2ninDzwo0ux2szOo7zzVYrzDLTVwBcpsacz2PNDREREblwF9x4m/FRKRTCknFPux3b3dQ7DUBt1sYgytyYrTa3HcRVTtkj5/O4FJyIiIhcuGtx4I04a+LL9JB9abnJIt2J2GyxSXYxllzj5X3dTWeFOk5LERERNSBx9uPuK9thYHvf+jGJAxp3BcFijuDG6hTcWN0GN94yM+6uC3UMboiIiBqQeMXRzGs7I1bn21evc18nlVLhMZOiraufMTutojJbbTCZfau5cRauwQ2npYiIiBqQOEaRZGO8XOdczJsS67rTsZg9c2N0npayyi8Zrx2P5zBAbh+dcMDghoiIqAGJWxy4a7lwbbdU6NRKfHbPQOGY85RRSpzn4EbtZlrK5KHmxlstj3MX8XDBaSkiIqIG1CElFqOuaIHEaK3bGpe3bu+D8hozmsVohWPOG+hNHtgWs5btc/s59mkp5839LFb3wQ1rboiIiMhvCoUCi6b2l3tBeKhWKSWBDQA4J3n+2D8dLeJ0KK4y4YmlewAAPVrH43hBJW7p20ZSUGxwKSh2V3PjeQLH3f44oY7TUkRERCHIuR5GoVDgmitSkZaoF451TIlFzvOjMfem7tDU7YVjNNsCNi0VrpmbkAhuFi5ciMzMTOj1egwcOBDbtm3zeP6CBQvQpUsXREVFIT09HY8//jhqamoaabREREQNz12tr16jEh5r1Uro1CooFAq3S8Gdp6XEAY23aakkp2xSuAj6tNSXX36JmTNn4u2338bAgQOxYMECjBkzBocPH0aLFi1czv/ss8/w1FNP4YMPPsCQIUNw5MgR3HXXXVAoFHjjjTeC8BsQEREFnvNScDu92hHc6ESPhaXgTqujTFbptNTXDwwRHrtbCj55YFsUVxrx8NWd6jf4IAt65uaNN97A9OnTMW3aNHTr1g1vv/02oqOj8cEHH8iev2nTJlx55ZWYPHkyMjMzce2112LSpElesz1EREShxNtScHdZFXGHcHFbBnv9jPO0lEW0NHzGyI7onZ7ouMZNemhcj1b4zx19kRCt8TLK0BTU4MZoNGLnzp0YNWqUcEypVGLUqFHYvHmz7DVDhgzBzp07hWDmxIkT+OmnnzBu3DjZ8w0GA8rKyiQ/REREoc5dcOM8LWXnblrKJJqWcl6K7q7mJlx7StkFdVqqsLAQFosFqampkuOpqak4dOiQ7DWTJ09GYWEhhg4dCpvNBrPZjPvvvx9PP/207Pnz5s3DnDlzAj52IiKihuS8FNxOLxPQ1D6WXwoubr+gUbvueixH42Xn4lAX9Gkpf61duxYvv/wy3nrrLezatQvLli3Df//7X7z44ouy58+aNQulpaXCT25ubiOPmIiIyH9dWsbJHteJMjdiWo8FxTbJOXbuNhX0tkQ81AU1c5OcnAyVSoX8/HzJ8fz8fLRs2VL2mueeew533nkn7rnnHgBAz549UVlZiXvvvRfPPPMMlE7zhzqdDjqd510diYiIGpu7XpjfPjgEX+04iyfHdJF9XZy5Ee9CI26/YHBaCm50My3lLnPjSxfyUBbU0Eyr1aJv375YvXq1cMxqtWL16tUYPHiw7DVVVVUuAYxKVRvF2mzhudkQERGRXXbbZpg3safLpn52kqyK6HvPvvLJZLa69JYy1T13Xh3lLojx1lAz1AV9KfjMmTMxdepU9OvXDwMGDMCCBQtQWVmJadOmAQCmTJmC1q1bY968eQCA8ePH44033kB2djYGDhyIY8eO4bnnnsP48eOFIIeIiKgpEDcJl0xLOXcFd1dQ7CaI8dZQM9QFPbi57bbbcPHiRcyePRsXLlxA7969sWLFCqHI+MyZM5JMzbPPPguFQoFnn30W586dQ0pKCsaPH4+XXnopWL8CERFRUNhEE1P2HYqPFlTgaEGFcFzcfsG55sZdEBPu01JBD24AYMaMGZgxY4bsa2vXrpU8V6vVeP755/H88883wsiIiIgaRiDCB3E1hrviYHN9am7CfFoqvPNORERETZi0oFg+IBFPS/lac+MuUAoXIZG5ISIiIt9lNo/GqUtVGNvDsbLYecrJ7vs954XH0VppbaqSm/gRERFRoIzs0gK7zpQgTu//V/HPj16F/LIaZCbHCMd82ZsmRufbZ2lYUExERET+um94B7RKjMKQDs39vjZKq5IENgB8CpJifQxuWHNDREREftOqlbilbxukJUYF5P2SY3WYf1uWx3N8zdyE+7QUgxsiIqIIMSG7DW7uneb2dV8zN+FeUBzeoyciIiIJvZveUwAQo/Vts1tmboiIiChk6ES9p5xXR4V7Q0xfNY3fkoiIqIkQdw3/+dFhSE8KTE1POGFwQ0REFEHEXcO1aiWU7tqPRzAGN0RERBFEKw5uVMqAtHkINwxuiIiIIohClKlpqpkbbuJHREQUQcSxjFat9Nqhc8mfBmDjsUsorjTiyx25DTu4RsLMDRERUQQRZ2q0KiXuGpIJABjeOUX2/GGdUvDU2K5hvyuxGDM3REREEUQcoigUCtwxMAPd0xLQrVW85+siJ7ZhcENERBRJnGtslEoF+mY083qdIoJKjzktRUREFEHqm4EJ802JJRjcEBERRRBFPaObB0Z0RGK0BtOHtQvwiBofp6WIiIgiyMB2SfW6rmWCHjufHR32faUABjdEREQRpUfrBCx7cAhaJ/rfdiESAhuAwQ0REVHE6dPWewFxJGPNDREREUUUBjdEREQUURjcEBERUURhcENEREQRhcENERERRRQGN0RERBRRGNwQERFRRGFwQ0RERBGFwQ0RERFFFAY3REREFFEY3BAREVFEYXBDREREEYXBDREREUWUJtcV3GazAQDKysqCPBIiIiLylf172/497kmTC27Ky8sBAOnp6UEeCREREfmrvLwcCQkJHs9R2HwJgSKI1WrF+fPnERcXB4VCgf79+2P79u0u58kd93asrKwM6enpyM3NRXx8fMP9Eh7G01DX+3Kup3P8uc9yx5vKffbl/Pq+7st/087PI/leN+Z/0/zbwfvcGNdfzt8Of18Lxt9om82G8vJypKWlQan0XFXT5DI3SqUSbdq0EZ6rVCrZmy933Ndj8fHxjfL/OO7G3hDX+3Kup3P8uc9yx5vKffbl/Pq+7st/v+6ujcR73Zj/TfNvB+9zY1x/OX87/H0tWH+jvWVs7Jp8QfFDDz3k83FfjzWWy/1sf6735VxP5/hzn+WON5X77Mv59X3dl/9+g3mfA/H5ofrfNP921P8c3ufAnV+f++zutVD72+GsyU1LNaSysjIkJCSgtLS0Uf5V0FTxPjce3uvGwfvcOHifG0co3Ocmn7kJJJ1Oh+effx46nS7YQ4lovM+Nh/e6cfA+Nw7e58YRCveZmRsiIiKKKMzcEBERUURhcENEREQRhcENERERRRQGN0RERBRRGNwQERFRRGFwEySZmZno1asXevfujZEjRwZ7OBGvqqoKGRkZeOKJJ4I9lIhUUlKCfv36oXfv3ujRowfee++9YA8pIuXm5mLEiBHo1q0bevXqhaVLlwZ7SBFtwoQJaNasGW655ZZgDyWi/Pjjj+jSpQs6deqERYsWNchncCl4kGRmZmL//v2IjY0N9lCahGeeeQbHjh1Deno6XnvttWAPJ+JYLBYYDAZER0ejsrISPXr0wI4dO9C8efNgDy2i5OXlIT8/H71798aFCxfQt29fHDlyBDExMcEeWkRau3YtysvL8dFHH+Hrr78O9nAigtlsRrdu3bBmzRokJCSgb9++2LRpU8D/VjBzQxHv6NGjOHToEMaOHRvsoUQslUqF6OhoAIDBYIDNZgP/3RR4rVq1Qu/evQEALVu2RHJyMoqKioI7qAg2YsQIxMXFBXsYEWXbtm3o3r07WrdujdjYWIwdOxa//vprwD+HwY2MdevWYfz48UhLS4NCocDy5ctdzlm4cCEyMzOh1+sxcOBAbNu2za/PUCgUGD58OPr3749PP/00QCMPP41xr5944gnMmzcvQCMOT41xn0tKSpCVlYU2bdrgL3/5C5KTkwM0+vDRGPfZbufOnbBYLEhPT7/MUYenxrzX5HC59/38+fNo3bq18Lx169Y4d+5cwMfJ4EZGZWUlsrKysHDhQtnXv/zyS8ycORPPP/88du3ahaysLIwZMwYFBQXCOfbaA+ef8+fPAwA2bNiAnTt34vvvv8fLL7+MvXv3NsrvFmoa+l5/99136Ny5Mzp37txYv1JIaoz/phMTE7Fnzx6cPHkSn332GfLz8xvldwsljXGfAaCoqAhTpkzBu+++2+C/U6hqrHtNUoG4743CRh4BsH377beSYwMGDLA99NBDwnOLxWJLS0uzzZs3r16f8cQTT9g+/PDDyxhlZGiIe/3UU0/Z2rRpY8vIyLA1b97cFh8fb5szZ04ghx12GuO/6QceeMC2dOnSyxlm2Guo+1xTU2MbNmyY7eOPPw7UUMNeQ/43vWbNGtsf/vCHQAwz4tTnvm/cuNF28803C68/+uijtk8//TTgY2Pmxk9GoxE7d+7EqFGjhGNKpRKjRo3C5s2bfXqPyspKlJeXAwAqKirw22+/oXv37g0y3nAWiHs9b9485Obm4tSpU3jttdcwffp0zJ49u6GGHJYCcZ/z8/OF/6ZLS0uxbt06dOnSpUHGG64CcZ9tNhvuuusuXH311bjzzjsbaqhhLxD3mvzny30fMGAA9u/fj3PnzqGiogI///wzxowZE/CxqAP+jhGusLAQFosFqampkuOpqak4dOiQT++Rn5+PCRMmAKhdZTJ9+nT0798/4GMNd4G41+RdIO7z6dOnce+99wqFxA8//DB69uzZEMMNW4G4zxs3bsSXX36JXr16CbUOS5Ys4b12Eqi/HaNGjcKePXtQWVmJNm3aYOnSpRg8eHCghxsxfLnvarUar7/+OkaOHAmr1Yonn3yyQVZVMrgJgvbt22PPnj3BHkaTc9dddwV7CBFrwIAByMnJCfYwIt7QoUNhtVqDPYwmY9WqVcEeQkS68cYbceONNzboZ3Bayk/JyclQqVQuxZL5+flo2bJlkEYVmXivGwfvc+PgfW48vNfBEUr3ncGNn7RaLfr27YvVq1cLx6xWK1avXs10ZYDxXjcO3ufGwfvceHivgyOU7junpWRUVFTg2LFjwvOTJ08iJycHSUlJaNu2LWbOnImpU6eiX79+GDBgABYsWIDKykpMmzYtiKMOT7zXjYP3uXHwPjce3uvgCJv7HvD1VxFgzZo1NgAuP1OnThXO+de//mVr27atTavV2gYMGGDbsmVL8AYcxnivGwfvc+PgfW48vNfBES73nb2liIiIKKKw5oaIiIgiCoMbIiIiiigMboiIiCiiMLghIiKiiMLghoiIiCIKgxsiIiKKKAxuiIiIKKIwuCEiIqKIwuCGiMJKZmYmFixYEOxhEFEIY3BDRC7uuusu3HzzzcEehqzt27fj3nvvbfDPyczMhEKhgEKhQHR0NHr27IlFixb5/T4KhQLLly8P/ACJyC0GN0QUEkwmk0/npaSkIDo6uoFHU2vu3LnIy8vD/v37cccdd2D69On4+eefG+Wziaj+GNwQkd/279+PsWPHIjY2FqmpqbjzzjtRWFgovL5ixQoMHToUiYmJaN68OW644QYcP35ceP3UqVNQKBT48ssvMXz4cOj1enz66adCxui1115Dq1at0Lx5czz00EOSwMd5WkqhUGDRokWYMGECoqOj0alTJ3z//feS8X7//ffo1KkT9Ho9Ro4ciY8++ggKhQIlJSUef8+4uDi0bNkS7du3x1//+lckJSVh5cqVwuvbt2/H6NGjkZycjISEBAwfPhy7du2SjBUAJkyYAIVCITwHgO+++w59+vSBXq9H+/btMWfOHJjNZl9uPxF5weCGiPxSUlKCq6++GtnZ2dixYwdWrFiB/Px83HrrrcI5lZWVmDlzJnbs2IHVq1dDqVRiwoQJsFqtkvd66qmn8Oijj+LgwYMYM2YMAGDNmjU4fvw41qxZg48++giLFy/G4sWLPY5pzpw5uPXWW7F3716MGzcOt99+O4qKigAAJ0+exC233IKbb74Ze/bswX333YdnnnnGr9/ZarXim2++QXFxMbRarXC8vLwcU6dOxYYNG7BlyxZ06tQJ48aNQ3l5OYDa4AcAPvzwQ+Tl5QnP169fjylTpuDRRx/FgQMH8M4772Dx4sV46aWX/BoXEbnR6H3IiSjkTZ061XbTTTfJvvbiiy/arr32Wsmx3NxcGwDb4cOHZa+5ePGiDYBt3759NpvNZjt58qQNgG3BggUun5uRkWEzm83Csf/7v/+z3XbbbcLzjIwM2/z584XnAGzPPvus8LyiosIGwPbzzz/bbDab7a9//autR48eks955plnbABsxcXF8jeg7nO0Wq0tJibGplarbQBsSUlJtqNHj7q9xmKx2OLi4mw//PCDZHzffvut5LxrrrnG9vLLL0uOLVmyxNaqVSu3701EvmPmhoj8smfPHqxZswaxsbHCT9euXQFAmHo6evQoJk2ahPbt2yM+Pl6Yjjlz5ozkvfr16+fy/t27d4dKpRKet2rVCgUFBR7H1KtXL+FxTEwM4uPjhWsOHz6M/v37S84fMGCAT7/rX/7yF+Tk5OC3337DwIEDMX/+fHTs2FF4PT8/H9OnT0enTp2QkJCA+Ph4VFRUuPyezvbs2YO5c+dK7uH06dORl5eHqqoqn8ZGRO6pgz0AIgovFRUVGD9+PP7+97+7vNaqVSsAwPjx45GRkYH33nsPaWlpsFqt6NGjB4xGo+T8mJgYl/fQaDSS5wqFwmU6KxDX+CI5ORkdO3ZEx44dsXTpUvTs2RP9+vVDt27dAABTp07FpUuX8M9//hMZGRnQ6XQYPHiwy+/prKKiAnPmzMHEiRNdXtPr9Zc9bqKmjsENEfmlT58++Oabb5CZmQm12vVPyKVLl3D48GG89957GDZsGABgw4YNjT1MQZcuXfDTTz9JjtlrX/yRnp6O2267DbNmzcJ3330HANi4cSPeeustjBs3DgCQm5srKawGagMvi8UiOdanTx8cPnxYkgUiosDhtBQRySotLUVOTo7kJzc3Fw899BCKioowadIkbN++HcePH8cvv/yCadOmwWKxoFmzZmjevDneffddHDt2DL/99htmzpwZtN/jvvvuw6FDh/DXv/4VR44cwVdffSUUKCsUCr/e69FHH8UPP/yAHTt2AAA6deqEJUuW4ODBg9i6dStuv/12REVFSa7JzMzE6tWrceHCBRQXFwMAZs+ejY8//hhz5szB77//joMHD+KLL77As88+e/m/MBExuCEieWvXrkV2drbkZ86cOUhLS8PGjRthsVhw7bXXomfPnnjssceQmJgIpVIJpVKJL774Ajt37kSPHj3w+OOP4x//+EfQfo927drh66+/xrJly9CrVy/85z//EVZL6XQ6v96rW7duuPbaazF79mwAwPvvv4/i4mL06dMHd955Jx555BG0aNFCcs3rr7+OlStXIj09HdnZ2QCAMWPG4Mcff8Svv/6K/v37Y9CgQZg/fz4yMjIC8BsTkcJms9mCPQgiosb00ksv4e2330Zubm6wh0JEDYA1N0QU8d566y30798fzZs3x8aNG/GPf/wDM2bMCPawiKiBMLghooh39OhR/O1vf0NRURHatm2LP//5z5g1a1awh0VEDYTTUkRERBRRWFBMREREEYXBDREREUUUBjdEREQUURjcEBERUURhcENEREQRhcENERERRRQGN0RERBRRGNwQERFRRGFwQ0RERBHl/wGf0VfAoQUh8QAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# steepest desceending part of graph 0.05"
      ],
      "metadata": {
        "id": "ak57br58sFlQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "g = torch.Generator().manual_seed(2147483647) # for reproducibility\n",
        "C = torch.randn((27, 10), generator=g)\n",
        "W1 = torch.randn((30, 200), generator=g)\n",
        "b1 = torch.randn(200, generator=g)\n",
        "W2 = torch.randn((200, 27), generator=g)\n",
        "b2 = torch.randn(27, generator=g)\n",
        "parameters = [C, W1, b1, W2, b2]\n",
        "\n",
        "for p in parameters:\n",
        "  p.requires_grad = True"
      ],
      "metadata": {
        "id": "iLj9MDZcsgKW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1 x 50,000 @ 0.05, 1 x 100,000 @ 0.01\n",
        "\n",
        "for i in range(100000):\n",
        "\n",
        "  # mini-batch\n",
        "  ix = torch.randint(0,Xtr.shape[0],(32,))\n",
        "\n",
        "  # forward pass\n",
        "  emb = C[Xtr[ix]] # (32, 3, 2) - this would be (20000, 3, 2) without mini-batch\n",
        "  h = torch.tanh(emb.view(-1, 30) @ W1 + b1) # (32, 100)\n",
        "  logits = h @ W2 + b2 # (32, 27)\n",
        "  loss = F.cross_entropy(logits, Ytr[ix])\n",
        "\n",
        "  # backward pass\n",
        "  for p in parameters:\n",
        "    p.grad = None\n",
        "  loss.backward()\n",
        "\n",
        "  lr = 0.01\n",
        "  # update\n",
        "  for p in parameters:\n",
        "    p.data += -lr* p.grad\n",
        "\n",
        "  # track stats\n",
        "  stepi.append(i)\n",
        "  lossi.append(loss.log10().item())"
      ],
      "metadata": {
        "id": "e24lDRMJsZJd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# quickly get the loss on training set\n",
        "emb = C[Xtr] # (32, 3, 2)\n",
        "h = torch.tanh(emb.view(-1, 30) @ W1 + b1) # (32, 100)\n",
        "logits = h @ W2 + b2 # (32, 27)\n",
        "loss = F.cross_entropy(logits, Ytr)\n",
        "print(loss.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dxrEpDPFsrLh",
        "outputId": "e3baaa99-7e35-41b5-d056-3379e785e3cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.2061283588409424\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# quickly get the loss on training set\n",
        "emb = C[Xdev] # (32, 3, 2)\n",
        "h = torch.tanh(emb.view(-1, 30) @ W1 + b1) # (32, 100)\n",
        "logits = h @ W2 + b2 # (32, 27)\n",
        "loss = F.cross_entropy(logits, Ydev)\n",
        "print(loss.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61_2AJG3srzZ",
        "outputId": "38140520-ce09-4618-bce4-802a5a46c5bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.226166009902954\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# better validation loss with 0.1 and then 0.01"
      ],
      "metadata": {
        "id": "JxKvoxaLt1c1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tuning the Batch size\n",
        "\n",
        "Batch size is a crucial hyperparameter in training neural networks. It determines the number of samples that are used to compute the gradient and update the model parameters in each iteration.\n",
        "\n",
        "Intuition:\n",
        "\n",
        "1. Small Batch Size:\n",
        "   - More noise in the gradient estimate, which can sometimes help escape local minima.\n",
        "   - More frequent parameter updates, which can lead to faster convergence.\n",
        "   - Less memory required, allowing for larger models or higher resolutions.\n",
        "   - However, it can lead to less stable training and require more careful tuning of the learning rate.\n",
        "\n",
        "2. Large Batch Size:\n",
        "   - More accurate gradient estimate, leading to more stable training and convergence.\n",
        "   - Better utilization of hardware (GPUs), leading to faster training.\n",
        "   - However, it can require more memory, limiting model size or resolution.\n",
        "   - It might converge to sharper minima, which can hurt generalization.\n",
        "\n",
        "How to adjust the batch size:\n",
        "\n",
        "1. **Start with a reasonable default**: Typically, a batch size of 32 or 64 is a good starting point.\n",
        "\n",
        "2. **Increase the batch size**: Gradually increase the batch size while monitoring the training and validation performance. If you notice that the model is training faster without a significant drop in performance, you can keep increasing the batch size.\n",
        "\n",
        "3. **Consider your hardware**: If you're running out of memory, you might need to reduce the batch size. Conversely, if you have a lot of available memory, you could try increasing the batch size to speed up training.\n",
        "\n",
        "4. **Tune other hyperparameters**: When you change the batch size, you might also need to adjust the learning rate. A common practice is to scale the learning rate linearly with the batch size.\n",
        "\n",
        "5. **Experiment**: The optimal batch size can depend on the specific problem, dataset, and model architecture. Don't be afraid to experiment with different batch sizes to find the best one for your situation.\n",
        "\n",
        "Let's think step-by-step:\n",
        "\n",
        "1. Start with a default batch size (e.g., 32 or 64).\n",
        "2. Increase the batch size gradually, observing the effects on training speed and performance.\n",
        "3. Adjust the learning rate as you change the batch size. You can try scaling the learning rate linearly with the batch size.\n",
        "4. Monitor the training and validation performance, and choose the batch size that provides a good balance between training speed and performance.\n",
        "5. Consider your hardware limitations and available memory when selecting the batch size.\n",
        "\n",
        "Remember that finding the optimal batch size might require some experimentation and fine-tuning. Keep in mind the trade-offs between small and large batch sizes and adjust other hyperparameters as needed."
      ],
      "metadata": {
        "id": "Gdmchce1u5pz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# let's try 64\n",
        "\n",
        "g = torch.Generator().manual_seed(2147483647) # for reproducibility\n",
        "C = torch.randn((27, 10), generator=g)\n",
        "W1 = torch.randn((30, 200), generator=g)\n",
        "b1 = torch.randn(200, generator=g)\n",
        "W2 = torch.randn((200, 27), generator=g)\n",
        "b2 = torch.randn(27, generator=g)\n",
        "parameters = [C, W1, b1, W2, b2]\n",
        "\n",
        "for p in parameters:\n",
        "  p.requires_grad = True"
      ],
      "metadata": {
        "id": "c9uERMJzvR-Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1 x 50,000 @ 0.2, 1 x 100,000 @ 0.02\n",
        "\n",
        "for i in range(150000):\n",
        "\n",
        "  # mini-batch\n",
        "  ix = torch.randint(0,Xtr.shape[0],(64,))\n",
        "\n",
        "  # forward pass\n",
        "  emb = C[Xtr[ix]] # (32, 3, 2) - this would be (20000, 3, 2) without mini-batch\n",
        "  h = torch.tanh(emb.view(-1, 30) @ W1 + b1) # (32, 100)\n",
        "  logits = h @ W2 + b2 # (32, 27)\n",
        "  loss = F.cross_entropy(logits, Ytr[ix])\n",
        "\n",
        "  # backward pass\n",
        "  for p in parameters:\n",
        "    p.grad = None\n",
        "  loss.backward()\n",
        "\n",
        "  lr1 = 0.2\n",
        "  lr2 = 0.02\n",
        "\n",
        "  if i < 50000:\n",
        "    lr = lr1\n",
        "  else:\n",
        "    lr = lr2\n",
        "  # update\n",
        "  for p in parameters:\n",
        "    p.data += -lr* p.grad\n",
        "\n",
        "  # track stats\n",
        "  stepi.append(i)\n",
        "  lossi.append(loss.log10().item())"
      ],
      "metadata": {
        "id": "cNJ8PY1GvdZV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# quickly get the loss on training set\n",
        "emb = C[Xtr] # (32, 3, 2)\n",
        "h = torch.tanh(emb.view(-1, 30) @ W1 + b1) # (32, 100)\n",
        "logits = h @ W2 + b2 # (32, 27)\n",
        "loss = F.cross_entropy(logits, Ytr)\n",
        "print(loss.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xvh_PhQ5vff4",
        "outputId": "d7e39ec0-d388-475b-a234-c4c213c434eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.111565351486206\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# quickly get the loss on training set\n",
        "emb = C[Xdev] # (32, 3, 2)\n",
        "h = torch.tanh(emb.view(-1, 30) @ W1 + b1) # (32, 100)\n",
        "logits = h @ W2 + b2 # (32, 27)\n",
        "loss = F.cross_entropy(logits, Ydev)\n",
        "print(loss.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7pz6SY0SvhwF",
        "outputId": "4e9270bc-cbe4-4815-be82-111c4dcfe5df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.1568567752838135\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# best loss yet. let's try 128"
      ],
      "metadata": {
        "id": "NP8xevVaxHAR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1 x 50,000 @ 0.2, 1 x 100,000 @ 0.02\n",
        "\n",
        "for i in range(150000):\n",
        "\n",
        "  # mini-batch\n",
        "  ix = torch.randint(0,Xtr.shape[0],(128,))\n",
        "\n",
        "  # forward pass\n",
        "  emb = C[Xtr[ix]] # (32, 3, 2) - this would be (20000, 3, 2) without mini-batch\n",
        "  h = torch.tanh(emb.view(-1, 30) @ W1 + b1) # (32, 100)\n",
        "  logits = h @ W2 + b2 # (32, 27)\n",
        "  loss = F.cross_entropy(logits, Ytr[ix])\n",
        "\n",
        "  # backward pass\n",
        "  for p in parameters:\n",
        "    p.grad = None\n",
        "  loss.backward()\n",
        "\n",
        "  lr1 = 0.4\n",
        "  lr2 = 0.04\n",
        "\n",
        "  if i < 50000:\n",
        "    lr = lr1\n",
        "  else:\n",
        "    lr = lr2\n",
        "  # update\n",
        "  for p in parameters:\n",
        "    p.data += -lr* p.grad\n",
        "\n",
        "  # track stats\n",
        "  stepi.append(i)\n",
        "  lossi.append(loss.log10().item())"
      ],
      "metadata": {
        "id": "wiWyo3PKxAKD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# quickly get the loss on training set\n",
        "emb = C[Xtr] # (32, 3, 2)\n",
        "h = torch.tanh(emb.view(-1, 30) @ W1 + b1) # (32, 100)\n",
        "logits = h @ W2 + b2 # (32, 27)\n",
        "loss = F.cross_entropy(logits, Ytr)\n",
        "print(loss.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LoSBpt9Xxybi",
        "outputId": "165ecf95-e72f-4f2c-fecf-817d768ff19a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.0567314624786377\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# quickly get the loss on training set\n",
        "emb = C[Xdev] # (32, 3, 2)\n",
        "h = torch.tanh(emb.view(-1, 30) @ W1 + b1) # (32, 100)\n",
        "logits = h @ W2 + b2 # (32, 27)\n",
        "loss = F.cross_entropy(logits, Ydev)\n",
        "print(loss.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sr_nK9oBx3wn",
        "outputId": "45c1ce3a-c564-4267-b935-a71361dd90ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.1286516189575195\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# lowest loss yet. Change starting learning rate from 0.4 to 0.2.\n",
        "\n",
        "# 1 x 50,000 @ 0.2, 1 x 100,000 @ 0.02\n",
        "\n",
        "for i in range(150000):\n",
        "\n",
        "  # mini-batch\n",
        "  ix = torch.randint(0,Xtr.shape[0],(128,))\n",
        "\n",
        "  # forward pass\n",
        "  emb = C[Xtr[ix]] # (32, 3, 2) - this would be (20000, 3, 2) without mini-batch\n",
        "  h = torch.tanh(emb.view(-1, 30) @ W1 + b1) # (32, 100)\n",
        "  logits = h @ W2 + b2 # (32, 27)\n",
        "  loss = F.cross_entropy(logits, Ytr[ix])\n",
        "\n",
        "  # backward pass\n",
        "  for p in parameters:\n",
        "    p.grad = None\n",
        "  loss.backward()\n",
        "\n",
        "  lr1 = 0.2\n",
        "  lr2 = 0.04\n",
        "\n",
        "  if i < 50000:\n",
        "    lr = lr1\n",
        "  else:\n",
        "    lr = lr2\n",
        "  # update\n",
        "  for p in parameters:\n",
        "    p.data += -lr* p.grad\n",
        "\n",
        "  # track stats\n",
        "  stepi.append(i)\n",
        "  lossi.append(loss.log10().item())"
      ],
      "metadata": {
        "id": "-DhMiV4lx9M-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# quickly get the loss on training set\n",
        "emb = C[Xtr] # (32, 3, 2)\n",
        "h = torch.tanh(emb.view(-1, 30) @ W1 + b1) # (32, 100)\n",
        "logits = h @ W2 + b2 # (32, 27)\n",
        "loss = F.cross_entropy(logits, Ytr)\n",
        "print(loss.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x4jtxQem6Uhu",
        "outputId": "c962aabf-d630-4416-e4d5-631b60475e89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.11159086227417\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# quickly get the loss on training set\n",
        "emb = C[Xdev] # (32, 3, 2)\n",
        "h = torch.tanh(emb.view(-1, 30) @ W1 + b1) # (32, 100)\n",
        "logits = h @ W2 + b2 # (32, 27)\n",
        "loss = F.cross_entropy(logits, Ydev)\n",
        "print(loss.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r1gwj9_56XHm",
        "outputId": "ef18eba8-2dfd-473d-e407-65461b3113ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.161386728286743\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 256\n",
        "\n",
        "for i in range(150000):\n",
        "\n",
        "  # mini-batch\n",
        "  ix = torch.randint(0,Xtr.shape[0],(256,))\n",
        "\n",
        "  # forward pass\n",
        "  emb = C[Xtr[ix]] # (32, 3, 2) - this would be (20000, 3, 2) without mini-batch\n",
        "  h = torch.tanh(emb.view(-1, 30) @ W1 + b1) # (32, 100)\n",
        "  logits = h @ W2 + b2 # (32, 27)\n",
        "  loss = F.cross_entropy(logits, Ytr[ix])\n",
        "\n",
        "  # backward pass\n",
        "  for p in parameters:\n",
        "    p.grad = None\n",
        "  loss.backward()\n",
        "\n",
        "  lr1 = 0.4\n",
        "  lr2 = 0.04\n",
        "\n",
        "  if i < 50000:\n",
        "    lr = lr1\n",
        "  else:\n",
        "    lr = lr2\n",
        "  # update\n",
        "  for p in parameters:\n",
        "    p.data += -lr* p.grad\n",
        "\n",
        "  # track stats\n",
        "  stepi.append(i)\n",
        "  lossi.append(loss.log10().item())"
      ],
      "metadata": {
        "id": "HRzyGPwb6exE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# quickly get the loss on training set\n",
        "emb = C[Xtr] # (32, 3, 2)\n",
        "h = torch.tanh(emb.view(-1, 30) @ W1 + b1) # (32, 100)\n",
        "logits = h @ W2 + b2 # (32, 27)\n",
        "loss = F.cross_entropy(logits, Ytr)\n",
        "print(loss.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z3hN9mgq7Noy",
        "outputId": "9ff6ee80-5666-463a-890d-b7f87f69a2b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.0543265342712402\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# quickly get the loss on training set\n",
        "emb = C[Xdev] # (32, 3, 2)\n",
        "h = torch.tanh(emb.view(-1, 30) @ W1 + b1) # (32, 100)\n",
        "logits = h @ W2 + b2 # (32, 27)\n",
        "loss = F.cross_entropy(logits, Ydev)\n",
        "print(loss.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uw6WFqKD7P4S",
        "outputId": "2ac7643c-d593-4aef-dfbd-e7f9a9485cf1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.1247036457061768\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# going forward with batch size 256"
      ],
      "metadata": {
        "id": "ipxqUHn08wi4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Batch size and the training process\n",
        "\n",
        "Batch size has several effects on the training process:\n",
        "\n",
        "1. **Computation Speed**: Larger batches can be more computationally efficient because they can take better advantage of parallelism in modern hardware (GPUs). However, this benefit plateaus at a certain point, after which increasing the batch size may not yield significant improvements in computational speed.\n",
        "\n",
        "2. **Memory Usage**: Larger batches require more memory because you need to store more data at once. If the batch size is too large, you might exceed your GPU or RAM capacity, resulting in out-of-memory errors.\n",
        "\n",
        "3. **Gradient Quality**: Larger batches provide a more accurate estimate of the gradient. In contrast, smaller batches provide a noisier estimate of the gradient, which can sometimes be beneficial because it can help escape local minima and explore the loss landscape more broadly. However, too much noise can hinder convergence.\n",
        "\n",
        "4. **Generalization**: Smaller batches tend to provide better generalization performance (better test set accuracy), possibly due to the implicit regularization introduced by the noisier gradients. However, training with small batches can be slower (in terms of wall-clock time) because it requires more parameter updates.\n",
        "\n",
        "5. **Epoch Duration**: An epoch is defined as one pass through the entire training dataset. Larger batches mean fewer iterations per epoch, so each epoch will be faster. However, you might need more epochs to converge because you're updating the parameters less frequently.\n",
        "\n",
        "6. **Learning Rate and Convergence**: The choice of batch size affects the optimal learning rate and the convergence properties of the training process. Typically, larger batches allow for larger learning rates, but the relationship is not strictly linear, and the optimal learning rate for a given batch size may depend on other factors as well.\n",
        "\n",
        "As a seasoned ML practitioner, it is essential to:\n",
        "\n",
        "- Understand the trade-offs associated with different batch sizes.\n",
        "- Monitor the training process and adjust the batch size if necessary (e.g., if the model is not converging or if you're running out of memory).\n",
        "- Consider using techniques like gradient accumulation (where you compute the gradients for several small batches and then update the parameters) if you want to benefit from large-batch training but are limited by memory capacity.\n",
        "- Experiment with different batch sizes to find the best configuration for your specific problem and hardware setup."
      ],
      "metadata": {
        "id": "ir4fmRYm8RKv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Which batch size?\n",
        "\n",
        "If you get similar low loss at both batch sizes of 64 and 256, you might want to consider the following factors to make your decision:\n",
        "\n",
        "1. **Training Speed**: If the training speed at batch size 256 is significantly faster than at batch size 64, you might prefer to use 256. Larger batch sizes can be more efficient due to better utilization of parallelism in modern GPUs.\n",
        "\n",
        "2. **Memory Usage**: If you're close to the memory limits of your hardware with batch size 256, you might prefer to use 64 to avoid potential out-of-memory errors, especially if you plan to increase the model size or use more data in the future.\n",
        "\n",
        "3. **Generalization Performance**: Sometimes, smaller batches can lead to better generalization on the validation or test set, even if the training loss is similar. You might want to check the performance of your model on a validation set for both batch sizes.\n",
        "\n",
        "4. **Stability**: If the training process is more stable (less fluctuation in loss) at one of the batch sizes, you might prefer to use that one.\n",
        "\n",
        "5. **Learning Rate**: The optimal learning rate can depend on the batch size. If you have already tuned the learning rate for one of the batch sizes, you might prefer to stick with that one.\n",
        "\n",
        "6. **Future Scalability**: If you plan to scale up your experiments (e.g., larger models or more data), it might be beneficial to use the larger batch size if your hardware can handle it, as it could lead to more efficient training in those scenarios.\n",
        "\n",
        "In summary, the choice between batch sizes of 64 and 256 depends on your specific circumstances, including hardware constraints, training speed, generalization performance, and future plans. It's essential to consider these factors and possibly run some additional experiments to make an informed decision."
      ],
      "metadata": {
        "id": "tvbNjTVU8df7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Signs of underfitting or overfitting\n",
        "\n",
        "A seasoned ML practitioner would look for signs of underfitting or overfitting by analyzing the learning curves and performance metrics of the model on both the training and validation data. Here are some step-by-step guidelines:\n",
        "\n",
        "1. **Plot Learning Curves**: Plot the training and validation loss (and optionally accuracy) as a function of the number of training epochs or iterations. Analyze the behavior of these curves.\n",
        "\n",
        "   a. **Underfitting**: If both the training and validation losses are high and similar, the model might be underfitting. This indicates that the model is too simple to capture the underlying patterns in the data.\n",
        "   b. **Overfitting**: If the training loss is much lower than the validation loss and the validation loss starts increasing after a certain point (while the training loss continues to decrease), the model might be overfitting. This indicates that the model is too complex and is fitting to the noise in the training data.\n",
        "\n",
        "2. **Evaluate Performance Metrics**: Calculate performance metrics such as accuracy, precision, recall, F1-score, or area under the ROC curve (AUC) on both the training and validation datasets. Compare these metrics.\n",
        "\n",
        "   a. **Underfitting**: If the performance metrics are poor on both the training and validation data, the model might be underfitting.\n",
        "   b. **Overfitting**: If the performance metrics are excellent on the training data but significantly worse on the validation data, the model might be overfitting.\n",
        "\n",
        "3. **Inspect Model Predictions**: Manually inspect some of the model's predictions on the training and validation data. Check whether the errors are systematic or random.\n",
        "\n",
        "   a. **Underfitting**: If the model makes systematic errors on both the training and validation data, it might be underfitting.\n",
        "   b. **Overfitting**: If the model makes random errors only on the validation data, it might be overfitting.\n",
        "\n",
        "4. **Complexity of the Model**: Consider the complexity of the model relative to the amount of data available. A model with too many parameters relative to the size of the training data is more likely to overfit.\n",
        "\n",
        "5. **Early Stopping**: Monitor the validation loss during training. If the validation loss starts to increase (while the training loss continues to decrease), it might be a sign of overfitting. In this case, you can stop the training early to prevent overfitting.\n",
        "\n",
        "6. **Regularization Techniques**: If you suspect overfitting, you can apply regularization techniques like L1/L2 regularization, dropout, or data augmentation. If these techniques improve the validation performance, it is an indication that the model was overfitting.\n",
        "\n",
        "Remember that underfitting and overfitting are part of the bias-variance trade-off. A seasoned ML practitioner would balance model complexity and data availability to achieve a model that generalizes well to new data."
      ],
      "metadata": {
        "id": "qs5R03iT-GSQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "g = torch.Generator().manual_seed(2147483647) # for reproducibility\n",
        "C = torch.randn((27, 10), generator=g)\n",
        "W1 = torch.randn((30, 200), generator=g)\n",
        "b1 = torch.randn(200, generator=g)\n",
        "W2 = torch.randn((200, 27), generator=g)\n",
        "b2 = torch.randn(27, generator=g)\n",
        "parameters = [C, W1, b1, W2, b2]\n",
        "\n",
        "for p in parameters:\n",
        "  p.requires_grad = True"
      ],
      "metadata": {
        "id": "q9fPswhyADZw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_lossi = []\n",
        "stepi = []\n",
        "lossi = []"
      ],
      "metadata": {
        "id": "N5WNImHpAgbX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "N = 5000\n",
        "\n",
        "for i in range(150000):\n",
        "\n",
        "  # mini-batch\n",
        "  ix = torch.randint(0,Xtr.shape[0],(256,))\n",
        "\n",
        "  # forward pass\n",
        "  emb = C[Xtr[ix]] # (32, 3, 2) - this would be (20000, 3, 2) without mini-batch\n",
        "  h = torch.tanh(emb.view(-1, 30) @ W1 + b1) # (32, 100)\n",
        "  logits = h @ W2 + b2 # (32, 27)\n",
        "  loss = F.cross_entropy(logits, Ytr[ix])\n",
        "\n",
        "  # Compute validation loss (optional: only do this every N iterations)\n",
        "  if i % N == 0:\n",
        "      with torch.no_grad():\n",
        "          emb = C[Xdev]\n",
        "          h = torch.tanh(emb.view(-1, 30) @ W1 + b1)\n",
        "          logits = h @ W2 + b2\n",
        "          val_loss = F.cross_entropy(logits, Ydev)\n",
        "          val_lossi.append(val_loss.log10().item())\n",
        "\n",
        "  # backward pass\n",
        "  for p in parameters:\n",
        "    p.grad = None\n",
        "  loss.backward()\n",
        "\n",
        "  lr1 = 0.4\n",
        "  lr2 = 0.04\n",
        "\n",
        "  if i < 50000:\n",
        "    lr = lr1\n",
        "  else:\n",
        "    lr = lr2\n",
        "  # update\n",
        "  for p in parameters:\n",
        "    p.data += -lr* p.grad\n",
        "\n",
        "  # track stats\n",
        "  stepi.append(i)\n",
        "  lossi.append(loss.log10().item())"
      ],
      "metadata": {
        "id": "Gd-3ZH9R_7W3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(stepi, lossi, label='Training Loss')\n",
        "plt.plot(stepi[:len(val_lossi)], val_lossi, label='Validation Loss', linestyle='--')\n",
        "plt.xlabel('Training Iteration')\n",
        "plt.ylabel('Loss (log10 scale)')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "ZT28GB7LA1Ee",
        "outputId": "af4b6630-2a3c-44cc-d7e9-8a235b30089b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Convert the loss data to a pandas Series\n",
        "train_loss_series = pd.Series(lossi)\n",
        "val_loss_series = pd.Series(val_lossi)\n",
        "\n",
        "# Use a moving average to smooth the data\n",
        "window_size = 500  # Set the window size for the moving average\n",
        "smoothed_train_loss = train_loss_series.rolling(window=window_size).mean()\n",
        "smoothed_val_loss = val_loss_series.rolling(window=window_size).mean()\n",
        "\n",
        "# Plot the smoothed data\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(stepi[window_size - 1:], smoothed_train_loss[window_size - 1:], label='Training Loss (Smoothed)')\n",
        "plt.plot(stepi[:len(smoothed_val_loss)][window_size - 1:], smoothed_val_loss[window_size - 1:], label='Validation Loss (Smoothed)', linestyle='--')\n",
        "plt.xlabel('Training Iteration')\n",
        "plt.ylabel('Loss (log10 scale)')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "IXz_hBbhDu3r",
        "outputId": "d9a61f15-720e-4b02-bb91-bf6d916e4422"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The change in the loss curve at 50,000 iterations, where you switch the learning rate from 0.4 to 0.04, suggests that the lower learning rate is having a significant impact on the optimization process.\n",
        "\n",
        "Here's what might be happening:\n",
        "\n",
        "1. **Initial Phase (0 to 50,000 iterations with learning rate 0.4)**: In this phase, the learning rate is relatively high, which allows the model to learn quickly and make large updates to the parameters. This is probably why you see a steady decrease in the loss during this phase - the model is rapidly learning and improving its performance.\n",
        "\n",
        "2. **Change Point (at 50,000 iterations)**: When you switch to a lower learning rate of 0.04, the updates to the parameters become smaller, which allows the model to fine-tune its parameters. The big drop in the loss at this point might be due to the model making a more precise adjustment to its parameters that it couldn't do with the higher learning rate.\n",
        "\n",
        "3. **Final Phase (50,000 to 150,000 iterations with learning rate 0.04)**: In this phase, the learning rate is low, which means the model is making smaller updates to the parameters. This is likely why the loss more or less plateaus - the model has already learned most of what it can from the data, and the lower learning rate is just fine-tuning the parameters.\n",
        "\n",
        "This pattern is a good example of the benefits of using a learning rate schedule in training a neural network. Starting with a high learning rate allows the model to learn quickly and make large improvements in performance. Then, switching to a lower learning rate allows the model to fine-tune its parameters and potentially achieve a better final performance.\n",
        "\n",
        "In summary, the change in the loss curve suggests that your learning rate schedule is effectively helping the model to learn quickly in the initial phase and then fine-tune its parameters in the later phase."
      ],
      "metadata": {
        "id": "od9-Ab_IFFTh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ways to make the graph less noisy\n",
        "\n",
        "There are several ways to make the graph less noisy and more useful:\n",
        "\n",
        "1. **Smoothing**: One common approach is to use a moving average to smooth the data. Instead of plotting every individual loss value, you can plot the average loss over a certain window of iterations.\n",
        "\n",
        "2. **Plot fewer data points**: Instead of plotting the loss at every iteration, you can plot it every \\(N\\) iterations. This will make the graph less cluttered and easier to read.\n",
        "\n",
        "3. **Use a logarithmic scale**: If the loss values span a wide range, using a logarithmic scale for the y-axis can make the graph more readable.\n",
        "\n",
        "4. **Separate the plots**: Instead of plotting both the training and validation loss on the same graph, you can plot them on separate graphs.\n",
        "\n",
        "5. **Change the line style**: You can use different line styles for the training and validation loss to make them easier to distinguish.\n",
        "\n",
        "6. **Highlight important points**: If there are specific points or ranges of interest in your graph (e.g., the point where the learning rate changes), you can highlight them with vertical lines, annotations, or other markers.\n",
        "\n",
        "Here's an example of how you can apply some of these suggestions to your code:\n",
        "\n",
        "```python\n",
        "import pandas as pd\n",
        "\n",
        "# Convert the loss data to a pandas Series\n",
        "train_loss_series = pd.Series(lossi)\n",
        "val_loss_series = pd.Series(val_lossi)\n",
        "\n",
        "# Use a moving average to smooth the data\n",
        "window_size = 500  # Set the window size for the moving average\n",
        "smoothed_train_loss = train_loss_series.rolling(window=window_size).mean()\n",
        "smoothed_val_loss = val_loss_series.rolling(window=window_size).mean()\n",
        "\n",
        "# Plot the smoothed data\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(stepi[window_size - 1:], smoothed_train_loss[window_size - 1:], label='Training Loss (Smoothed)')\n",
        "plt.plot(stepi[:len(smoothed_val_loss)][window_size - 1:], smoothed_val_loss[window_size - 1:], label='Validation Loss (Smoothed)', linestyle='--')\n",
        "plt.xlabel('Training Iteration')\n",
        "plt.ylabel('Loss (log10 scale)')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "In this example, we're using the `rolling` method from the pandas library to calculate the moving average of the loss data. We then plot the smoothed data instead of the raw data. This should result in a less noisy graph that is easier to interpret.\n",
        "\n",
        "---\n",
        "\n",
        "Instead of appending the loss at every iteration, you can append it every N iterations.\n",
        "\n",
        "```python\n",
        "N = 1000  # Record the loss every 1000 iterations\n",
        "\n",
        "stepi = []\n",
        "lossi = []\n",
        "val_lossi = []\n",
        "\n",
        "for i in range(150000):  \n",
        "    # mini-batch\n",
        "    ix = torch.randint(0,Xtr.shape[0],(256,))\n",
        "\n",
        "    # forward pass\n",
        "    emb = C[Xtr[ix]] # (32, 3, 2) - this would be (20000, 3, 2) without mini-batch\n",
        "    h = torch.tanh(emb.view(-1, 30) @ W1 + b1) # (32, 100)\n",
        "    logits = h @ W2 + b2 # (32, 27)\n",
        "    loss = F.cross_entropy(logits, Ytr[ix])\n",
        "\n",
        "    # backward pass\n",
        "    for p in parameters:\n",
        "        p.grad = None\n",
        "    loss.backward()\n",
        "\n",
        "    lr1 = 0.4\n",
        "    lr2 = 0.04  \n",
        "\n",
        "    if i < 50000:\n",
        "        lr = lr1\n",
        "    else:\n",
        "        lr = lr2\n",
        "\n",
        "    # update\n",
        "    for p in parameters:\n",
        "        p.data += -lr* p.grad\n",
        "\n",
        "    # track stats every N iterations\n",
        "    if i % N == 0:\n",
        "        stepi.append(i)\n",
        "        lossi.append(loss.log10().item())\n",
        "        # Optionally, record the validation loss here as well\n",
        "```\n",
        "\n",
        "This code modification will record the loss every 1000 iterations (as specified by the `N` variable), which will result in a less cluttered graph. You can adjust the value of `N` based on your needs."
      ],
      "metadata": {
        "id": "4kOV5uKoJi5t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tuning the hidden layer\n",
        "\n",
        "When tuning the hidden layer size in a neural network, a seasoned ML practitioner might follow these steps:\n",
        "\n",
        "1. **Understand the problem and data**: Before making any changes, understand the problem you're trying to solve and the characteristics of your data. If your data is complex and high-dimensional, it might benefit from a larger hidden layer.\n",
        "\n",
        "2. **Start with a reasonable default**: Begin with a hidden layer size that is commonly used in similar problems or based on prior experience. For example, if you're working on a standard problem, you might start with the baseline size of 100 neurons.\n",
        "\n",
        "3. **Evaluate the baseline model**: Train and evaluate the baseline model with the initial hidden layer size. Monitor the training and validation loss, and check for signs of underfitting or overfitting.\n",
        "\n",
        "4. **Increase or decrease the size**: Gradually increase the hidden layer size if you suspect underfitting (the model is too simple) or decrease it if you suspect overfitting (the model is too complex). It is a good practice to increase or decrease the size in multiples of 2 (e.g., 50, 100, 200, 400) to explore a wide range of sizes efficiently.\n",
        "\n",
        "5. **Re-evaluate the model**: Train and evaluate the model with the new hidden layer size. Compare the performance to the baseline model and check for improvements in the training and validation loss.\n",
        "\n",
        "6. **Regularization**: If you increase the hidden layer size and start observing overfitting, consider adding regularization techniques such as dropout, L1/L2 regularization, or early stopping to prevent overfitting while maintaining the increased capacity.\n",
        "\n",
        "7. **Iterate**: Repeat steps 4-6 until you find a hidden layer size that achieves the best balance between underfitting and overfitting on your training and validation data.\n",
        "\n",
        "8. **Consider other hyperparameters**: Keep in mind that changing the hidden layer size might affect other hyperparameters, such as the learning rate. You may need to re-tune other hyperparameters after adjusting the hidden layer size.\n",
        "\n",
        "9. **Cross-validation**: Optionally, use cross-validation to get a more robust estimate of the model's performance with different hidden layer sizes.\n",
        "\n",
        "10. **Final validation**: Once you have selected the best hidden layer size, train the model on the entire training set and evaluate it on the test set to get the final performance metrics.\n",
        "\n",
        "Remember that tuning the hidden layer size is an iterative process, and finding the optimal size might require multiple experiments. It is essential to consider the trade-offs between model complexity, training time, and generalization performance."
      ],
      "metadata": {
        "id": "V-ku_1x-Khb-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/karpathy/makemore/master/names.txt\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt # for making figures\n",
        "%matplotlib inline\n",
        "\n",
        "words = open(\"names.txt\", \"r\").read().splitlines()\n",
        "\n",
        "chars = sorted(list(set(''.join(words))))\n",
        "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
        "stoi['.'] = 0\n",
        "itos = {i:s for s,i in stoi.items()}\n",
        "\n",
        "# build the dataset\n",
        "block_size = 3 # context length: how many characters do we take to predict the next one?\n",
        "\n",
        "def build_dataset(words):\n",
        "  X, Y = [], []\n",
        "  for w in words:\n",
        "\n",
        "    #print(w)\n",
        "    context = [0] * block_size\n",
        "    for ch in w + '.':\n",
        "      ix = stoi[ch]\n",
        "      X.append(context)\n",
        "      Y.append(ix)\n",
        "      #print(''.join(itos[i] for i in context), '--->', itos[ix])\n",
        "      context = context[1:] + [ix] # crop and append\n",
        "\n",
        "  X = torch.tensor(X)\n",
        "  Y = torch.tensor(Y)\n",
        "  print(X.shape, Y.shape)\n",
        "  return X, Y\n",
        "\n",
        "import random\n",
        "random.seed(42)\n",
        "random.shuffle(words)\n",
        "n1 = int(0.8*len(words))\n",
        "n2 = int(0.9*len(words))\n",
        "\n",
        "Xtr, Ytr = build_dataset(words[:n1])\n",
        "Xdev, Ydev = build_dataset(words[n1:n2])\n",
        "Xte, Yte = build_dataset(words[n2:])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3-vlFjbwKqDI",
        "outputId": "b7793906-55fa-4805-8053-a1d513bfec52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-08-21 17:38:03--  https://raw.githubusercontent.com/karpathy/makemore/master/names.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 228145 (223K) [text/plain]\n",
            "Saving to: ‘names.txt’\n",
            "\n",
            "names.txt           100%[===================>] 222.80K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2023-08-21 17:38:03 (7.22 MB/s) - ‘names.txt’ saved [228145/228145]\n",
            "\n",
            "torch.Size([182625, 3]) torch.Size([182625])\n",
            "torch.Size([22655, 3]) torch.Size([22655])\n",
            "torch.Size([22866, 3]) torch.Size([22866])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# let's try 100 in hidden layer\n",
        "\n",
        "g = torch.Generator().manual_seed(2147483647) # for reproducibility\n",
        "C = torch.randn((27, 10), generator=g)\n",
        "W1 = torch.randn((30, 100), generator=g)\n",
        "b1 = torch.randn(100, generator=g)\n",
        "W2 = torch.randn((100, 27), generator=g)\n",
        "b2 = torch.randn(27, generator=g)\n",
        "parameters = [C, W1, b1, W2, b2]\n",
        "\n",
        "for p in parameters:\n",
        "  p.requires_grad = True"
      ],
      "metadata": {
        "id": "Iv1zmFU0L6rW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_lossi = []\n",
        "stepi = []\n",
        "lossi = []"
      ],
      "metadata": {
        "id": "z7f4-BygMShe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "for i in range(150000):\n",
        "\n",
        "  # mini-batch\n",
        "  ix = torch.randint(0,Xtr.shape[0],(256,))\n",
        "\n",
        "  # forward pass\n",
        "  emb = C[Xtr[ix]] # (32, 3, 2) - this would be (20000, 3, 2) without mini-batch\n",
        "  h = torch.tanh(emb.view(-1, 30) @ W1 + b1) # (32, 100)\n",
        "  logits = h @ W2 + b2 # (32, 27)\n",
        "  loss = F.cross_entropy(logits, Ytr[ix])\n",
        "\n",
        "  # backward pass\n",
        "  for p in parameters:\n",
        "    p.grad = None\n",
        "  loss.backward()\n",
        "\n",
        "  lr1 = 0.4\n",
        "  lr2 = 0.04\n",
        "\n",
        "  if i < 50000:\n",
        "    lr = lr1\n",
        "  else:\n",
        "    lr = lr2\n",
        "  # update\n",
        "  for p in parameters:\n",
        "    p.data += -lr* p.grad\n",
        "\n",
        "  # track stats\n",
        "  stepi.append(i)\n",
        "  lossi.append(loss.log10().item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C-0hH7q9LcNj",
        "outputId": "6ae831ef-fa74-48d1-8eb8-6ca3ffd6c19b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 2min 18s, sys: 260 ms, total: 2min 18s\n",
            "Wall time: 2min 21s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# quickly get the loss on training set\n",
        "emb = C[Xtr] # (32, 3, 2)\n",
        "h = torch.tanh(emb.view(-1, 30) @ W1 + b1) # (32, 100)\n",
        "logits = h @ W2 + b2 # (32, 27)\n",
        "loss = F.cross_entropy(logits, Ytr)\n",
        "print(loss.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V2gePDbALkP9",
        "outputId": "9c010043-c8b9-4932-8024-9f9977a04bd0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.108203411102295\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# quickly get the loss on val set\n",
        "emb = C[Xdev] # (32, 3, 2)\n",
        "h = torch.tanh(emb.view(-1, 30) @ W1 + b1) # (32, 100)\n",
        "logits = h @ W2 + b2 # (32, 27)\n",
        "loss = F.cross_entropy(logits, Ydev)\n",
        "print(loss.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pGytml2oLlTs",
        "outputId": "52ee246e-5c28-46ff-eecb-5b6ce4983f39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.1456985473632812\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# validation loss has increased\n",
        "\n",
        "# let's try 400 in hidden layer\n",
        "\n",
        "g = torch.Generator().manual_seed(2147483647) # for reproducibility\n",
        "C = torch.randn((27, 10), generator=g)\n",
        "W1 = torch.randn((30, 400), generator=g)\n",
        "b1 = torch.randn(400, generator=g)\n",
        "W2 = torch.randn((400, 27), generator=g)\n",
        "b2 = torch.randn(27, generator=g)\n",
        "parameters = [C, W1, b1, W2, b2]\n",
        "\n",
        "for p in parameters:\n",
        "  p.requires_grad = True"
      ],
      "metadata": {
        "id": "oN5pfikYNH0B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "for i in range(150000):\n",
        "\n",
        "  # mini-batch\n",
        "  ix = torch.randint(0,Xtr.shape[0],(256,))\n",
        "\n",
        "  # forward pass\n",
        "  emb = C[Xtr[ix]] # (32, 3, 2) - this would be (20000, 3, 2) without mini-batch\n",
        "  h = torch.tanh(emb.view(-1, 30) @ W1 + b1) # (32, 100)\n",
        "  logits = h @ W2 + b2 # (32, 27)\n",
        "  loss = F.cross_entropy(logits, Ytr[ix])\n",
        "\n",
        "  # backward pass\n",
        "  for p in parameters:\n",
        "    p.grad = None\n",
        "  loss.backward()\n",
        "\n",
        "  lr1 = 0.4\n",
        "  lr2 = 0.04\n",
        "\n",
        "  if i < 50000:\n",
        "    lr = lr1\n",
        "  else:\n",
        "    lr = lr2\n",
        "  # update\n",
        "  for p in parameters:\n",
        "    p.data += -lr* p.grad\n",
        "\n",
        "  # track stats\n",
        "  stepi.append(i)\n",
        "  lossi.append(loss.log10().item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cCcDnQvvNach",
        "outputId": "5435b990-9259-4b4d-d05b-82e0a203179a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 4min 52s, sys: 494 ms, total: 4min 53s\n",
            "Wall time: 4min 58s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# quickly get the loss on training set\n",
        "emb = C[Xtr] # (32, 3, 2)\n",
        "h = torch.tanh(emb.view(-1, 30) @ W1 + b1) # (32, 100)\n",
        "logits = h @ W2 + b2 # (32, 27)\n",
        "loss = F.cross_entropy(logits, Ytr)\n",
        "print(loss.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w3G6YxwTPank",
        "outputId": "d0fe8200-26a7-45d9-a504-66909426e74d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.0112102031707764\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# quickly get the loss on val set\n",
        "emb = C[Xdev] # (32, 3, 2)\n",
        "h = torch.tanh(emb.view(-1, 30) @ W1 + b1) # (32, 100)\n",
        "logits = h @ W2 + b2 # (32, 27)\n",
        "loss = F.cross_entropy(logits, Ydev)\n",
        "print(loss.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aPMbJ2I9Pe31",
        "outputId": "2f38bfb5-8487-4f0b-a978-0a44c1fa40e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.1260759830474854\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2.1247 is 256 with 200"
      ],
      "metadata": {
        "id": "hrpYK0PIPqk1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tuning the embeddings layer\n",
        "\n",
        "When fine-tuning the embeddings layer, the key is to balance the computational cost with the ability to capture complex relationships. Here's a plan to optimize the embeddings layer:\n",
        "\n",
        "1. **Start with the baseline model**: Begin with your current embeddings layer of 10 dimensions, which serves as the baseline model. Take note of the training and validation loss, as well as the training time.\n",
        "2. **Incrementally increase the embeddings size**: Gradually increase the embeddings dimension (e.g., to 20, 30, 40, etc.), and observe the effect on the training and validation loss, as well as the training time.\n",
        "3. **Evaluate the trade-off**: As you increase the embeddings size, the model may capture more complex relationships and improve the performance. However, this comes at the cost of increased computational requirements and training time. Evaluate the trade-off between performance improvement and computational cost.\n",
        "4. **Monitor overfitting**: As you increase the embeddings size, the model's capacity increases, which may lead to overfitting. Monitor the gap between training and validation loss. If the gap starts to widen, it's a sign of overfitting.\n",
        "5. **Regularization**: If you observe overfitting, consider adding regularization techniques such as dropout or weight decay to mitigate it.\n",
        "6. **Experiment with embeddings initialization**: Try different embeddings initialization strategies, such as random initialization, pre-trained embeddings, or a combination of both. Observe the impact on model performance.\n",
        "7. **Evaluate on downstream tasks**: After fine-tuning the embeddings layer, evaluate the model on downstream tasks that are relevant to your application. This will help you assess the quality of the embeddings in a more practical context.\n",
        "\n",
        "A seasoned ML practitioner would start with a reasonable range of embeddings sizes based on the dataset size and task complexity. They would then incrementally adjust the embeddings size while monitoring the trade-off between performance improvement and computational cost, and applying regularization techniques as needed. They would also evaluate the embeddings on relevant downstream tasks to assess their quality in a practical context.\n",
        "\n",
        "Let's think step-by-step:\n",
        "\n",
        "1. Start with the baseline model (10-dimensional embeddings).\n",
        "2. Incrementally increase the embeddings size (e.g., 20, 30, 40).\n",
        "3. Observe the effect on training and validation loss, as well as training time.\n",
        "4. Evaluate the trade-off between performance improvement and computational cost.\n",
        "5. Monitor overfitting by observing the gap between training and validation loss.\n",
        "6. Apply regularization techniques if overfitting is observed.\n",
        "7. Experiment with embeddings initialization strategies.\n",
        "8. Evaluate the fine-tuned embeddings on downstream tasks.\n",
        "\n",
        "Remember to perform these experiments in a systematic and organized manner to easily track the impact of each change on model performance."
      ],
      "metadata": {
        "id": "T1ff3ScIQpqu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# validation loss has increased\n",
        "\n",
        "g = torch.Generator().manual_seed(2147483647) # for reproducibility\n",
        "C = torch.randn((27, 5), generator=g)\n",
        "W1 = torch.randn((15, 200), generator=g)\n",
        "b1 = torch.randn(200, generator=g)\n",
        "W2 = torch.randn((200, 27), generator=g)\n",
        "b2 = torch.randn(27, generator=g)\n",
        "parameters = [C, W1, b1, W2, b2]\n",
        "\n",
        "for p in parameters:\n",
        "  p.requires_grad = True"
      ],
      "metadata": {
        "id": "HQlpFdPiQzL2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "for i in range(150000):\n",
        "\n",
        "  # mini-batch\n",
        "  ix = torch.randint(0,Xtr.shape[0],(256,))\n",
        "\n",
        "  # forward pass\n",
        "  emb = C[Xtr[ix]] # (32, 3, 2) - this would be (20000, 3, 2) without mini-batch\n",
        "  h = torch.tanh(emb.view(-1, 15) @ W1 + b1) # (32, 100)\n",
        "  logits = h @ W2 + b2 # (32, 27)\n",
        "  loss = F.cross_entropy(logits, Ytr[ix])\n",
        "\n",
        "  # backward pass\n",
        "  for p in parameters:\n",
        "    p.grad = None\n",
        "  loss.backward()\n",
        "\n",
        "  lr1 = 0.4\n",
        "  lr2 = 0.04\n",
        "\n",
        "  if i < 50000:\n",
        "    lr = lr1\n",
        "  else:\n",
        "    lr = lr2\n",
        "  # update\n",
        "  for p in parameters:\n",
        "    p.data += -lr* p.grad\n",
        "\n",
        "  # track stats\n",
        "  stepi.append(i)\n",
        "  lossi.append(loss.log10().item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1nVAyCMlQ7nc",
        "outputId": "d4598da0-b969-442f-9da0-ba0f5d38a135"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 3min 3s, sys: 363 ms, total: 3min 3s\n",
            "Wall time: 3min 12s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# quickly get the loss on training set\n",
        "emb = C[Xtr] # (32, 3, 2)\n",
        "h = torch.tanh(emb.view(-1, 15) @ W1 + b1) # (32, 100)\n",
        "logits = h @ W2 + b2 # (32, 27)\n",
        "loss = F.cross_entropy(logits, Ytr)\n",
        "print(loss.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jlhvGj7lRS6M",
        "outputId": "9c204e38-dfe8-43db-e336-cf68ac298262"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.108706474304199\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# quickly get the loss on val set\n",
        "emb = C[Xdev] # (32, 3, 2)\n",
        "h = torch.tanh(emb.view(-1, 15) @ W1 + b1) # (32, 100)\n",
        "logits = h @ W2 + b2 # (32, 27)\n",
        "loss = F.cross_entropy(logits, Ydev)\n",
        "print(loss.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6AI1uS9pRVid",
        "outputId": "ca545dde-3f65-4811-8d71-ba10d495fd11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.147738218307495\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# validation loss has increased\n",
        "\n",
        "g = torch.Generator().manual_seed(2147483647) # for reproducibility\n",
        "C = torch.randn((27, 20), generator=g)\n",
        "W1 = torch.randn((60, 200), generator=g)\n",
        "b1 = torch.randn(200, generator=g)\n",
        "W2 = torch.randn((200, 27), generator=g)\n",
        "b2 = torch.randn(27, generator=g)\n",
        "parameters = [C, W1, b1, W2, b2]\n",
        "\n",
        "for p in parameters:\n",
        "  p.requires_grad = True"
      ],
      "metadata": {
        "id": "VRAOvhlfTbP4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "for i in range(150000):\n",
        "\n",
        "  # mini-batch\n",
        "  ix = torch.randint(0,Xtr.shape[0],(256,))\n",
        "\n",
        "  # forward pass\n",
        "  emb = C[Xtr[ix]] # (32, 3, 2) - this would be (20000, 3, 2) without mini-batch\n",
        "  h = torch.tanh(emb.view(-1, 60) @ W1 + b1) # (32, 100)\n",
        "  logits = h @ W2 + b2 # (32, 27)\n",
        "  loss = F.cross_entropy(logits, Ytr[ix])\n",
        "\n",
        "  # backward pass\n",
        "  for p in parameters:\n",
        "    p.grad = None\n",
        "  loss.backward()\n",
        "\n",
        "  lr1 = 0.4\n",
        "  lr2 = 0.04\n",
        "\n",
        "  if i < 50000:\n",
        "    lr = lr1\n",
        "  else:\n",
        "    lr = lr2\n",
        "  # update\n",
        "  for p in parameters:\n",
        "    p.data += -lr* p.grad\n",
        "\n",
        "  # track stats\n",
        "  stepi.append(i)\n",
        "  lossi.append(loss.log10().item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rgC8KZBRTg43",
        "outputId": "e3f625f6-45aa-43bc-ba43-c4d5e2adc0bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 3min 57s, sys: 466 ms, total: 3min 57s\n",
            "Wall time: 4min 12s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# quickly get the loss on training set\n",
        "emb = C[Xtr] # (32, 3, 2)\n",
        "h = torch.tanh(emb.view(-1, 60) @ W1 + b1) # (32, 100)\n",
        "logits = h @ W2 + b2 # (32, 27)\n",
        "loss = F.cross_entropy(logits, Ytr)\n",
        "print(loss.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IwsS9wl1Tm6w",
        "outputId": "2f2ef814-8016-4bcd-8937-31de25a45c5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.020221710205078\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# quickly get the loss on val set\n",
        "emb = C[Xdev] # (32, 3, 2)\n",
        "h = torch.tanh(emb.view(-1, 60) @ W1 + b1) # (32, 100)\n",
        "logits = h @ W2 + b2 # (32, 27)\n",
        "loss = F.cross_entropy(logits, Ydev)\n",
        "print(loss.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tCkknjdATpJ1",
        "outputId": "416026f0-e127-4f10-bcc0-66d45aa5c5f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.120725154876709\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# smallest loss so far"
      ],
      "metadata": {
        "id": "8fRlSAjvU4a9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# finally get the loss on test set\n",
        "emb = C[Xte] # (32, 3, 2)\n",
        "h = torch.tanh(emb.view(-1, 60) @ W1 + b1) # (32, 100)\n",
        "logits = h @ W2 + b2 # (32, 27)\n",
        "loss = F.cross_entropy(logits, Yte)\n",
        "print(loss.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dgBgYWeYXBK-",
        "outputId": "d08fa8e1-683e-462e-8257-e36ce0306cc2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.1293997764587402\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# once more with embeddings of 40\n",
        "\n",
        "g = torch.Generator().manual_seed(2147483647) # for reproducibility\n",
        "C = torch.randn((27, 40), generator=g)\n",
        "W1 = torch.randn((120, 200), generator=g)\n",
        "b1 = torch.randn(200, generator=g)\n",
        "W2 = torch.randn((200, 27), generator=g)\n",
        "b2 = torch.randn(27, generator=g)\n",
        "parameters = [C, W1, b1, W2, b2]\n",
        "\n",
        "for p in parameters:\n",
        "  p.requires_grad = True"
      ],
      "metadata": {
        "id": "AKmX0-KhZeh0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "for i in range(150000):\n",
        "\n",
        "  # mini-batch\n",
        "  ix = torch.randint(0,Xtr.shape[0],(256,))\n",
        "\n",
        "  # forward pass\n",
        "  emb = C[Xtr[ix]] # (32, 3, 2) - this would be (20000, 3, 2) without mini-batch\n",
        "  h = torch.tanh(emb.view(-1, 120) @ W1 + b1) # (32, 100)\n",
        "  logits = h @ W2 + b2 # (32, 27)\n",
        "  loss = F.cross_entropy(logits, Ytr[ix])\n",
        "\n",
        "  # backward pass\n",
        "  for p in parameters:\n",
        "    p.grad = None\n",
        "  loss.backward()\n",
        "\n",
        "  lr1 = 0.4\n",
        "  lr2 = 0.04\n",
        "\n",
        "  if i < 50000:\n",
        "    lr = lr1\n",
        "  else:\n",
        "    lr = lr2\n",
        "  # update\n",
        "  for p in parameters:\n",
        "    p.data += -lr* p.grad\n",
        "\n",
        "  # track stats\n",
        "  stepi.append(i)\n",
        "  lossi.append(loss.log10().item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aDMN1BtqZj7e",
        "outputId": "95f26fde-20b4-4156-d765-975a13fa9751"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 4min 46s, sys: 522 ms, total: 4min 47s\n",
            "Wall time: 4min 56s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# quickly get the loss on training set\n",
        "emb = C[Xtr] # (32, 3, 2)\n",
        "h = torch.tanh(emb.view(-1, 120) @ W1 + b1) # (32, 100)\n",
        "logits = h @ W2 + b2 # (32, 27)\n",
        "loss = F.cross_entropy(logits, Ytr)\n",
        "print(loss.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZAWtccoFZpIg",
        "outputId": "86a68457-9770-4932-fff0-a9f43eb5bd84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.011589765548706\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# quickly get the loss on val set\n",
        "emb = C[Xdev] # (32, 3, 2)\n",
        "h = torch.tanh(emb.view(-1, 120) @ W1 + b1) # (32, 100)\n",
        "logits = h @ W2 + b2 # (32, 27)\n",
        "loss = F.cross_entropy(logits, Ydev)\n",
        "print(loss.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R09UZuzLZrXf",
        "outputId": "8362015d-5303-49b0-9fbc-845b83b8178f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.1243789196014404\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# finally get the loss on test set\n",
        "emb = C[Xte] # (32, 3, 2)\n",
        "h = torch.tanh(emb.view(-1, 120) @ W1 + b1) # (32, 100)\n",
        "logits = h @ W2 + b2 # (32, 27)\n",
        "loss = F.cross_entropy(logits, Yte)\n",
        "print(loss.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bj3k8-d1ZtaX",
        "outputId": "073221f9-33cc-4353-e1fb-848b1f7a72ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.1232595443725586\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sampling from the model\n",
        "g = torch.Generator().manual_seed(2147483647 + 10)\n",
        "\n",
        "for _ in range(20):\n",
        "\n",
        "    out = []\n",
        "    context = [0] * block_size # initialize with all ...\n",
        "    while True:\n",
        "      emb = C[torch.tensor([context])] # (1,block_size,d)\n",
        "      h = torch.tanh(emb.view(1, -1) @ W1 + b1)\n",
        "      logits = h @ W2 + b2\n",
        "      probs = F.softmax(logits, dim=1)\n",
        "      ix = torch.multinomial(probs, num_samples=1, generator=g).item()\n",
        "      context = context[1:] + [ix]\n",
        "      out.append(ix)\n",
        "      if ix == 0:\n",
        "        break\n",
        "\n",
        "    print(''.join(itos[i] for i in out))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CubJhhUPX_ge",
        "outputId": "0166fe6d-c417-4088-f449-8e83c2a454b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "montaymyah.\n",
            "see.\n",
            "medhayla.\n",
            "reish.\n",
            "jendraeg.\n",
            "adee.\n",
            "deelin.\n",
            "shi.\n",
            "jena.\n",
            "keiseananar.\n",
            "elyzion.\n",
            "kamin.\n",
            "shubergiairiel.\n",
            "kendreed.\n",
            "konnie.\n",
            "casubemard.\n",
            "ryyah.\n",
            "fael.\n",
            "yume.\n",
            "muskella.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Summary of Model Optimizations\n",
        "\n",
        "In this notebook, we developed a character-level neural network model to predict the next character in a sequence of characters. We used a dataset of names to train the model. The model consisted of an embedding layer, a hidden layer, and an output layer. We optimized the model by experimenting with various hyperparameters and training settings.\n",
        "\n",
        "## Steps taken to optimize the model:\n",
        "\n",
        "1. **Tuning the Learning Rate**: We experimented with various learning rates and used a learning rate schedule that starts with a higher learning rate and then decreases it after a certain number of iterations. The optimal learning rate was found to be 0.4.\n",
        "\n",
        "2. **Adjusting the Batch Size**: We experimented with different batch sizes and found that a batch size of 256 gave the best results in terms of training speed and model performance.\n",
        "\n",
        "3. **Tuning the Hidden Layer Size**: We experimented with different sizes for the hidden layer. After trying various sizes, we found that a hidden layer with 100 units provided the best trade-off between model capacity and computational cost.\n",
        "\n",
        "4. **Fine-tuning the Embeddings Layer**: We experimented with different embedding dimensions and found that an embedding dimension of 20 provided a good balance between capturing complex relationships and computational cost.\n",
        "\n",
        "5. **Monitoring Training and Validation Loss**: We tracked the training and validation loss throughout the training process to ensure that the model was learning effectively and not overfitting.\n",
        "\n",
        "## Final Model Configuration:\n",
        "\n",
        "- Embeddings: 40 dimensions\n",
        "- Batch size: 256\n",
        "- Learning rate: 0.4\n",
        "- Hidden layer: 100 units\n",
        "\n",
        "## Results:\n",
        "\n",
        "After optimizing the model, we achieved a test loss of 2.1232. This indicates that the model is capable of predicting the next character in a sequence with a reasonable degree of accuracy. The optimized model configuration and training settings allowed us to achieve this performance while keeping the computational cost manageable.\n",
        "\n",
        "In conclusion, the optimization steps taken in this notebook have improved the model's performance and made it more efficient. The final model can be used for tasks such as generating new names or completing partially entered names."
      ],
      "metadata": {
        "id": "HZu0K_PUXuvH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise 2:\n",
        "\n"
      ],
      "metadata": {
        "id": "4crJEv5ScC7x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`E02: I was not careful with the intialization of the network in this video. (1) What is the loss you'd get if the predicted probabilities at initialization were perfectly uniform? What loss do we achieve? (2) Can you tune the initialization to get a starting loss that is much more similar to (1)?`\n",
        "\n",
        "\n",
        "1. **Uniform Probabilities and Initial Loss**:\n",
        "    - The first part of the task is asking about the loss value if the model's predictions were perfectly uniform. This means that the model would assign equal probabilities to each possible character when trying to predict the next character in a sequence.\n",
        "    - You're also asked to determine the loss value that the current model achieves at initialization. This means you'll need to compute the loss value before the model has been trained at all, using the initial weights.\n",
        "    - The goal is to compare the loss from a perfectly uniform prediction with the initial loss of the model.\n",
        "\n",
        "2. **Tuning the Initialization**:\n",
        "    - The second part of the task is about adjusting the initialization of the network's weights to get a starting loss that's closer to the loss from a uniform prediction.\n",
        "    - In neural networks, the initial values of the weights can have a significant impact on training. If the weights are initialized poorly, the network might not learn effectively.\n",
        "    - You're being asked to experiment with different ways of initializing the weights to see if you can improve the starting loss.\n",
        "\n",
        "In summary, the task is asking you to analyze the initial loss of the model, compare it to the loss from a uniform prediction, and experiment with different weight initializations to try to improve the starting loss."
      ],
      "metadata": {
        "id": "EK9gfC6FxSOC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Xavier (Glorot) initialization\n",
        "\n",
        "In simple terms, Xavier initialization is a method to set the initial random weights of a neural network in a way that each neuron's output has a variance that is roughly the same across all layers. This helps to ensure that the weights are neither too small nor too large, which can help improve the model's performance during training."
      ],
      "metadata": {
        "id": "yg11yiItxbwE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "g = torch.Generator().manual_seed(2147483647) # for reproducibility\n",
        "C = torch.randn((27, 40), generator=g)\n",
        "W1 = torch.randn((120, 200), generator=g)\n",
        "b1 = torch.randn(200, generator=g)\n",
        "W2 = torch.randn((200, 27), generator=g)\n",
        "b2 = torch.randn(27, generator=g)\n",
        "parameters = [C, W1, b1, W2, b2]\n",
        "\n",
        "for p in parameters:\n",
        "  p.requires_grad = True"
      ],
      "metadata": {
        "id": "gPIftGkRcePJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  # mini-batch\n",
        "  ix = torch.randint(0,Xtr.shape[0],(256,))\n",
        "\n",
        "  # forward pass\n",
        "  emb = C[Xtr[ix]] # (32, 3, 2) - this would be (20000, 3, 2) without mini-batch\n",
        "  h = torch.tanh(emb.view(-1, 120) @ W1 + b1) # (32, 100)\n",
        "  logits = h @ W2 + b2 # (32, 27)\n",
        "  loss = F.cross_entropy(logits, Ytr[ix])"
      ],
      "metadata": {
        "id": "mf5BHPfqcozx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "esDXdNZQctIV",
        "outputId": "b40a182d-a231-4316-86ac-1a67ea5be9bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(27.3181, grad_fn=<NllLossBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the batch size and the number of classes (characters)\n",
        "batch_size = 256\n",
        "num_classes = 27\n",
        "\n",
        "# Create a tensor with equal probabilities for each character\n",
        "uniform_probs = torch.full((batch_size, num_classes), 1/num_classes)\n",
        "\n",
        "# Compute the cross-entropy loss using the uniform predictions and the true labels\n",
        "uniform_loss = F.cross_entropy(uniform_probs, Ytr[ix])\n",
        "\n",
        "print(\"Loss with uniform probabilities:\", uniform_loss.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KM0u8nhIdUf1",
        "outputId": "6f5a1489-7cb5-43d0-ac74-8451f3cbbebf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss with uniform probabilities: 3.295837163925171\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The random loss of 27.3181 indicates the loss value you get with the initial model parameters, which are randomly generated. The uniform loss of 3.2958 represents the loss value if the model were to predict equal probabilities for each character.\n",
        "\n",
        "Here's what these loss values mean:\n",
        "\n",
        "1. The high random loss suggests that the model's initial predictions are far from the true labels. The randomly initialized parameters are not providing meaningful predictions.\n",
        "2. The lower uniform loss shows the loss value if the model were to assign equal probabilities to each character. It serves as a baseline to compare with the initial loss.\n",
        "\n",
        "The difference between the two loss values indicates that the initial model parameters are not ideal. Ideally, the initial loss should be closer to the uniform loss, as this would indicate that the model starts with a more neutral prediction.\n",
        "\n",
        "To improve the initial loss, you can adjust the initialization of the model parameters. This is the second part of the task given by the lecturer. By tuning the initialization, you aim to get a starting loss that is closer to the uniform loss.\n",
        "\n",
        "Here are the next steps:\n",
        "\n",
        "1. Experiment with different initialization methods for the model parameters. You can try different initialization techniques like Xavier (Glorot) or He initialization.\n",
        "2. After modifying the initialization, recompute the initial loss and compare it with the uniform loss.\n",
        "3. Iterate this process until you find an initialization that brings the initial loss closer to the uniform loss.\n",
        "\n",
        "Remember, a better initialization can help the model to converge faster and reach a better local minimum during training."
      ],
      "metadata": {
        "id": "eo-A3rc-exnk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.init as init\n",
        "\n",
        "C = torch.randn((27, 40))\n",
        "W1 = torch.empty((120, 200))\n",
        "init.xavier_uniform_(W1) # Use xavier_normal_ for normal distribution\n",
        "b1 = torch.randn(200)\n",
        "W2 = torch.empty((200, 27))\n",
        "init.xavier_uniform_(W2) # Use xavier_normal_ for normal distribution\n",
        "b2 = torch.randn(27)\n",
        "parameters = [C, W1, b1, W2, b2]\n",
        "\n",
        "for p in parameters:\n",
        "    p.requires_grad = True"
      ],
      "metadata": {
        "id": "DgPK8Kfxfn9P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  # mini-batch\n",
        "  ix = torch.randint(0,Xtr.shape[0],(256,))\n",
        "\n",
        "  # forward pass\n",
        "  emb = C[Xtr[ix]] # (32, 3, 2) - this would be (20000, 3, 2) without mini-batch\n",
        "  h = torch.tanh(emb.view(-1, 120) @ W1 + b1) # (32, 100)\n",
        "  logits = h @ W2 + b2 # (32, 27)\n",
        "  loss = F.cross_entropy(logits, Ytr[ix])"
      ],
      "metadata": {
        "id": "6YMP5ncVgX8m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sobHIiCGgZh_",
        "outputId": "88687545-27b8-48aa-93c1-1989439af4c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(4.5342, grad_fn=<NllLossBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes, you can use the generator with the Xavier initialization, but it requires a slightly different approach. The `torch.nn.init` functions don't directly accept a generator argument, but you can use the generator to create random tensors with the desired properties, and then manually scale and shift them to achieve Xavier initialization.\n",
        "\n",
        "Here's how you can do it:\n",
        "\n",
        "1. Use the generator to create random tensors with elements drawn from a standard normal distribution.\n",
        "2. Scale the tensors by the square root of the inverse of the number of input features (the Xavier initialization factor).\n",
        "3. Use these tensors as your initial weights.\n",
        "\n",
        "This way, you can still use the generator to ensure reproducibility while achieving Xavier initialization for your weights."
      ],
      "metadata": {
        "id": "UinYkrDZhKuc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.init as init\n",
        "\n",
        "g = torch.Generator().manual_seed(2147483647)\n",
        "C = torch.randn((27, 40), generator=g)\n",
        "W1 = torch.randn((120, 200), generator=g) * torch.sqrt(torch.tensor(2.0 / (120 + 200)))\n",
        "b1 = torch.randn(200, generator=g)\n",
        "W2 = torch.randn((200, 27), generator=g) * torch.sqrt(torch.tensor(2.0 / (200 + 27)))\n",
        "b2 = torch.randn(27, generator=g)\n",
        "parameters = [C, W1, b1, W2, b2]\n",
        "\n",
        "for p in parameters:\n",
        "    p.requires_grad = True\n",
        "\n",
        "ix = torch.randint(0,Xtr.shape[0],(256,))\n",
        "\n",
        "# forward pass\n",
        "emb = C[Xtr[ix]] # (32, 3, 2) - this would be (20000, 3, 2) without mini-batch\n",
        "h = torch.tanh(emb.view(-1, 120) @ W1 + b1) # (32, 100)\n",
        "logits = h @ W2 + b2 # (32, 27)\n",
        "loss = F.cross_entropy(logits, Ytr[ix])\n",
        "\n",
        "loss\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dw8iJ44vhNS3",
        "outputId": "f727b2ed-b028-4eb0-ace3-65baf5ce31fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(4.7331, grad_fn=<NllLossBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# one tast full training with Xavier initialization\n",
        "\n",
        "import torch.nn.init as init\n",
        "\n",
        "g = torch.Generator().manual_seed(2147483647)\n",
        "C = torch.randn((27, 40), generator=g)\n",
        "W1 = torch.randn((120, 200), generator=g) * torch.sqrt(torch.tensor(2.0 / (120 + 200)))\n",
        "b1 = torch.randn(200, generator=g)\n",
        "W2 = torch.randn((200, 27), generator=g) * torch.sqrt(torch.tensor(2.0 / (200 + 27)))\n",
        "b2 = torch.randn(27, generator=g)\n",
        "parameters = [C, W1, b1, W2, b2]\n",
        "\n",
        "for p in parameters:\n",
        "    p.requires_grad = True\n"
      ],
      "metadata": {
        "id": "btzAITGshxqq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "for i in range(150000):\n",
        "\n",
        "  # mini-batch\n",
        "  ix = torch.randint(0,Xtr.shape[0],(256,))\n",
        "\n",
        "  # forward pass\n",
        "  emb = C[Xtr[ix]] # (32, 3, 2) - this would be (20000, 3, 2) without mini-batch\n",
        "  h = torch.tanh(emb.view(-1, 120) @ W1 + b1) # (32, 100)\n",
        "  logits = h @ W2 + b2 # (32, 27)\n",
        "  loss = F.cross_entropy(logits, Ytr[ix])\n",
        "\n",
        "  # backward pass\n",
        "  for p in parameters:\n",
        "    p.grad = None\n",
        "  loss.backward()\n",
        "\n",
        "  lr1 = 0.4\n",
        "  lr2 = 0.04\n",
        "\n",
        "  if i < 50000:\n",
        "    lr = lr1\n",
        "  else:\n",
        "    lr = lr2\n",
        "  # update\n",
        "  for p in parameters:\n",
        "    p.data += -lr* p.grad\n",
        "\n",
        "  # track stats\n",
        "  stepi.append(i)\n",
        "  lossi.append(loss.log10().item())\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T3TMUgS8hds-",
        "outputId": "df042a40-0e1d-4574-e869-11ff563aae46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 4min 50s, sys: 520 ms, total: 4min 51s\n",
            "Wall time: 5min 19s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "emb = C[Xtr] # (32, 3, 2)\n",
        "h = torch.tanh(emb.view(-1, 120) @ W1 + b1) # (32, 100)\n",
        "logits = h @ W2 + b2 # (32, 27)\n",
        "loss = F.cross_entropy(logits, Ytr)\n",
        "print(loss.item())"
      ],
      "metadata": {
        "id": "zH-ejCyCiOW8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emb = C[Xdev] # (32, 3, 2)\n",
        "h = torch.tanh(emb.view(-1, 120) @ W1 + b1) # (32, 100)\n",
        "logits = h @ W2 + b2 # (32, 27)\n",
        "loss = F.cross_entropy(logits, Ydev)\n",
        "print(loss.item())"
      ],
      "metadata": {
        "id": "W3PTRheUiPYk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emb = C[Xte] # (32, 3, 2)\n",
        "h = torch.tanh(emb.view(-1, 120) @ W1 + b1) # (32, 100)\n",
        "logits = h @ W2 + b2 # (32, 27)\n",
        "loss = F.cross_entropy(logits, Yte)\n",
        "print(loss.item())"
      ],
      "metadata": {
        "id": "A2xeKX8RiR-1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Glossary"
      ],
      "metadata": {
        "id": "my_qQhexwt1F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PyTorch indexing\n",
        "\n",
        "1. **X**:\n",
        "   - The variable `X` contains the input data for the character-level language model. It's a matrix with a shape of `[32, 3]`, which means it has 32 rows and 3 columns.\n",
        "   - Each row in `X` represents a context of 3 characters, where each character is represented by its integer index.\n",
        "\n",
        "2. **C**:\n",
        "   - The variable `C` is the embedding lookup table. It has a shape of `[27, 2]`, which means it contains 27 vectors (one for each character), and each vector is 2-dimensional.\n",
        "\n",
        "3. **Indexing with C[X]**:\n",
        "   - The expression `C[X]` uses the PyTorch multi-dimensional indexing feature to get the embedding vectors for each character in `X`.\n",
        "   - This expression replaces each integer index in `X` with its corresponding vector from the lookup table `C`.\n",
        "   - The result is a tensor with a shape of `[32, 3, 2]`, which means it has 32 rows (one for each context), 3 vectors per row (one for each character in the context), and each vector is 2-dimensional.\n",
        "\n",
        "4. **Benefits of PyTorch Indexing**:\n",
        "   - PyTorch indexing allows us to efficiently convert the integer indices in `X` to their corresponding vectors in `C` in one step.\n",
        "   - This is much faster and more memory-efficient than using a loop to convert each integer index to its vector one by one.\n",
        "   - PyTorch indexing also makes the code simpler and easier to read.\n",
        "\n",
        "5. **Intuition**:\n",
        "   - We're using the embedding lookup table `C` to convert the integer indices in `X` to more informative vector representations.\n",
        "   - These vectors are then passed to the subsequent layers of the neural network.\n",
        "   - The vectors in `C` are adjusted during training to make them more useful for predicting the next character.\n",
        "   - Characters that appear in similar contexts will have vectors that are close together in the embedding space.\n",
        "\n",
        "In summary, PyTorch multi-dimensional indexing is a powerful feature that allows us to efficiently convert the integer indices in `X` to their corresponding vectors in `C`. This makes the code faster, more memory-efficient, and easier to read."
      ],
      "metadata": {
        "id": "rghJ5DbBx4IC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## `torch.linspace()`\n",
        "\n",
        "`torch.linspace()` is a function in PyTorch that generates a one-dimensional tensor of evenly spaced values within a specified range.\n",
        "\n",
        "The function takes three parameters:\n",
        "- `start`: the starting value of the sequence\n",
        "- `end`: the ending value of the sequence\n",
        "- `steps`: the number of equally spaced points to generate\n",
        "\n",
        "It returns a tensor that contains `steps` elements, starting from `start` and ending at `end`, with equal spacing between adjacent elements.\n",
        "\n",
        "Here's an example:\n",
        "\n",
        "```python\n",
        "import torch\n",
        "\n",
        "# Generate a tensor with 5 equally spaced values between 0 and 1\n",
        "t = torch.linspace(0, 1, 5)\n",
        "print(t)\n",
        "```\n",
        "\n",
        "Output:\n",
        "\n",
        "```\n",
        "tensor([0.0000, 0.2500, 0.5000, 0.7500, 1.0000])\n",
        "```\n",
        "\n",
        "In this example, `torch.linspace()` generates a tensor with 5 equally spaced values between 0 and 1. The spacing between adjacent elements is (1 - 0) / (5 - 1) = 0.25."
      ],
      "metadata": {
        "id": "_B2igXjgxjsM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PyTorch's `backward()` method\n",
        "\n",
        "1. **What is backward()?**\n",
        "   In PyTorch, the `backward()` method is used to calculate the gradients of the parameters (like weights and biases) with respect to the loss. Gradients are essential in the training of neural networks because they are used to update the parameters. The `backward()` method automates the calculation of gradients, making it easier to train models.\n",
        "\n",
        "2. **Why is it important?**\n",
        "   Calculating gradients manually can be complex, especially for large neural networks. The `backward()` method simplifies this process. By automatically calculating gradients, it enables the use of optimization algorithms like gradient descent to minimize the loss and improve the model's performance.\n",
        "\n",
        "3. **How does it work?**\n",
        "   The `backward()` method is based on the concept of automatic differentiation. It works by traversing the computational graph of the model in reverse (from output to input) and applying the chain rule of calculus to compute the gradients. This process is known as backpropagation.\n",
        "\n",
        "4. **What did people use before?**\n",
        "   Before tools like PyTorch and its `backward()` method, people had to manually derive and implement the gradients for their models. This could be error-prone, time-consuming, and difficult, especially for complex models. Some tools, like Theano, provided automatic differentiation capabilities, but they weren't as user-friendly and flexible as modern deep learning libraries like PyTorch and TensorFlow.\n",
        "\n",
        "Here's an easy-to-understand analogy:\n",
        "\n",
        "Imagine you're trying to find your way out of a maze. At each intersection, you need to decide which direction to go. In machine learning, the \"direction\" is determined by the gradient, which tells you which way to update your parameters to minimize the loss. Calculating the gradient is like having a compass that points you in the right direction. The `backward()` method automatically gives you this \"compass\" for every parameter in your model, making it much easier to find your way out of the \"maze\" of high loss and improve your model's performance."
      ],
      "metadata": {
        "id": "aFqZNCARxxyQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pytorch's `max()` function\n",
        "\n",
        "In PyTorch, the `max()` function can be used to find the maximum value along a specified dimension of a tensor. When called with an argument, like `max(1)`, it returns two tensors: one with the maximum values and another with the indices of those maximum values along the specified dimension.\n",
        "\n",
        "In the context of neural networks and classification, these indices often represent the class labels that the network predicts as most probable.\n",
        "\n",
        "Let's break it down step by step:\n",
        "\n",
        "1. **Logits**: The term \"logits\" refers to the raw, unnormalized scores that a classification model (like a neural network) outputs for each class.\n",
        "\n",
        "2. **Max Function**: The `max()` function, when applied along the dimension 1 (columns), finds the maximum value in each row of the logits tensor.\n",
        "\n",
        "3. **Returned Values**: The function returns two tensors:\n",
        "    - The first tensor (`values`) contains the maximum values themselves.\n",
        "    - The second tensor (`indices`) contains the indices where these maximum values occurred.\n",
        "\n",
        "4. **Predicted Class Labels**: In the context of classification, the indices correspond to the predicted class labels. These are the classes that the model thinks are most probable for each input.\n",
        "\n",
        "5. **Example**: Consider a logits tensor `[[1, 2, 3], [4, 5, 6], [7, 8, 9]]`. When we call `max(1)` on this tensor, it will return:\n",
        "    - `values` tensor: `[3, 6, 9]` (the maximum values in each row).\n",
        "    - `indices` tensor: `[2, 2, 2]` (the indices where these maximum values occurred).\n",
        "\n",
        "In summary, calling `max(1)` on the logits tensor returns the maximum values and their corresponding indices along the columns. These indices represent the predicted class labels that the model assigns to each input."
      ],
      "metadata": {
        "id": "g-nGH2Joxp86"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Jupyter notebook's `%%time`\n",
        "\n",
        "In a Jupyter notebook, you can use the `%%time` cell magic command at the beginning of a code cell to measure and display the time it takes to execute that cell.\n",
        "\n",
        "Here's an example:\n",
        "\n",
        "```python\n",
        "%%time\n",
        "\n",
        "# Your code here\n",
        "for i in range(1000000):\n",
        "    pass\n",
        "```\n",
        "\n",
        "When you run this cell, Jupyter will display the execution time at the bottom of the cell.\n",
        "\n",
        "If you want to time individual lines within a cell, you can use the `%time` line magic command instead. Here's an example:\n",
        "\n",
        "```python\n",
        "# Some code\n",
        "\n",
        "%time for i in range(1000000): pass\n",
        "\n",
        "# More code\n",
        "```\n",
        "\n",
        "This will display the execution time for just that one line of code."
      ],
      "metadata": {
        "id": "yFPQw2e5CJ7q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Jupyter Notebook tips and tricks\n",
        "\n",
        "1. **`%matplotlib inline`**: This magic command allows you to display matplotlib plots directly within the notebook, without needing to call `plt.show()`.\n",
        "\n",
        "2. **`%load`**: This command lets you load the contents of an external file into a code cell.\n",
        "\n",
        "3. **`%run`**: This command allows you to run an external Python script as if it were a part of the notebook.\n",
        "\n",
        "4. **`%%writefile`**: This cell magic command allows you to write the contents of a cell to an external file.\n",
        "\n",
        "5. **`%debug`**: This command lets you enter the interactive debugger at the point where an exception was raised. This can be very useful for debugging errors in your code.\n",
        "\n",
        "6. **`%who`**: This command lists all variables of global scope. You can specify a datatype to list only variables of that type.\n",
        "\n",
        "7. **`%reset`**: This command resets the namespace by removing all names defined by the user. It's useful for starting fresh without restarting the kernel.\n",
        "\n",
        "8. **`%timeit`**: This command runs a statement multiple times to measure its execution time. It's very useful for performance testing.\n",
        "\n",
        "9. **`%autoreload`**: This command automatically reloads Python modules before executing user code. It's useful when you're editing external Python scripts that you're importing into your notebook.\n",
        "\n",
        "10. **`!`**: You can use the exclamation point to run shell commands directly from your Jupyter notebook. For example, `!ls` would list the contents of the current directory.\n",
        "\n",
        "11. **`Tab` Completion**: Jupyter supports tab completion. Start typing a variable name and press `Tab` to see a list of available completions.\n",
        "\n",
        "12. **`Shift+Tab`**: Hold `Shift` and press `Tab` while your cursor is on a function name to see the function's signature and docstring.\n",
        "\n",
        "13. **Markdown and LaTeX Support**: Jupyter notebooks support Markdown for formatted text and LaTeX for mathematical equations.\n",
        "\n",
        "14. **Keyboard Shortcuts**: Jupyter has a lot of keyboard shortcuts that can speed up your workflow. For example, `Shift+Enter` runs the current cell, `Ctrl+Enter` runs the current cell in-place, and `Alt+Enter` runs the current cell and inserts a new cell below.\n",
        "\n",
        "15. **Extensions**: Jupyter has a wide range of extensions that can enhance its functionality. The Nbextensions package, in particular, offers a collection of useful extensions.\n",
        "\n",
        "These are just a few of the many features and tricks that Jupyter notebooks offer. Exploring the Jupyter documentation and community resources can help you discover even more ways to enhance your workflow.\n"
      ],
      "metadata": {
        "id": "w8fKSBhQw9GN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tensor views\n",
        "\n",
        "In PyTorch, a tensor view is a way to reshape or modify the dimensions of a tensor without creating a new copy of the tensor's data. This is very efficient as it reduces memory usage and computational overhead. Instead of copying the data, a view provides a new way of looking at the same data, with different dimensions.\n",
        "\n",
        "Let's go through some examples to understand how tensor views work in PyTorch.\n",
        "\n",
        "1. **Reshape**: You can use the `.view()` method to reshape a tensor. For example, if you have a tensor with a shape of `[4, 5]`, you can reshape it to have a shape of `[2, 10]`, as long as the total number of elements remains the same (i.e., 20 elements in this case).\n",
        "\n",
        "```python\n",
        "import torch\n",
        "\n",
        "x = torch.rand(4, 5)\n",
        "print(x.shape)  # torch.Size([4, 5])\n",
        "\n",
        "y = x.view(2, 10)\n",
        "print(y.shape)  # torch.Size([2, 10])\n",
        "```\n",
        "\n",
        "2. **Flatten**: You can flatten a tensor (i.e., convert it to a one-dimensional tensor) by using the `.view()` method with `-1` as an argument. The `-1` tells PyTorch to infer the size of the dimension based on the total number of elements in the tensor.\n",
        "\n",
        "```python\n",
        "z = x.view(-1)\n",
        "print(z.shape)  # torch.Size([20])\n",
        "```\n",
        "\n",
        "3. **Squeeze and Unsqueeze**: You can use the `.squeeze()` and `.unsqueeze()` methods to remove or add dimensions of size 1, respectively.\n",
        "\n",
        "```python\n",
        "a = torch.rand(1, 3, 1, 4)\n",
        "print(a.shape)  # torch.Size([1, 3, 1, 4])\n",
        "\n",
        "b = a.squeeze()\n",
        "print(b.shape)  # torch.Size([3, 4])\n",
        "\n",
        "c = b.unsqueeze(0)\n",
        "print(c.shape)  # torch.Size([1, 3, 4])\n",
        "```\n",
        "\n",
        "It's important to note that when you modify a view, the original tensor's data is also modified, as they share the same memory. This behavior can be useful, but you should be aware of it to avoid unexpected results.\n",
        "\n",
        "In summary, tensor views in PyTorch allow you to reshape and modify the dimensions of tensors efficiently without creating new copies of the data. This is helpful for reducing memory usage and computational overhead."
      ],
      "metadata": {
        "id": "B6RWTpMLwveH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## macOS and GPU\n",
        "\n",
        "MacOS does not support NVIDIA CUDA, which is the most common framework for GPU acceleration. This means that you can't use NVIDIA GPUs on a Mac to accelerate machine learning training. However, Apple has its own GPU architecture, called Metal, and a framework for machine learning called Core ML. With Core ML, you can run machine learning models on Apple devices, including Macs, iPhones, and iPads. However, Core ML is optimized for inference, not training. This means that while you can use it to run pre-trained models quickly, it is not designed to train new models from scratch.\n",
        "\n",
        "If you're training models in a Jupyter notebook on a Mac, you're most likely using the CPU, not the GPU. However, Apple's CPUs are highly optimized and can be quite fast for small to medium-sized models. This could explain why training on your Macbook was faster than on Colab. However, for larger models or larger datasets, a GPU will usually be much faster than a CPU.\n",
        "\n",
        "If you're using PyTorch or TensorFlow in your Jupyter notebook, you can check if a GPU is available and, if so, move your model and data to the GPU. Here's how you can do it in PyTorch:\n",
        "\n",
        "1. First, check if a GPU is available:\n",
        "```python\n",
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "```\n",
        "\n",
        "2. Then, move your model and data to the GPU:\n",
        "```python\n",
        "model.to(device)\n",
        "data, labels = data.to(device), labels.to(device)\n",
        "```\n",
        "\n",
        "However, keep in mind that this will only work if you have a compatible GPU and the necessary drivers and libraries installed.\n",
        "\n",
        "In the case of a Macbook, as mentioned earlier, you're likely using the CPU for training, not the GPU. If you need to train large models or work with large datasets, you might want to consider using a cloud-based service like Google Colab, which offers free access to NVIDIA GPUs, or a cloud provider like AWS or Azure, where you can rent GPU instances."
      ],
      "metadata": {
        "id": "wexfipabxDhN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GPU on Google Colab\n",
        "\n",
        "To use the available GPU on Google Colab, you can follow these steps:\n",
        "\n",
        "1. First, make sure that the GPU runtime is enabled. You can do this by clicking on the \"Runtime\" menu in the top bar, then selecting \"Change runtime type\" and choosing \"GPU\" in the \"Hardware accelerator\" dropdown.\n",
        "\n",
        "2. Next, you need to move your model and data to the GPU in your code. You can do this by using the `to()` method of PyTorch tensors and modules. Here's an example:\n",
        "\n",
        "```python\n",
        "# Check if a GPU is available and, if so, use it\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Move your model and data to the GPU\n",
        "model.to(device)\n",
        "data, labels = data.to(device), labels.to(device)\n",
        "```\n",
        "\n",
        "In your specific code, you can do this by adding the following lines:\n",
        "\n",
        "```python\n",
        "# Check if a GPU is available and, if so, use it\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Move your parameters to the GPU\n",
        "for p in parameters:\n",
        "    p.to(device)\n",
        "```\n",
        "\n",
        "Add this code after you have defined your parameters and set `requires_grad = True`, but before you start the training loop.\n",
        "\n",
        "3. Make sure that all the computations in your training loop are done on the GPU. You can do this by moving any tensors that are involved in the computations to the GPU as well. In your specific code, you can do this by adding the following lines:\n",
        "\n",
        "```python\n",
        "# Move your mini-batch to the GPU\n",
        "ix = ix.to(device)\n",
        "\n",
        "# Move your input data and labels to the GPU\n",
        "Xtr, Ytr = Xtr.to(device), Ytr.to(device)\n",
        "```\n",
        "\n",
        "Add this code at the beginning of your training loop, before the forward pass.\n",
        "\n",
        "That's it! Now your code should be using the GPU on Google Colab. Note that using the GPU can significantly speed up the training process, especially for large models and large datasets."
      ],
      "metadata": {
        "id": "ciUzot-7xIKu"
      }
    }
  ]
}